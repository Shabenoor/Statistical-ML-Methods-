{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Project - Shabenoor Kamal - Statistical and ML Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sys.setenv(LANG = \"en\")\n",
    "\n",
    "# Data processing library\n",
    "library(data.table)       # Data manipulation\n",
    "library(plyr)             # Data manipulation\n",
    "library(stringr)          # String, text processing\n",
    "library(vita)             # Quickly check variable importance\n",
    "library(dataPreparation)  # Data preparation library\n",
    "library(woeBinning)       # Decision tree–based binning for numerical and categorical variables\n",
    "library(Boruta)           # Variable selection\n",
    "\n",
    "# Machine learning library\n",
    "library(mlr)          # Machine learning framework\n",
    "library(caret)         # Data processing and machine learning framework\n",
    "library(MASS)          # LDA\n",
    "library(randomForest)  # RF\n",
    "library(gbm)           # Boosting Tree\n",
    "library(xgboost)       # XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data summary and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and print out some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train (full), test (holdout)\n",
    "train_full <- read.csv('C:/Users/skamal/Downloads/bank_mkt_train.csv')  # Training dataset\n",
    "test_holdout <- read.csv('C:/Users/skamal/Downloads/bank_mkt_test.csv')  # Holdout data set without response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t7000 obs. of  21 variables:\n",
      " $ client_id     : int  2 3 4 5 6 7 8 9 14 15 ...\n",
      " $ age           : int  29 39 49 32 29 51 34 52 52 29 ...\n",
      " $ job           : Factor w/ 12 levels \"admin.\",\"blue-collar\",..: 4 11 2 7 1 7 2 8 1 1 ...\n",
      " $ marital       : Factor w/ 4 levels \"divorced\",\"married\",..: 3 2 2 3 3 2 2 2 2 3 ...\n",
      " $ education     : Factor w/ 8 levels \"basic.4y\",\"basic.6y\",..: 4 3 2 7 4 7 1 4 7 7 ...\n",
      " $ default       : Factor w/ 2 levels \"no\",\"unknown\": 1 2 2 1 2 2 1 1 1 1 ...\n",
      " $ housing       : Factor w/ 3 levels \"no\",\"unknown\",..: 1 3 1 3 3 3 3 3 3 3 ...\n",
      " $ loan          : Factor w/ 3 levels \"no\",\"unknown\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ contact       : Factor w/ 2 levels \"cellular\",\"telephone\": 2 2 1 1 1 2 1 1 1 1 ...\n",
      " $ month         : Factor w/ 10 levels \"apr\",\"aug\",\"dec\",..: 7 5 8 7 4 5 8 8 8 5 ...\n",
      " $ day_of_week   : Factor w/ 5 levels \"fri\",\"mon\",\"thu\",..: 2 1 4 2 1 4 4 4 3 2 ...\n",
      " $ campaign      : int  3 6 2 3 2 1 1 1 3 1 ...\n",
      " $ pdays         : int  999 999 999 999 999 999 999 999 999 999 ...\n",
      " $ previous      : int  0 0 0 1 0 0 0 0 0 0 ...\n",
      " $ poutcome      : Factor w/ 3 levels \"failure\",\"nonexistent\",..: 2 2 2 1 2 2 2 2 2 2 ...\n",
      " $ emp.var.rate  : num  1.1 1.4 -0.1 -1.8 1.4 1.4 -0.1 -0.1 -0.1 -2.9 ...\n",
      " $ cons.price.idx: num  94 94.5 93.2 92.9 93.9 ...\n",
      " $ cons.conf.idx : num  -36.4 -41.8 -42 -46.2 -42.7 -41.8 -42 -42 -42 -40.8 ...\n",
      " $ euribor3m     : num  4.86 4.96 4.15 1.3 4.96 ...\n",
      " $ nr.employed   : num  5191 5228 5196 5099 5228 ...\n",
      " $ subscribe     : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Print out to check the data type\n",
    "str(train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct the variable: campaign\n",
    "\n",
    "Since campaign includes also the last contact, its value should be reduce by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fix the value\n",
    "train_full[, 'campaign'] <- train_full[, 'campaign'] - 1\n",
    "test_holdout[, 'campaign'] <- test_holdout[, 'campaign'] - 1\n",
    "\n",
    "# Quick check\n",
    "min(train_full[, 'campaign'])  # Previously = 1\n",
    "min(test_holdout[, 'campaign'])  # Previously = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check and fix data error (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>client_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>age</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>job</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>marital</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>education</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>default</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>housing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>loan</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>contact</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>month</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>day_of_week</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>campaign</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>pdays</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>previous</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>poutcome</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>emp.var.rate</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>cons.price.idx</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>cons.conf.idx</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>euribor3m</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>nr.employed</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>subscribe</dt>\n",
       "\t\t<dd>0</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[client\\textbackslash{}\\_id] 0\n",
       "\\item[age] 0\n",
       "\\item[job] 0\n",
       "\\item[marital] 0\n",
       "\\item[education] 0\n",
       "\\item[default] 0\n",
       "\\item[housing] 0\n",
       "\\item[loan] 0\n",
       "\\item[contact] 0\n",
       "\\item[month] 0\n",
       "\\item[day\\textbackslash{}\\_of\\textbackslash{}\\_week] 0\n",
       "\\item[campaign] 0\n",
       "\\item[pdays] 0\n",
       "\\item[previous] 0\n",
       "\\item[poutcome] 0\n",
       "\\item[emp.var.rate] 0\n",
       "\\item[cons.price.idx] 0\n",
       "\\item[cons.conf.idx] 0\n",
       "\\item[euribor3m] 0\n",
       "\\item[nr.employed] 0\n",
       "\\item[subscribe] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "client_id\n",
       ":   0age\n",
       ":   0job\n",
       ":   0marital\n",
       ":   0education\n",
       ":   0default\n",
       ":   0housing\n",
       ":   0loan\n",
       ":   0contact\n",
       ":   0month\n",
       ":   0day_of_week\n",
       ":   0campaign\n",
       ":   0pdays\n",
       ":   0previous\n",
       ":   0poutcome\n",
       ":   0emp.var.rate\n",
       ":   0cons.price.idx\n",
       ":   0cons.conf.idx\n",
       ":   0euribor3m\n",
       ":   0nr.employed\n",
       ":   0subscribe\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "     client_id            age            job        marital      education \n",
       "             0              0              0              0              0 \n",
       "       default        housing           loan        contact          month \n",
       "             0              0              0              0              0 \n",
       "   day_of_week       campaign          pdays       previous       poutcome \n",
       "             0              0              0              0              0 \n",
       "  emp.var.rate cons.price.idx  cons.conf.idx      euribor3m    nr.employed \n",
       "             0              0              0              0              0 \n",
       "     subscribe \n",
       "             0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing value\n",
    "apply(is.na(train_full), 2, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train (full) data into train, valid, test (70:15:15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "\n",
    "train_idx <- caret::createDataPartition(y=train_full[, 'subscribe'], p=.7, list=F)\n",
    "train <- train_full[train_idx, ]  # Train 70%\n",
    "valid_test <- train_full[-train_idx, ]  # Valid + Test 30%\n",
    "\n",
    "valid_idx <- caret::createDataPartition(y=valid_test[, 'subscribe'], p=.5, list=F)\n",
    "valid <- valid_test[valid_idx, ]  # Valid 15%\n",
    "test <- valid_test[-valid_idx, ]  # Test 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the target variable class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "4329  571 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "932 118 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "917 133 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# By number\n",
    "table(train$subscribe)\n",
    "table(valid$subscribe)\n",
    "table(test$subscribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        0         1 \n",
       "0.8834694 0.1165306 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "       0        1 \n",
       "0.887619 0.112381 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        0         1 \n",
       "0.8733333 0.1266667 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# By percentage\n",
    "table(train$subscribe) / nrow(train)\n",
    "table(valid$subscribe) / nrow(valid)\n",
    "table(test$subscribe) / nrow(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simply check which variables are potentially important\n",
    "\n",
    "Note: Running this permutation algorithm may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIMP-Algorithm For The Permutation Variable Importance Measure\n",
    "# https://cran.r-project.org/web/packages/vita/vita.pdf\n",
    "X <- train[, 2:(ncol(train)-1)]\n",
    "y <- as.factor(train[, 'subscribe'])\n",
    "rf_model <- randomForest(X, y, mtry=3, ntree=100, importance=T, seed=1)\n",
    "pimp_varImp <- PIMP(X, y, rf_model, S=10, parallel=F, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>month</dt>\n",
       "\t\t<dd>0.046329877427378</dd>\n",
       "\t<dt>euribor3m</dt>\n",
       "\t\t<dd>0.0402249693139268</dd>\n",
       "\t<dt>emp.var.rate</dt>\n",
       "\t\t<dd>0.0393108185969687</dd>\n",
       "\t<dt>cons.price.idx</dt>\n",
       "\t\t<dd>0.0300008701836996</dd>\n",
       "\t<dt>cons.conf.idx</dt>\n",
       "\t\t<dd>0.021629211621251</dd>\n",
       "\t<dt>nr.employed</dt>\n",
       "\t\t<dd>0.0192035332434342</dd>\n",
       "\t<dt>job</dt>\n",
       "\t\t<dd>0.0078583567213465</dd>\n",
       "\t<dt>age</dt>\n",
       "\t\t<dd>0.00671807396714581</dd>\n",
       "\t<dt>poutcome</dt>\n",
       "\t\t<dd>0.00372629006401875</dd>\n",
       "\t<dt>education</dt>\n",
       "\t\t<dd>0.00339520396817073</dd>\n",
       "\t<dt>pdays</dt>\n",
       "\t\t<dd>0.00272257073490823</dd>\n",
       "\t<dt>previous</dt>\n",
       "\t\t<dd>0.00221187365115</dd>\n",
       "\t<dt>marital</dt>\n",
       "\t\t<dd>0.00106987847689769</dd>\n",
       "\t<dt>day_of_week</dt>\n",
       "\t\t<dd>0.00102034287689931</dd>\n",
       "\t<dt>default</dt>\n",
       "\t\t<dd>0.000731507734791684</dd>\n",
       "\t<dt>contact</dt>\n",
       "\t\t<dd>0.000643918598257863</dd>\n",
       "\t<dt>loan</dt>\n",
       "\t\t<dd>0.000437084699375957</dd>\n",
       "\t<dt>housing</dt>\n",
       "\t\t<dd>0.000246547689460713</dd>\n",
       "\t<dt>campaign</dt>\n",
       "\t\t<dd>-8.37192542087426e-05</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[month] 0.046329877427378\n",
       "\\item[euribor3m] 0.0402249693139268\n",
       "\\item[emp.var.rate] 0.0393108185969687\n",
       "\\item[cons.price.idx] 0.0300008701836996\n",
       "\\item[cons.conf.idx] 0.021629211621251\n",
       "\\item[nr.employed] 0.0192035332434342\n",
       "\\item[job] 0.0078583567213465\n",
       "\\item[age] 0.00671807396714581\n",
       "\\item[poutcome] 0.00372629006401875\n",
       "\\item[education] 0.00339520396817073\n",
       "\\item[pdays] 0.00272257073490823\n",
       "\\item[previous] 0.00221187365115\n",
       "\\item[marital] 0.00106987847689769\n",
       "\\item[day\\textbackslash{}\\_of\\textbackslash{}\\_week] 0.00102034287689931\n",
       "\\item[default] 0.000731507734791684\n",
       "\\item[contact] 0.000643918598257863\n",
       "\\item[loan] 0.000437084699375957\n",
       "\\item[housing] 0.000246547689460713\n",
       "\\item[campaign] -8.37192542087426e-05\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "month\n",
       ":   0.046329877427378euribor3m\n",
       ":   0.0402249693139268emp.var.rate\n",
       ":   0.0393108185969687cons.price.idx\n",
       ":   0.0300008701836996cons.conf.idx\n",
       ":   0.021629211621251nr.employed\n",
       ":   0.0192035332434342job\n",
       ":   0.0078583567213465age\n",
       ":   0.00671807396714581poutcome\n",
       ":   0.00372629006401875education\n",
       ":   0.00339520396817073pdays\n",
       ":   0.00272257073490823previous\n",
       ":   0.00221187365115marital\n",
       ":   0.00106987847689769day_of_week\n",
       ":   0.00102034287689931default\n",
       ":   0.000731507734791684contact\n",
       ":   0.000643918598257863loan\n",
       ":   0.000437084699375957housing\n",
       ":   0.000246547689460713campaign\n",
       ":   -8.37192542087426e-05\n",
       "\n"
      ],
      "text/plain": [
       "         month      euribor3m   emp.var.rate cons.price.idx  cons.conf.idx \n",
       "  4.632988e-02   4.022497e-02   3.931082e-02   3.000087e-02   2.162921e-02 \n",
       "   nr.employed            job            age       poutcome      education \n",
       "  1.920353e-02   7.858357e-03   6.718074e-03   3.726290e-03   3.395204e-03 \n",
       "         pdays       previous        marital    day_of_week        default \n",
       "  2.722571e-03   2.211874e-03   1.069878e-03   1.020343e-03   7.315077e-04 \n",
       "       contact           loan        housing       campaign \n",
       "  6.439186e-04   4.370847e-04   2.465477e-04  -8.371925e-05 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out top most important variables\n",
    "pimp_varImp$VarImp[order(pimp_varImp$VarImp[, 1], decreasing=T), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add variable: month_spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'month_spring'] <- as.logical(train$month %in% c('mar', 'apr', 'may'))\n",
    "valid[, 'month_spring'] <- as.logical(valid$month %in% c('mar', 'apr', 'may'))\n",
    "test[, 'month_spring'] <- as.logical(test$month %in% c('mar', 'apr', 'may'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_spring'] <- as.logical(test_holdout$month %in% c('mar', 'apr', 'may'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add variable: month_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'month_summer'] <- as.logical(train$month %in% c('jun', 'jul', 'aug'))\n",
    "valid[, 'month_summer'] <- as.logical(valid$month %in% c('jun', 'jul', 'aug'))\n",
    "test[, 'month_summer'] <- as.logical(test$month %in% c('jun', 'jul', 'aug'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_summer'] <- as.logical(test_holdout$month %in% c('jun', 'jul', 'aug'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add variable: month_autumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'month_autumn'] <- as.logical(train$month %in% c('sep', 'oct', 'nov'))\n",
    "valid[, 'month_autumn'] <- as.logical(valid$month %in% c('sep', 'oct', 'nov'))\n",
    "test[, 'month_autumn'] <- as.logical(test$month %in% c('sep', 'oct', 'nov'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_autumn'] <- as.logical(test_holdout$month %in% c('sep', 'oct', 'nov'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add variable: month_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'month_winter'] <- as.logical(train$month %in% c('dec', 'jan', 'feb'))\n",
    "valid[, 'month_winter'] <- as.logical(valid$month %in% c('dec', 'jan', 'feb'))\n",
    "test[, 'month_winter'] <- as.logical(test$month %in% c('dec', 'jan', 'feb'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_winter'] <- as.logical(test_holdout$month %in% c('dec', 'jan', 'feb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add variable: age > mean(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'age_ge_mean'] <- as.logical(train$age > mean(train$age))\n",
    "valid[, 'age_ge_mean'] <- as.logical(valid$age > mean(valid$age))\n",
    "test[, 'age_ge_mean'] <- as.logical(test$age > mean(test$age))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'age_ge_mean'] <- as.logical(test_holdout$age > mean(train$age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add variable: pdays_999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# pdays == 999 is a special value\n",
    "# Train, valid, test\n",
    "train[, 'pdays_999'] <- as.logical(train$pdays == 999)\n",
    "valid[, 'pdays_999'] <- as.logical(valid$pdays == 999)\n",
    "test[, 'pdays_999'] <- as.logical(test$pdays == 999)\n",
    "# Test (holdout)\n",
    "test_holdout[, 'pdays_999'] <- as.logical(test_holdout$pdays == 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to train, valid, test and test (holdout) - number emplyees >= or < mean\n",
    "# Train, valid, test\n",
    "train[, 'nremply_ge_mean'] <- as.logical(train$nr.employed > mean(train$nr.employed))\n",
    "valid[, 'nremply_ge_mean'] <- as.logical(valid$nr.employed > mean(valid$nr.employed))\n",
    "test[, 'nremply_ge_mean'] <- as.logical(test$nr.employed > mean(test$nr.employed))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'nremply_ge_mean'] <- as.logical(test_holdout$nr.employed > mean(train$nr.employed))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - number emplyees >= or < median\n",
    "# Train, valid, test\n",
    "train[, 'nremply_ge_median'] <- as.logical(train$nr.employed > median(train$nr.employed))\n",
    "valid[, 'nremply_ge_median'] <- as.logical(valid$nr.employed > median(valid$nr.employed))\n",
    "test[, 'nremply_ge_median'] <- as.logical(test$nr.employed > median(test$nr.employed))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'nremply_ge_median'] <- as.logical(test_holdout$nr.employed > median(train$nr.employed))\n",
    "\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - pdays >= or < mean\n",
    "# Train, valid, test\n",
    "train[, 'pdays_ge_mean'] <- as.logical(train$pdays > mean(train$pdays))\n",
    "valid[, 'pdays_ge_mean'] <- as.logical(valid$pdays > mean(valid$pdays))\n",
    "test[, 'pdays_ge_mean'] <- as.logical(test$pdays > mean(test$pdays))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'pdays_ge_mean'] <- as.logical(test_holdout$pdays > mean(train$pdays))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)- pdays >= or < median\n",
    "# Train, valid, test\n",
    "train[, 'pdays_ge_median'] <- as.logical(train$pdays > median(train$pdays))\n",
    "valid[, 'pdays_ge_median'] <- as.logical(valid$pdays > median(valid$pdays))\n",
    "test[, 'pdays_ge_median'] <- as.logical(test$pdays > median(test$pdays))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'pdays_ge_median'] <- as.logical(test_holdout$pdays > median(train$pdays))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)\n",
    "# previous contact == 0 (no contact) >0 (has been contacted before)\n",
    "# Train, valid, test\n",
    "train[, 'previous_ever'] <- as.logical(train$previous > 0)\n",
    "valid[, 'previous_ever'] <- as.logical(valid$previous > 0)\n",
    "test[, 'previous_ever'] <- as.logical(test$previous > 0)\n",
    "# Test (holdout)\n",
    "test_holdout[, 'previous_ever'] <- as.integer(test_holdout$previous > 0)\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)- previous contact days >= or < mean\n",
    "# Train, valid, test\n",
    "train[, 'previous_ge_mean'] <- as.logical(train$previous > mean(train$previous))\n",
    "valid[, 'previous_ge_mean'] <- as.logical(valid$previous > mean(valid$previous))\n",
    "test[, 'previous_ge_mean'] <- as.logical(test$previous > mean(test$previous))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'previous_ge_mean'] <- as.logical(test_holdout$previous > mean(train$previous))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - previous contact days >= or < median\n",
    "# Train, valid, test\n",
    "train[, 'previous_ge_median'] <- as.logical(train$previous > median(train$previous))\n",
    "valid[, 'previous_ge_median'] <- as.logical(valid$previous > median(valid$previous))\n",
    "test[, 'previous_ge_median'] <- as.logical(test$previous > median(test$previous))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'previous_ge_median'] <- as.logical(test_holdout$previous > median(train$previous))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - employee variation rate (positive/negative)\n",
    "# Train, valid, test\n",
    "train[, 'emp_varrate_positive'] <- as.logical(train$emp.var.rate  > 0)\n",
    "valid[, 'emp_varrate_positive'] <- as.logical(valid$emp.var.rate  > 0)\n",
    "test[, 'emp_varrate_positive'] <- as.logical(test$emp.var.rate  > 0)\n",
    "# Test (holdout)\n",
    "test_holdout[, 'emp_varrate_positive'] <- as.logical(test_holdout$emp.var.rate  > 0)\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)- employee variation rate >= or < mean\n",
    "# Train, valid, test\n",
    "train[, 'emp_varrate_ge_mean'] <- as.logical(train$emp.var.rate > mean(train$emp.var.rate))\n",
    "valid[, 'emp_varrate_ge_mean'] <- as.logical(valid$emp.var.rate > mean(valid$emp.var.rate))\n",
    "test[, 'emp_varrate_ge_mean'] <- as.logical(test$emp.var.rate > mean(test$emp.var.rate))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'emp_varrate_ge_mean'] <- as.logical(test_holdout$emp.var.rate > mean(train$emp.var.rate))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)- employee variation rate >= or < median\n",
    "# Train, valid, test\n",
    "train[, 'emp_varrate_ge_median'] <- as.logical(train$emp.var.rate > median(train$emp.var.rate))\n",
    "valid[, 'emp_varrate_ge_median'] <- as.logical(valid$emp.var.rate > median(valid$emp.var.rate))\n",
    "test[, 'emp_varrate_ge_median'] <- as.logical(test$emp.var.rate > median(test$emp.var.rate))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'emp_varrate_ge_median'] <- as.logical(test_holdout$emp.var.rate > median(train$emp.var.rate))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - consumer price index >= or < mean\n",
    "# Train, valid, test\n",
    "train[, 'conspriceindx_ge_mean'] <- as.logical(train$cons.price.idx > mean(train$cons.price.idx))\n",
    "valid[, 'conspriceindx_ge_mean'] <- as.logical(valid$cons.price.idx > mean(valid$cons.price.idx))\n",
    "test[, 'conspriceindx_ge_mean'] <- as.logical(test$cons.price.idx > mean(test$cons.price.idx))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'conspriceindx_ge_mean'] <- as.logical(test_holdout$cons.price.idx > mean(train$cons.price.idx))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - consumer price index  >= or < median\n",
    "# Train, valid, test\n",
    "train[, 'conspriceindx_ge_median'] <- as.logical(train$cons.price.idx > median(train$cons.price.idx))\n",
    "valid[, 'conspriceindx_ge_median'] <- as.logical(valid$cons.price.idx > median(valid$cons.price.idx))\n",
    "test[, 'conspriceindx_ge_median'] <- as.logical(test$cons.price.idx > median(test$cons.price.idx))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'conspriceindx_ge_median'] <- as.logical(test_holdout$cons.price.idx > median(train$cons.price.idx))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)- month in quarter 1 of year\n",
    "# Train, valid, test\n",
    "train[, 'month_quarter1'] <- as.logical(train$month %in% c('jan', 'feb', 'mar'))\n",
    "valid[, 'month_quarter1'] <- as.logical(valid$month %in% c('jan', 'feb', 'mar'))\n",
    "test[, 'month_quarter1'] <- as.logical(test$month %in% c('jan', 'feb', 'mar'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_quarter1'] <- as.logical(test_holdout$month %in% c('jan', 'feb', 'mar'))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - month in quarter 2 of year\n",
    "# Train, valid, test\n",
    "train[, 'month_quarter2'] <- as.logical(train$month %in% c('apr', 'may', 'jun'))\n",
    "valid[, 'month_quarter2'] <- as.logical(valid$month %in% c('apr', 'may', 'jun'))\n",
    "test[, 'month_quarter2'] <- as.logical(test$month %in% c('apr', 'may', 'jun'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_quarter2'] <- as.logical(test_holdout$month %in% c('apr', 'may', 'jun'))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout) - month in quarter 3 of year\n",
    "# Train, valid, test\n",
    "train[, 'month_quarter3'] <- as.logical(train$month %in% c('jul', 'aug', 'sep'))\n",
    "valid[, 'month_quarter3'] <- as.logical(valid$month %in% c('jul', 'aug', 'sep'))\n",
    "test[, 'month_quarter3'] <- as.logical(test$month %in% c('jul', 'aug', 'sep'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_quarter3'] <- as.logical(test_holdout$month %in% c('jul', 'aug', 'sep'))\n",
    "\n",
    "# Add new variable to train, valid, test and test (holdout)- month in quarter 4 of year\n",
    "# Train, valid, test\n",
    "train[, 'month_quarter4'] <- as.logical(train$month %in% c('oct', 'nov', 'dec'))\n",
    "valid[, 'month_quarter4'] <- as.logical(valid$month %in% c('oct', 'nov', 'dec'))\n",
    "test[, 'month_quarter4'] <- as.logical(test$month %in% c('oct', 'nov', 'dec'))\n",
    "# Test (holdout)\n",
    "test_holdout[, 'month_quarter4'] <- as.logical(test_holdout$month %in% c('oct', 'nov', 'dec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Value transformation\n",
    "\n",
    "- Categorical variables: remapping\n",
    "- Continuous variables: discretization\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Coussement, K., Lessmann, S., & Verstraeten, G. (2017). A comparative analysis of data preparation algorithms for customer churn prediction: A case study in the telecommunication industry. Decision Support Systems, 95, 27-36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list of categorical, boolean and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IV and DV list name\n",
    "# Dependent variable (DV)\n",
    "dv_list <- c('subscribe')\n",
    "# Independent variable (IV)\n",
    "iv_list <- setdiff(colnames(train), dv_list)  # Exclude the target variable\n",
    "iv_list <- setdiff(iv_list, 'client_id')  # Exclude the client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out categorical, boolean and numerical variable\n",
    "iv_cat_list <- c()  # List to store categorical variable\n",
    "iv_bool_list <- c()  # List to store boolean variable\n",
    "iv_num_list <- c()  # List to store numerical variable\n",
    "for (v in iv_list) {\n",
    "    if (class(train[, v]) == 'factor') {  # Factor == categorical variable\n",
    "        iv_cat_list <- c(iv_cat_list, v)\n",
    "    } else if (class(train[, v]) == 'logical') {  # Logical == boolean variable\n",
    "        iv_bool_list <- c(iv_bool_list, v)\n",
    "    } else {  # Non-factor + Non-logical == numerical variable\n",
    "        iv_num_list <- c(iv_num_list, v)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping (or remapping) categorical variables - Decision tree–based remapping\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Package ‘woeBinning’: https://cran.r-project.org/web/packages/woeBinning/woeBinning.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable remmaping on a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>'job'</li>\n",
       "\t<li><table>\n",
       "<thead><tr><th></th><th scope=col>Group.2</th><th scope=col>Group.1</th><th scope=col>woe</th><th scope=col>iv.total.final</th><th scope=col>1</th><th scope=col>0</th><th scope=col>col.perc.a</th><th scope=col>col.perc.b</th><th scope=col>iv.bins</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>misc. level neg. + technician + blue-collar + services</td><td>blue-collar                                           </td><td>-31.13043                                             </td><td>0.1344354                                             </td><td>237                                                   </td><td>2453                                                  </td><td>0.4150613                                             </td><td>0.5666436                                             </td><td>0.04718821                                            </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>misc. level neg. + technician + blue-collar + services</td><td>entrepreneur                                          </td><td>-31.13043                                             </td><td>0.1344354                                             </td><td>237                                                   </td><td>2453                                                  </td><td>0.4150613                                             </td><td>0.5666436                                             </td><td>0.04718821                                            </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>misc. level neg. + technician + blue-collar + services</td><td>housemaid                                             </td><td>-31.13043                                             </td><td>0.1344354                                             </td><td>237                                                   </td><td>2453                                                  </td><td>0.4150613                                             </td><td>0.5666436                                             </td><td>0.04718821                                            </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>misc. level neg. + technician + blue-collar + services</td><td>services                                              </td><td>-31.13043                                             </td><td>0.1344354                                             </td><td>237                                                   </td><td>2453                                                  </td><td>0.4150613                                             </td><td>0.5666436                                             </td><td>0.04718821                                            </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>misc. level neg. + technician + blue-collar + services</td><td>technician                                            </td><td>-31.13043                                             </td><td>0.1344354                                             </td><td>237                                                   </td><td>2453                                                  </td><td>0.4150613                                             </td><td>0.5666436                                             </td><td>0.04718821                                            </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>misc. level neg. + technician + blue-collar + services</td><td>unknown                                               </td><td>-31.13043                                             </td><td>0.1344354                                             </td><td>237                                                   </td><td>2453                                                  </td><td>0.4150613                                             </td><td>0.5666436                                             </td><td>0.04718821                                            </td></tr>\n",
       "\t<tr><th scope=row>1</th><td>admin. + management                                   </td><td>admin.                                                </td><td> 10.05149                                             </td><td>0.1344354                                             </td><td>202                                                   </td><td>1385                                                  </td><td>0.3537653                                             </td><td>0.3199353                                             </td><td>0.00340042                                            </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>admin. + management                                   </td><td>management                                            </td><td> 10.05149                                             </td><td>0.1344354                                             </td><td>202                                                   </td><td>1385                                                  </td><td>0.3537653                                             </td><td>0.3199353                                             </td><td>0.00340042                                            </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>misc. level pos.                                      </td><td>retired                                               </td><td> 71.20604                                             </td><td>0.1344354                                             </td><td>132                                                   </td><td> 491                                                  </td><td>0.2311734                                             </td><td>0.1134211                                             </td><td>0.08384673                                            </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>misc. level pos.                                      </td><td>self-employed                                         </td><td> 71.20604                                             </td><td>0.1344354                                             </td><td>132                                                   </td><td> 491                                                  </td><td>0.2311734                                             </td><td>0.1134211                                             </td><td>0.08384673                                            </td></tr>\n",
       "\t<tr><th scope=row>11</th><td>misc. level pos.                                      </td><td>student                                               </td><td> 71.20604                                             </td><td>0.1344354                                             </td><td>132                                                   </td><td> 491                                                  </td><td>0.2311734                                             </td><td>0.1134211                                             </td><td>0.08384673                                            </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>misc. level pos.                                      </td><td>unemployed                                            </td><td> 71.20604                                             </td><td>0.1344354                                             </td><td>132                                                   </td><td> 491                                                  </td><td>0.2311734                                             </td><td>0.1134211                                             </td><td>0.08384673                                            </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</li>\n",
       "\t<li><strong>iv.total.final:</strong> 0.134435357346989</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 'job'\n",
       "\\item \\begin{tabular}{r|lllllllll}\n",
       "  & Group.2 & Group.1 & woe & iv.total.final & 1 & 0 & col.perc.a & col.perc.b & iv.bins\\\\\n",
       "\\hline\n",
       "\t3 & misc. level neg. + technician + blue-collar + services & blue-collar                                            & -31.13043                                              & 0.1344354                                              & 237                                                    & 2453                                                   & 0.4150613                                              & 0.5666436                                              & 0.04718821                                            \\\\\n",
       "\t4 & misc. level neg. + technician + blue-collar + services & entrepreneur                                           & -31.13043                                              & 0.1344354                                              & 237                                                    & 2453                                                   & 0.4150613                                              & 0.5666436                                              & 0.04718821                                            \\\\\n",
       "\t5 & misc. level neg. + technician + blue-collar + services & housemaid                                              & -31.13043                                              & 0.1344354                                              & 237                                                    & 2453                                                   & 0.4150613                                              & 0.5666436                                              & 0.04718821                                            \\\\\n",
       "\t6 & misc. level neg. + technician + blue-collar + services & services                                               & -31.13043                                              & 0.1344354                                              & 237                                                    & 2453                                                   & 0.4150613                                              & 0.5666436                                              & 0.04718821                                            \\\\\n",
       "\t7 & misc. level neg. + technician + blue-collar + services & technician                                             & -31.13043                                              & 0.1344354                                              & 237                                                    & 2453                                                   & 0.4150613                                              & 0.5666436                                              & 0.04718821                                            \\\\\n",
       "\t8 & misc. level neg. + technician + blue-collar + services & unknown                                                & -31.13043                                              & 0.1344354                                              & 237                                                    & 2453                                                   & 0.4150613                                              & 0.5666436                                              & 0.04718821                                            \\\\\n",
       "\t1 & admin. + management                                    & admin.                                                 &  10.05149                                              & 0.1344354                                              & 202                                                    & 1385                                                   & 0.3537653                                              & 0.3199353                                              & 0.00340042                                            \\\\\n",
       "\t2 & admin. + management                                    & management                                             &  10.05149                                              & 0.1344354                                              & 202                                                    & 1385                                                   & 0.3537653                                              & 0.3199353                                              & 0.00340042                                            \\\\\n",
       "\t9 & misc. level pos.                                       & retired                                                &  71.20604                                              & 0.1344354                                              & 132                                                    &  491                                                   & 0.2311734                                              & 0.1134211                                              & 0.08384673                                            \\\\\n",
       "\t10 & misc. level pos.                                       & self-employed                                          &  71.20604                                              & 0.1344354                                              & 132                                                    &  491                                                   & 0.2311734                                              & 0.1134211                                              & 0.08384673                                            \\\\\n",
       "\t11 & misc. level pos.                                       & student                                                &  71.20604                                              & 0.1344354                                              & 132                                                    &  491                                                   & 0.2311734                                              & 0.1134211                                              & 0.08384673                                            \\\\\n",
       "\t12 & misc. level pos.                                       & unemployed                                             &  71.20604                                              & 0.1344354                                              & 132                                                    &  491                                                   & 0.2311734                                              & 0.1134211                                              & 0.08384673                                            \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\item \\textbf{iv.total.final:} 0.134435357346989\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 'job'\n",
       "2. \n",
       "| <!--/--> | Group.2 | Group.1 | woe | iv.total.final | 1 | 0 | col.perc.a | col.perc.b | iv.bins |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3 | misc. level neg. + technician + blue-collar + services | blue-collar                                            | -31.13043                                              | 0.1344354                                              | 237                                                    | 2453                                                   | 0.4150613                                              | 0.5666436                                              | 0.04718821                                             |\n",
       "| 4 | misc. level neg. + technician + blue-collar + services | entrepreneur                                           | -31.13043                                              | 0.1344354                                              | 237                                                    | 2453                                                   | 0.4150613                                              | 0.5666436                                              | 0.04718821                                             |\n",
       "| 5 | misc. level neg. + technician + blue-collar + services | housemaid                                              | -31.13043                                              | 0.1344354                                              | 237                                                    | 2453                                                   | 0.4150613                                              | 0.5666436                                              | 0.04718821                                             |\n",
       "| 6 | misc. level neg. + technician + blue-collar + services | services                                               | -31.13043                                              | 0.1344354                                              | 237                                                    | 2453                                                   | 0.4150613                                              | 0.5666436                                              | 0.04718821                                             |\n",
       "| 7 | misc. level neg. + technician + blue-collar + services | technician                                             | -31.13043                                              | 0.1344354                                              | 237                                                    | 2453                                                   | 0.4150613                                              | 0.5666436                                              | 0.04718821                                             |\n",
       "| 8 | misc. level neg. + technician + blue-collar + services | unknown                                                | -31.13043                                              | 0.1344354                                              | 237                                                    | 2453                                                   | 0.4150613                                              | 0.5666436                                              | 0.04718821                                             |\n",
       "| 1 | admin. + management                                    | admin.                                                 |  10.05149                                              | 0.1344354                                              | 202                                                    | 1385                                                   | 0.3537653                                              | 0.3199353                                              | 0.00340042                                             |\n",
       "| 2 | admin. + management                                    | management                                             |  10.05149                                              | 0.1344354                                              | 202                                                    | 1385                                                   | 0.3537653                                              | 0.3199353                                              | 0.00340042                                             |\n",
       "| 9 | misc. level pos.                                       | retired                                                |  71.20604                                              | 0.1344354                                              | 132                                                    |  491                                                   | 0.2311734                                              | 0.1134211                                              | 0.08384673                                             |\n",
       "| 10 | misc. level pos.                                       | self-employed                                          |  71.20604                                              | 0.1344354                                              | 132                                                    |  491                                                   | 0.2311734                                              | 0.1134211                                              | 0.08384673                                             |\n",
       "| 11 | misc. level pos.                                       | student                                                |  71.20604                                              | 0.1344354                                              | 132                                                    |  491                                                   | 0.2311734                                              | 0.1134211                                              | 0.08384673                                             |\n",
       "| 12 | misc. level pos.                                       | unemployed                                             |  71.20604                                              | 0.1344354                                              | 132                                                    |  491                                                   | 0.2311734                                              | 0.1134211                                              | 0.08384673                                             |\n",
       "\n",
       "\n",
       "3. **iv.total.final:** 0.134435357346989\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] \"job\"\n",
       "\n",
       "[[2]]\n",
       "                                                  Group.2       Group.1\n",
       "3  misc. level neg. + technician + blue-collar + services   blue-collar\n",
       "4  misc. level neg. + technician + blue-collar + services  entrepreneur\n",
       "5  misc. level neg. + technician + blue-collar + services     housemaid\n",
       "6  misc. level neg. + technician + blue-collar + services      services\n",
       "7  misc. level neg. + technician + blue-collar + services    technician\n",
       "8  misc. level neg. + technician + blue-collar + services       unknown\n",
       "1                                     admin. + management        admin.\n",
       "2                                     admin. + management    management\n",
       "9                                        misc. level pos.       retired\n",
       "10                                       misc. level pos. self-employed\n",
       "11                                       misc. level pos.       student\n",
       "12                                       misc. level pos.    unemployed\n",
       "         woe iv.total.final   1    0 col.perc.a col.perc.b    iv.bins\n",
       "3  -31.13043      0.1344354 237 2453  0.4150613  0.5666436 0.04718821\n",
       "4  -31.13043      0.1344354 237 2453  0.4150613  0.5666436 0.04718821\n",
       "5  -31.13043      0.1344354 237 2453  0.4150613  0.5666436 0.04718821\n",
       "6  -31.13043      0.1344354 237 2453  0.4150613  0.5666436 0.04718821\n",
       "7  -31.13043      0.1344354 237 2453  0.4150613  0.5666436 0.04718821\n",
       "8  -31.13043      0.1344354 237 2453  0.4150613  0.5666436 0.04718821\n",
       "1   10.05149      0.1344354 202 1385  0.3537653  0.3199353 0.00340042\n",
       "2   10.05149      0.1344354 202 1385  0.3537653  0.3199353 0.00340042\n",
       "9   71.20604      0.1344354 132  491  0.2311734  0.1134211 0.08384673\n",
       "10  71.20604      0.1344354 132  491  0.2311734  0.1134211 0.08384673\n",
       "11  71.20604      0.1344354 132  491  0.2311734  0.1134211 0.08384673\n",
       "12  71.20604      0.1344354 132  491  0.2311734  0.1134211 0.08384673\n",
       "\n",
       "[[3]]\n",
       "iv.total.final \n",
       "     0.1344354 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grouping 12 categories in the variable job onto 3 groups using WOE\n",
    "binning_cat <- woe.binning(train, 'subscribe', 'job')\n",
    "binning_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>job</th><th scope=col>job.binned</th><th scope=col>woe.job.binned</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>housemaid                                             </td><td>misc. level neg. + technician + blue-collar + services</td><td>-31.13043                                             </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>blue-collar                                           </td><td>misc. level neg. + technician + blue-collar + services</td><td>-31.13043                                             </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>self-employed                                         </td><td>misc. level pos.                                      </td><td> 71.20604                                             </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>self-employed                                         </td><td>misc. level pos.                                      </td><td> 71.20604                                             </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>blue-collar                                           </td><td>misc. level neg. + technician + blue-collar + services</td><td>-31.13043                                             </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>technician                                            </td><td>misc. level neg. + technician + blue-collar + services</td><td>-31.13043                                             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & job & job.binned & woe.job.binned\\\\\n",
       "\\hline\n",
       "\t1 & housemaid                                              & misc. level neg. + technician + blue-collar + services & -31.13043                                             \\\\\n",
       "\t3 & blue-collar                                            & misc. level neg. + technician + blue-collar + services & -31.13043                                             \\\\\n",
       "\t4 & self-employed                                          & misc. level pos.                                       &  71.20604                                             \\\\\n",
       "\t6 & self-employed                                          & misc. level pos.                                       &  71.20604                                             \\\\\n",
       "\t7 & blue-collar                                            & misc. level neg. + technician + blue-collar + services & -31.13043                                             \\\\\n",
       "\t14 & technician                                             & misc. level neg. + technician + blue-collar + services & -31.13043                                             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | job | job.binned | woe.job.binned |\n",
       "|---|---|---|---|\n",
       "| 1 | housemaid                                              | misc. level neg. + technician + blue-collar + services | -31.13043                                              |\n",
       "| 3 | blue-collar                                            | misc. level neg. + technician + blue-collar + services | -31.13043                                              |\n",
       "| 4 | self-employed                                          | misc. level pos.                                       |  71.20604                                              |\n",
       "| 6 | self-employed                                          | misc. level pos.                                       |  71.20604                                              |\n",
       "| 7 | blue-collar                                            | misc. level neg. + technician + blue-collar + services | -31.13043                                              |\n",
       "| 14 | technician                                             | misc. level neg. + technician + blue-collar + services | -31.13043                                              |\n",
       "\n"
      ],
      "text/plain": [
       "   job           job.binned                                            \n",
       "1  housemaid     misc. level neg. + technician + blue-collar + services\n",
       "3  blue-collar   misc. level neg. + technician + blue-collar + services\n",
       "4  self-employed misc. level pos.                                      \n",
       "6  self-employed misc. level pos.                                      \n",
       "7  blue-collar   misc. level neg. + technician + blue-collar + services\n",
       "14 technician    misc. level neg. + technician + blue-collar + services\n",
       "   woe.job.binned\n",
       "1  -31.13043     \n",
       "3  -31.13043     \n",
       "4   71.20604     \n",
       "6   71.20604     \n",
       "7  -31.13043     \n",
       "14 -31.13043     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the binning to data\n",
    "tmp <- woe.binning.deploy(train, binning_cat, add.woe.or.dum.var='woe')\n",
    "head(tmp[, c('job', 'job.binned', 'woe.job.binned')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable remmaping for all categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all categorical variables\n",
    "for (v in iv_cat_list) {\n",
    "    \n",
    "    # Remapping categorical variable on train data\n",
    "    binning_cat <- woe.binning(train, 'subscribe', v)\n",
    "    \n",
    "    # Apply the binning to the train, valid and test data\n",
    "    train <- woe.binning.deploy(train, binning_cat, add.woe.or.dum.var='woe')\n",
    "    valid <- woe.binning.deploy(valid, binning_cat, add.woe.or.dum.var='woe')\n",
    "    test <- woe.binning.deploy(test, binning_cat, add.woe.or.dum.var='woe')\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    test_holdout <- woe.binning.deploy(test_holdout, binning_cat, add.woe.or.dum.var='woe')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping (or discretizing) numerical variables - Decision tree–based discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable discretizing on a numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>'age'</li>\n",
       "\t<li><table>\n",
       "<thead><tr><th></th><th scope=col>woe</th><th scope=col>cutpoints.final</th><th scope=col>cutpoints.final[-1]</th><th scope=col>iv.total.final</th><th scope=col>1</th><th scope=col>0</th><th scope=col>col.perc.a</th><th scope=col>col.perc.b</th><th scope=col>iv.bins</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(-Inf,26]</th><td> 58.096468  </td><td>-Inf        </td><td>26          </td><td>0.1508385   </td><td> 54         </td><td> 229        </td><td>0.09457093  </td><td>0.05289905  </td><td>0.0242098877</td></tr>\n",
       "\t<tr><th scope=row>(26,37]</th><td>  3.963093  </td><td>  26        </td><td>37          </td><td>0.1508385   </td><td>251         </td><td>1829        </td><td>0.43957968  </td><td>0.42249942  </td><td>0.0006769067</td></tr>\n",
       "\t<tr><th scope=row>(37,55]</th><td>-40.499981  </td><td>  37        </td><td>55          </td><td>0.1508385   </td><td>169         </td><td>1921        </td><td>0.29597198  </td><td>0.44375144  </td><td>0.0598506552</td></tr>\n",
       "\t<tr><th scope=row>(55, Inf]</th><td> 74.248046  </td><td>  55        </td><td>Inf         </td><td>0.1508385   </td><td> 97         </td><td> 350        </td><td>0.16987741  </td><td>0.08085008  </td><td>0.0661010510</td></tr>\n",
       "\t<tr><th scope=row>Missing</th><td>        NA  </td><td> Inf        </td><td>Missing     </td><td>0.1508385   </td><td>  0         </td><td>   0        </td><td>0.00000000  </td><td>0.00000000  </td><td>          NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</li>\n",
       "\t<li><strong>iv.total.final:</strong> 0.1508385005618</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 'age'\n",
       "\\item \\begin{tabular}{r|lllllllll}\n",
       "  & woe & cutpoints.final & cutpoints.final{[}-1{]} & iv.total.final & 1 & 0 & col.perc.a & col.perc.b & iv.bins\\\\\n",
       "\\hline\n",
       "\t(-Inf,26{]} &  58.096468   & -Inf         & 26           & 0.1508385    &  54          &  229         & 0.09457093   & 0.05289905   & 0.0242098877\\\\\n",
       "\t(26,37{]} &   3.963093   &   26         & 37           & 0.1508385    & 251          & 1829         & 0.43957968   & 0.42249942   & 0.0006769067\\\\\n",
       "\t(37,55{]} & -40.499981   &   37         & 55           & 0.1508385    & 169          & 1921         & 0.29597198   & 0.44375144   & 0.0598506552\\\\\n",
       "\t(55, Inf{]} &  74.248046   &   55         & Inf          & 0.1508385    &  97          &  350         & 0.16987741   & 0.08085008   & 0.0661010510\\\\\n",
       "\tMissing &         NA   &  Inf         & Missing      & 0.1508385    &   0          &    0         & 0.00000000   & 0.00000000   &           NA\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\item \\textbf{iv.total.final:} 0.1508385005618\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 'age'\n",
       "2. \n",
       "| <!--/--> | woe | cutpoints.final | cutpoints.final[-1] | iv.total.final | 1 | 0 | col.perc.a | col.perc.b | iv.bins |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| (-Inf,26] |  58.096468   | -Inf         | 26           | 0.1508385    |  54          |  229         | 0.09457093   | 0.05289905   | 0.0242098877 |\n",
       "| (26,37] |   3.963093   |   26         | 37           | 0.1508385    | 251          | 1829         | 0.43957968   | 0.42249942   | 0.0006769067 |\n",
       "| (37,55] | -40.499981   |   37         | 55           | 0.1508385    | 169          | 1921         | 0.29597198   | 0.44375144   | 0.0598506552 |\n",
       "| (55, Inf] |  74.248046   |   55         | Inf          | 0.1508385    |  97          |  350         | 0.16987741   | 0.08085008   | 0.0661010510 |\n",
       "| Missing |         NA   |  Inf         | Missing      | 0.1508385    |   0          |    0         | 0.00000000   | 0.00000000   |           NA |\n",
       "\n",
       "\n",
       "3. **iv.total.final:** 0.1508385005618\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] \"age\"\n",
       "\n",
       "[[2]]\n",
       "                 woe cutpoints.final cutpoints.final[-1] iv.total.final   1\n",
       "(-Inf,26]  58.096468            -Inf                  26      0.1508385  54\n",
       "(26,37]     3.963093              26                  37      0.1508385 251\n",
       "(37,55]   -40.499981              37                  55      0.1508385 169\n",
       "(55, Inf]  74.248046              55                 Inf      0.1508385  97\n",
       "Missing           NA             Inf             Missing      0.1508385   0\n",
       "             0 col.perc.a col.perc.b      iv.bins\n",
       "(-Inf,26]  229 0.09457093 0.05289905 0.0242098877\n",
       "(26,37]   1829 0.43957968 0.42249942 0.0006769067\n",
       "(37,55]   1921 0.29597198 0.44375144 0.0598506552\n",
       "(55, Inf]  350 0.16987741 0.08085008 0.0661010510\n",
       "Missing      0 0.00000000 0.00000000           NA\n",
       "\n",
       "[[3]]\n",
       "iv.total.final \n",
       "     0.1508385 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grouping the variable age onto 4 groups using WOE\n",
    "binning_num <- woe.binning(train, 'subscribe', 'age')\n",
    "binning_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>age</th><th scope=col>age.binned</th><th scope=col>woe.age.binned</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>29        </td><td>(26,37]   </td><td>  3.963093</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>49        </td><td>(37,55]   </td><td>-40.499981</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>32        </td><td>(26,37]   </td><td>  3.963093</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>51        </td><td>(37,55]   </td><td>-40.499981</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>34        </td><td>(26,37]   </td><td>  3.963093</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>39        </td><td>(37,55]   </td><td>-40.499981</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & age & age.binned & woe.age.binned\\\\\n",
       "\\hline\n",
       "\t1 & 29         & (26,37{]}  &   3.963093\\\\\n",
       "\t3 & 49         & (37,55{]}  & -40.499981\\\\\n",
       "\t4 & 32         & (26,37{]}  &   3.963093\\\\\n",
       "\t6 & 51         & (37,55{]}  & -40.499981\\\\\n",
       "\t7 & 34         & (26,37{]}  &   3.963093\\\\\n",
       "\t14 & 39         & (37,55{]}  & -40.499981\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | age | age.binned | woe.age.binned |\n",
       "|---|---|---|---|\n",
       "| 1 | 29         | (26,37]    |   3.963093 |\n",
       "| 3 | 49         | (37,55]    | -40.499981 |\n",
       "| 4 | 32         | (26,37]    |   3.963093 |\n",
       "| 6 | 51         | (37,55]    | -40.499981 |\n",
       "| 7 | 34         | (26,37]    |   3.963093 |\n",
       "| 14 | 39         | (37,55]    | -40.499981 |\n",
       "\n"
      ],
      "text/plain": [
       "   age age.binned woe.age.binned\n",
       "1  29  (26,37]      3.963093    \n",
       "3  49  (37,55]    -40.499981    \n",
       "4  32  (26,37]      3.963093    \n",
       "6  51  (37,55]    -40.499981    \n",
       "7  34  (26,37]      3.963093    \n",
       "14 39  (37,55]    -40.499981    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the binning to data\n",
    "tmp <- woe.binning.deploy(train, binning_num, add.woe.or.dum.var='woe')\n",
    "head(tmp[, c('age', 'age.binned', 'woe.age.binned')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable discretizing for all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all numerical variables\n",
    "for (v in iv_num_list) {\n",
    "    \n",
    "    # Discretizing numerical variable on train data\n",
    "    binning_num <- woe.binning(train, 'subscribe', v)\n",
    "    \n",
    "    # Apply the binning to the train, valid and test data\n",
    "    train <- woe.binning.deploy(train, binning_num, add.woe.or.dum.var='woe')\n",
    "    valid <- woe.binning.deploy(valid, binning_num, add.woe.or.dum.var='woe')\n",
    "    test <- woe.binning.deploy(test, binning_num, add.woe.or.dum.var='woe')\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    test_holdout <- woe.binning.deploy(test_holdout, binning_num, add.woe.or.dum.var='woe')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping (or discretizing) numerical variables - Equal frequency discretization\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Tutorial to prepare train and test set using dataPreparation: https://cran.r-project.org/web/packages/dataPreparation/vignettes/train_test_prep.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable discretizing on a numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>$age</strong> = <ol class=list-inline>\n",
       "\t<li>-Inf</li>\n",
       "\t<li>31</li>\n",
       "\t<li>35</li>\n",
       "\t<li>41</li>\n",
       "\t<li>50</li>\n",
       "\t<li>Inf</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\textbf{\\$age} = \\begin{enumerate*}\n",
       "\\item -Inf\n",
       "\\item 31\n",
       "\\item 35\n",
       "\\item 41\n",
       "\\item 50\n",
       "\\item Inf\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**$age** = 1. -Inf\n",
       "2. 31\n",
       "3. 35\n",
       "4. 41\n",
       "5. 50\n",
       "6. Inf\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$age\n",
       "[1] -Inf   31   35   41   50  Inf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the discretization\n",
    "bins <- build_bins(dataSet=train, cols=\"age\", n_bins=5, type=\"equal_freq\", verbose=F)\n",
    "\n",
    "# Print out to check\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>]-Inf, 31[</li>\n",
       "\t<li>[41, 50[</li>\n",
       "\t<li>[31, 35[</li>\n",
       "\t<li>[50, +Inf[</li>\n",
       "\t<li>[31, 35[</li>\n",
       "\t<li>[35, 41[</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'[31, 35['</li>\n",
       "\t\t<li>'[35, 41['</li>\n",
       "\t\t<li>'[41, 50['</li>\n",
       "\t\t<li>'[50, +Inf['</li>\n",
       "\t\t<li>']-Inf, 31['</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item {]}-Inf, 31{[}\n",
       "\\item {[}41, 50{[}\n",
       "\\item {[}31, 35{[}\n",
       "\\item {[}50, +Inf{[}\n",
       "\\item {[}31, 35{[}\n",
       "\\item {[}35, 41{[}\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '{[}31, 35{[}'\n",
       "\\item '{[}35, 41{[}'\n",
       "\\item '{[}41, 50{[}'\n",
       "\\item '{[}50, +Inf{[}'\n",
       "\\item '{]}-Inf, 31{[}'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. ]-Inf, 31[\n",
       "2. [41, 50[\n",
       "3. [31, 35[\n",
       "4. [50, +Inf[\n",
       "5. [31, 35[\n",
       "6. [35, 41[\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. '[31, 35['\n",
       "2. '[35, 41['\n",
       "3. '[41, 50['\n",
       "4. '[50, +Inf['\n",
       "5. ']-Inf, 31['\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] ]-Inf, 31[ [41, 50[   [31, 35[   [50, +Inf[ [31, 35[   [35, 41[  \n",
       "Levels: [31, 35[ [35, 41[ [41, 50[ [50, +Inf[ ]-Inf, 31["
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply to the data\n",
    "tmp <- fastDiscretization(dataSet=train, bins=bins, verbose=F)\n",
    "setDF(tmp); setDF(train)  # Convert data.table to data.frame\n",
    "head(tmp[, 'age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable discretizing for all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all numerical variables\n",
    "for (v in iv_num_list) {\n",
    "    \n",
    "    # Discretizing numerical variable on train data, n_bins=5\n",
    "    bins <- build_bins(dataSet=train, cols=v, n_bins=5, type=\"equal_freq\", verbose=F)\n",
    "    \n",
    "    # Apply the binning to the train, valid and test data\n",
    "    tmp <- fastDiscretization(dataSet=train, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(train)  # Convert data.table to data.frame\n",
    "    train[, paste0(v, '_freq_bin')] <- tmp[, v]  # Add new variable\n",
    "    \n",
    "    tmp <- fastDiscretization(dataSet=valid, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(valid)  # Convert data.table to data.frame\n",
    "    valid[, paste0(v, '_freq_bin')] <- tmp[, v]  # Add new variable\n",
    "    \n",
    "    tmp <- fastDiscretization(dataSet=test, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(test)  # Convert data.table to data.frame\n",
    "    test[, paste0(v, '_freq_bin')] <- tmp[, v]  # Add new variable\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    tmp <- fastDiscretization(dataSet=test_holdout, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(test_holdout)  # Convert data.table to data.frame\n",
    "    test_holdout[, paste0(v, '_freq_bin')] <- tmp[, v]  # Add new variable\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping (or discretizing) numerical variables - Equal width discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable discretizing on a numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>$age</strong> = <ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>32.8</li>\n",
       "\t<li>46.6</li>\n",
       "\t<li>60.4</li>\n",
       "\t<li>74.2</li>\n",
       "\t<li>88</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\textbf{\\$age} = \\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 32.8\n",
       "\\item 46.6\n",
       "\\item 60.4\n",
       "\\item 74.2\n",
       "\\item 88\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**$age** = 1. 19\n",
       "2. 32.8\n",
       "3. 46.6\n",
       "4. 60.4\n",
       "5. 74.2\n",
       "6. 88\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$age\n",
       "[1] 19.0 32.8 46.6 60.4 74.2 88.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the discretization\n",
    "bins <- build_bins(dataSet=train, cols=\"age\", n_bins=5, type=\"equal_width\", verbose=F)\n",
    "\n",
    "# Print out to check\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>[19, 32.8[</li>\n",
       "\t<li>[46.6, 60.4[</li>\n",
       "\t<li>[19, 32.8[</li>\n",
       "\t<li>[46.6, 60.4[</li>\n",
       "\t<li>[32.8, 46.6[</li>\n",
       "\t<li>[32.8, 46.6[</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'[19, 32.8['</li>\n",
       "\t\t<li>'[32.8, 46.6['</li>\n",
       "\t\t<li>'[46.6, 60.4['</li>\n",
       "\t\t<li>'[60.4, 74.2['</li>\n",
       "\t\t<li>'[74.2, 88]'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item {[}19, 32.8{[}\n",
       "\\item {[}46.6, 60.4{[}\n",
       "\\item {[}19, 32.8{[}\n",
       "\\item {[}46.6, 60.4{[}\n",
       "\\item {[}32.8, 46.6{[}\n",
       "\\item {[}32.8, 46.6{[}\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '{[}19, 32.8{[}'\n",
       "\\item '{[}32.8, 46.6{[}'\n",
       "\\item '{[}46.6, 60.4{[}'\n",
       "\\item '{[}60.4, 74.2{[}'\n",
       "\\item '{[}74.2, 88{]}'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. [19, 32.8[\n",
       "2. [46.6, 60.4[\n",
       "3. [19, 32.8[\n",
       "4. [46.6, 60.4[\n",
       "5. [32.8, 46.6[\n",
       "6. [32.8, 46.6[\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. '[19, 32.8['\n",
       "2. '[32.8, 46.6['\n",
       "3. '[46.6, 60.4['\n",
       "4. '[60.4, 74.2['\n",
       "5. '[74.2, 88]'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] [19, 32.8[   [46.6, 60.4[ [19, 32.8[   [46.6, 60.4[ [32.8, 46.6[\n",
       "[6] [32.8, 46.6[\n",
       "Levels: [19, 32.8[ [32.8, 46.6[ [46.6, 60.4[ [60.4, 74.2[ [74.2, 88]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply to the data\n",
    "tmp <- fastDiscretization(dataSet=train, bins=bins, verbose=F)\n",
    "setDF(tmp); setDF(train)  # Convert data.table to data.frame\n",
    "head(tmp[, 'age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable discretizing for all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all numerical variables\n",
    "for (v in iv_num_list) {\n",
    "    \n",
    "    # Discretizing numerical variable on train data, n_bins=5\n",
    "    bins <- build_bins(dataSet=train, cols=v, n_bins=5, type=\"equal_width\", verbose=F)\n",
    "    \n",
    "    # Apply the binning to the train, valid and test data\n",
    "    tmp <- fastDiscretization(dataSet=train, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(train)  # Convert data.table to data.frame\n",
    "    train[, paste0(v, '_width_bin')] <- tmp[, v]  # Add new variable\n",
    "    \n",
    "    tmp <- fastDiscretization(dataSet=valid, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(valid)  # Convert data.table to data.frame\n",
    "    valid[, paste0(v, '_width_bin')] <- tmp[, v]  # Add new variable\n",
    "    \n",
    "    tmp <- fastDiscretization(dataSet=test, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(test)  # Convert data.table to data.frame\n",
    "    test[, paste0(v, '_width_bin')] <- tmp[, v]  # Add new variable\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    tmp <- fastDiscretization(dataSet=test_holdout, bins=bins, verbose=F)\n",
    "    setDF(tmp); setDF(test_holdout)  # Convert data.table to data.frame\n",
    "    test_holdout[, paste0(v, '_width_bin')] <- tmp[, v]  # Add new variable\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Value representation\n",
    "\n",
    "- Dummy coding\n",
    "- Incidence replacement\n",
    "- Weight of evidence (WoE conversion)\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Coussement, K., Lessmann, S., & Verstraeten, G. (2017). A comparative analysis of data preparation algorithms for customer churn prediction: A case study in the telecommunication industry. Decision Support Systems, 95, 27-36.\n",
    "\n",
    "All about Categorical Variable Encoding: https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the updated list of categorical, boolean and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IV and DV list name\n",
    "# Dependent variable (DV)\n",
    "dv_list <- c('subscribe')\n",
    "# Independent variable (IV)\n",
    "iv_list <- setdiff(colnames(train), dv_list)  # Exclude the target variable\n",
    "iv_list <- setdiff(iv_list, 'client_id')  # Exclude the client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out categorical, boolean and numerical variable\n",
    "iv_cat_list <- c()  # List to store categorical variable\n",
    "iv_bool_list <- c()  # List to store boolean variable\n",
    "iv_num_list <- c()  # List to store numerical variable\n",
    "for (v in iv_list) {\n",
    "    if (class(train[, v]) == 'factor') {  # Factor == categorical variable\n",
    "        iv_cat_list <- c(iv_cat_list, v)\n",
    "    } else if (class(train[, v]) == 'logical') {  # Logical == boolean variable\n",
    "        iv_bool_list <- c(iv_bool_list, v)\n",
    "    } else {  # Non-factor + Non-logical == numerical variable\n",
    "        iv_num_list <- c(iv_num_list, v)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categorical variables to dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable representation on a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dummy encoding\n",
    "encoding <- build_encoding(dataSet=train, cols=\"job\", verbose=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>age_freq_bin</th><th scope=col>campaign_freq_bin</th><th scope=col>pdays_freq_bin</th><th scope=col>previous_freq_bin</th><th scope=col>emp.var.rate_freq_bin</th><th scope=col>cons.price.idx_freq_bin</th><th scope=col>cons.conf.idx_freq_bin</th><th scope=col>euribor3m_freq_bin</th><th scope=col>nr.employed_freq_bin</th><th scope=col>age_width_bin</th><th scope=col>...</th><th scope=col>job.blue.collar</th><th scope=col>job.entrepreneur</th><th scope=col>job.housemaid</th><th scope=col>job.management</th><th scope=col>job.retired</th><th scope=col>job.self.employed</th><th scope=col>job.services</th><th scope=col>job.student</th><th scope=col>job.technician</th><th scope=col>job.unemployed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>]-Inf, 31[      </td><td>[2, +Inf[       </td><td>[999, +Inf[     </td><td>[0, +Inf[       </td><td>[1.1, 1.4[      </td><td>[93.994, +Inf[  </td><td>[-36.4, +Inf[   </td><td>[4.153, 4.864[  </td><td>[5191, 5195.8[  </td><td>[19, 32.8[      </td><td>...             </td><td>FALSE           </td><td>FALSE           </td><td> TRUE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td></tr>\n",
       "\t<tr><td>[41, 50[        </td><td>[1, 2[          </td><td>[999, +Inf[     </td><td>[0, +Inf[       </td><td>[-0.1, 1.1[     </td><td>[92.963, 93.444[</td><td>[-42, -39.8[    </td><td>[4.153, 4.864[  </td><td>[5195.8, 5228.1[</td><td>[46.6, 60.4[    </td><td>...             </td><td> TRUE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td></tr>\n",
       "\t<tr><td>[31, 35[        </td><td>[2, +Inf[       </td><td>[999, +Inf[     </td><td>[0, +Inf[       </td><td>[-1.8, -0.1[    </td><td>]-Inf, 92.963[  </td><td>[-46.2, -42[    </td><td>[1.291, 4.153[  </td><td>[5099.1, 5191[  </td><td>[19, 32.8[      </td><td>...             </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td> TRUE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td></tr>\n",
       "\t<tr><td>[50, +Inf[      </td><td>[0, 1[          </td><td>[999, +Inf[     </td><td>[0, +Inf[       </td><td>[1.4, +Inf[     </td><td>[93.994, +Inf[  </td><td>[-42, -39.8[    </td><td>[4.864, 4.962[  </td><td>[5228.1, +Inf[  </td><td>[46.6, 60.4[    </td><td>...             </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td> TRUE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td></tr>\n",
       "\t<tr><td>[31, 35[        </td><td>[0, 1[          </td><td>[999, +Inf[     </td><td>[0, +Inf[       </td><td>[-0.1, 1.1[     </td><td>[92.963, 93.444[</td><td>[-42, -39.8[    </td><td>[4.153, 4.864[  </td><td>[5195.8, 5228.1[</td><td>[32.8, 46.6[    </td><td>...             </td><td> TRUE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td></tr>\n",
       "\t<tr><td>[35, 41[        </td><td>[0, 1[          </td><td>[999, +Inf[     </td><td>[0, +Inf[       </td><td>[1.4, +Inf[     </td><td>[93.444, 93.918[</td><td>[-36.4, +Inf[   </td><td>[4.962, +Inf[   </td><td>[5228.1, +Inf[  </td><td>[32.8, 46.6[    </td><td>...             </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td>FALSE           </td><td> TRUE           </td><td>FALSE           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllll}\n",
       " age\\_freq\\_bin & campaign\\_freq\\_bin & pdays\\_freq\\_bin & previous\\_freq\\_bin & emp.var.rate\\_freq\\_bin & cons.price.idx\\_freq\\_bin & cons.conf.idx\\_freq\\_bin & euribor3m\\_freq\\_bin & nr.employed\\_freq\\_bin & age\\_width\\_bin & ... & job.blue.collar & job.entrepreneur & job.housemaid & job.management & job.retired & job.self.employed & job.services & job.student & job.technician & job.unemployed\\\\\n",
       "\\hline\n",
       "\t {]}-Inf, 31{[}       & {[}2, +Inf{[}        & {[}999, +Inf{[}      & {[}0, +Inf{[}        & {[}1.1, 1.4{[}       & {[}93.994, +Inf{[}   & {[}-36.4, +Inf{[}    & {[}4.153, 4.864{[}   & {[}5191, 5195.8{[}   & {[}19, 32.8{[}       & ...                  & FALSE                & FALSE                &  TRUE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE               \\\\\n",
       "\t {[}41, 50{[}         & {[}1, 2{[}           & {[}999, +Inf{[}      & {[}0, +Inf{[}        & {[}-0.1, 1.1{[}      & {[}92.963, 93.444{[} & {[}-42, -39.8{[}     & {[}4.153, 4.864{[}   & {[}5195.8, 5228.1{[} & {[}46.6, 60.4{[}     & ...                  &  TRUE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE               \\\\\n",
       "\t {[}31, 35{[}         & {[}2, +Inf{[}        & {[}999, +Inf{[}      & {[}0, +Inf{[}        & {[}-1.8, -0.1{[}     & {]}-Inf, 92.963{[}   & {[}-46.2, -42{[}     & {[}1.291, 4.153{[}   & {[}5099.1, 5191{[}   & {[}19, 32.8{[}       & ...                  & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                &  TRUE                & FALSE                & FALSE                & FALSE                & FALSE               \\\\\n",
       "\t {[}50, +Inf{[}       & {[}0, 1{[}           & {[}999, +Inf{[}      & {[}0, +Inf{[}        & {[}1.4, +Inf{[}      & {[}93.994, +Inf{[}   & {[}-42, -39.8{[}     & {[}4.864, 4.962{[}   & {[}5228.1, +Inf{[}   & {[}46.6, 60.4{[}     & ...                  & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                &  TRUE                & FALSE                & FALSE                & FALSE                & FALSE               \\\\\n",
       "\t {[}31, 35{[}         & {[}0, 1{[}           & {[}999, +Inf{[}      & {[}0, +Inf{[}        & {[}-0.1, 1.1{[}      & {[}92.963, 93.444{[} & {[}-42, -39.8{[}     & {[}4.153, 4.864{[}   & {[}5195.8, 5228.1{[} & {[}32.8, 46.6{[}     & ...                  &  TRUE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE               \\\\\n",
       "\t {[}35, 41{[}         & {[}0, 1{[}           & {[}999, +Inf{[}      & {[}0, +Inf{[}        & {[}1.4, +Inf{[}      & {[}93.444, 93.918{[} & {[}-36.4, +Inf{[}    & {[}4.962, +Inf{[}    & {[}5228.1, +Inf{[}   & {[}32.8, 46.6{[}     & ...                  & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                & FALSE                &  TRUE                & FALSE               \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| age_freq_bin | campaign_freq_bin | pdays_freq_bin | previous_freq_bin | emp.var.rate_freq_bin | cons.price.idx_freq_bin | cons.conf.idx_freq_bin | euribor3m_freq_bin | nr.employed_freq_bin | age_width_bin | ... | job.blue.collar | job.entrepreneur | job.housemaid | job.management | job.retired | job.self.employed | job.services | job.student | job.technician | job.unemployed |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| ]-Inf, 31[       | [2, +Inf[        | [999, +Inf[      | [0, +Inf[        | [1.1, 1.4[       | [93.994, +Inf[   | [-36.4, +Inf[    | [4.153, 4.864[   | [5191, 5195.8[   | [19, 32.8[       | ...              | FALSE            | FALSE            |  TRUE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            |\n",
       "| [41, 50[         | [1, 2[           | [999, +Inf[      | [0, +Inf[        | [-0.1, 1.1[      | [92.963, 93.444[ | [-42, -39.8[     | [4.153, 4.864[   | [5195.8, 5228.1[ | [46.6, 60.4[     | ...              |  TRUE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            |\n",
       "| [31, 35[         | [2, +Inf[        | [999, +Inf[      | [0, +Inf[        | [-1.8, -0.1[     | ]-Inf, 92.963[   | [-46.2, -42[     | [1.291, 4.153[   | [5099.1, 5191[   | [19, 32.8[       | ...              | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            |  TRUE            | FALSE            | FALSE            | FALSE            | FALSE            |\n",
       "| [50, +Inf[       | [0, 1[           | [999, +Inf[      | [0, +Inf[        | [1.4, +Inf[      | [93.994, +Inf[   | [-42, -39.8[     | [4.864, 4.962[   | [5228.1, +Inf[   | [46.6, 60.4[     | ...              | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            |  TRUE            | FALSE            | FALSE            | FALSE            | FALSE            |\n",
       "| [31, 35[         | [0, 1[           | [999, +Inf[      | [0, +Inf[        | [-0.1, 1.1[      | [92.963, 93.444[ | [-42, -39.8[     | [4.153, 4.864[   | [5195.8, 5228.1[ | [32.8, 46.6[     | ...              |  TRUE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            |\n",
       "| [35, 41[         | [0, 1[           | [999, +Inf[      | [0, +Inf[        | [1.4, +Inf[      | [93.444, 93.918[ | [-36.4, +Inf[    | [4.962, +Inf[    | [5228.1, +Inf[   | [32.8, 46.6[     | ...              | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            | FALSE            |  TRUE            | FALSE            |\n",
       "\n"
      ],
      "text/plain": [
       "  age_freq_bin campaign_freq_bin pdays_freq_bin previous_freq_bin\n",
       "1 ]-Inf, 31[   [2, +Inf[         [999, +Inf[    [0, +Inf[        \n",
       "2 [41, 50[     [1, 2[            [999, +Inf[    [0, +Inf[        \n",
       "3 [31, 35[     [2, +Inf[         [999, +Inf[    [0, +Inf[        \n",
       "4 [50, +Inf[   [0, 1[            [999, +Inf[    [0, +Inf[        \n",
       "5 [31, 35[     [0, 1[            [999, +Inf[    [0, +Inf[        \n",
       "6 [35, 41[     [0, 1[            [999, +Inf[    [0, +Inf[        \n",
       "  emp.var.rate_freq_bin cons.price.idx_freq_bin cons.conf.idx_freq_bin\n",
       "1 [1.1, 1.4[            [93.994, +Inf[          [-36.4, +Inf[         \n",
       "2 [-0.1, 1.1[           [92.963, 93.444[        [-42, -39.8[          \n",
       "3 [-1.8, -0.1[          ]-Inf, 92.963[          [-46.2, -42[          \n",
       "4 [1.4, +Inf[           [93.994, +Inf[          [-42, -39.8[          \n",
       "5 [-0.1, 1.1[           [92.963, 93.444[        [-42, -39.8[          \n",
       "6 [1.4, +Inf[           [93.444, 93.918[        [-36.4, +Inf[         \n",
       "  euribor3m_freq_bin nr.employed_freq_bin age_width_bin ... job.blue.collar\n",
       "1 [4.153, 4.864[     [5191, 5195.8[       [19, 32.8[    ... FALSE          \n",
       "2 [4.153, 4.864[     [5195.8, 5228.1[     [46.6, 60.4[  ...  TRUE          \n",
       "3 [1.291, 4.153[     [5099.1, 5191[       [19, 32.8[    ... FALSE          \n",
       "4 [4.864, 4.962[     [5228.1, +Inf[       [46.6, 60.4[  ... FALSE          \n",
       "5 [4.153, 4.864[     [5195.8, 5228.1[     [32.8, 46.6[  ...  TRUE          \n",
       "6 [4.962, +Inf[      [5228.1, +Inf[       [32.8, 46.6[  ... FALSE          \n",
       "  job.entrepreneur job.housemaid job.management job.retired job.self.employed\n",
       "1 FALSE             TRUE         FALSE          FALSE       FALSE            \n",
       "2 FALSE            FALSE         FALSE          FALSE       FALSE            \n",
       "3 FALSE            FALSE         FALSE          FALSE        TRUE            \n",
       "4 FALSE            FALSE         FALSE          FALSE        TRUE            \n",
       "5 FALSE            FALSE         FALSE          FALSE       FALSE            \n",
       "6 FALSE            FALSE         FALSE          FALSE       FALSE            \n",
       "  job.services job.student job.technician job.unemployed\n",
       "1 FALSE        FALSE       FALSE          FALSE         \n",
       "2 FALSE        FALSE       FALSE          FALSE         \n",
       "3 FALSE        FALSE       FALSE          FALSE         \n",
       "4 FALSE        FALSE       FALSE          FALSE         \n",
       "5 FALSE        FALSE       FALSE          FALSE         \n",
       "6 FALSE        FALSE        TRUE          FALSE         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform the categorical variable\n",
    "tmp <- one_hot_encoder(dataSet=train, encoding=encoding, type='logical', drop=F, verbose=F)\n",
    "setDF(tmp)\n",
    "tmp <- tmp[, -ncol(tmp)]\n",
    "head(tmp[, 84:ncol(tmp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable representation for all categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all categorical variables\n",
    "for (v in iv_cat_list) {\n",
    "    \n",
    "    # Representing categorical variable on train data\n",
    "    encoding <- build_encoding(dataSet=train, cols=v, verbose=F)\n",
    "    \n",
    "    # Apply the binning to the train, valid and test data\n",
    "    train <- one_hot_encoder(dataSet=train, encoding=encoding, type='logical', drop=F, verbose=F)\n",
    "    setDF(train)\n",
    "    train <- train[, -ncol(train)]  # Drop the last dummy column\n",
    "    \n",
    "    valid <- one_hot_encoder(dataSet=valid, encoding=encoding, type='logical', drop=F, verbose=F)\n",
    "    setDF(valid)\n",
    "    valid <- valid[, -ncol(valid)]  # Drop the last dummy column\n",
    "    \n",
    "    test <- one_hot_encoder(dataSet=test, encoding=encoding, type='logical', drop=F, verbose=F)\n",
    "    setDF(test)\n",
    "    test <- test[, -ncol(test)]  # Drop the last dummy column\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    test_holdout <- one_hot_encoder(dataSet=test_holdout, encoding=encoding, type='logical', drop=F, verbose=F)\n",
    "    setDF(test_holdout)\n",
    "    test_holdout <- test_holdout[, -ncol(test_holdout)]  # Drop the last dummy column\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent categorical variables using incidence of target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable representation on a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>job</th><th scope=col>job_incidence</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>admin.</th><td>admin.       </td><td>0.12975207   </td></tr>\n",
       "\t<tr><th scope=row>blue-collar</th><td>blue-collar  </td><td>0.08388313   </td></tr>\n",
       "\t<tr><th scope=row>entrepreneur</th><td>entrepreneur </td><td>0.10695187   </td></tr>\n",
       "\t<tr><th scope=row>housemaid</th><td>housemaid    </td><td>0.10937500   </td></tr>\n",
       "\t<tr><th scope=row>management</th><td>management   </td><td>0.11936340   </td></tr>\n",
       "\t<tr><th scope=row>retired</th><td>retired      </td><td>0.24778761   </td></tr>\n",
       "\t<tr><th scope=row>self-employed</th><td>self-employed</td><td>0.13888889   </td></tr>\n",
       "\t<tr><th scope=row>services</th><td>services     </td><td>0.07578947   </td></tr>\n",
       "\t<tr><th scope=row>student</th><td>student      </td><td>0.31775701   </td></tr>\n",
       "\t<tr><th scope=row>technician</th><td>technician   </td><td>0.09506173   </td></tr>\n",
       "\t<tr><th scope=row>unemployed</th><td>unemployed   </td><td>0.15454545   </td></tr>\n",
       "\t<tr><th scope=row>unknown</th><td>unknown      </td><td>0.03448276   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & job & job\\_incidence\\\\\n",
       "\\hline\n",
       "\tadmin. & admin.        & 0.12975207   \\\\\n",
       "\tblue-collar & blue-collar   & 0.08388313   \\\\\n",
       "\tentrepreneur & entrepreneur  & 0.10695187   \\\\\n",
       "\thousemaid & housemaid     & 0.10937500   \\\\\n",
       "\tmanagement & management    & 0.11936340   \\\\\n",
       "\tretired & retired       & 0.24778761   \\\\\n",
       "\tself-employed & self-employed & 0.13888889   \\\\\n",
       "\tservices & services      & 0.07578947   \\\\\n",
       "\tstudent & student       & 0.31775701   \\\\\n",
       "\ttechnician & technician    & 0.09506173   \\\\\n",
       "\tunemployed & unemployed    & 0.15454545   \\\\\n",
       "\tunknown & unknown       & 0.03448276   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | job | job_incidence |\n",
       "|---|---|---|\n",
       "| admin. | admin.        | 0.12975207    |\n",
       "| blue-collar | blue-collar   | 0.08388313    |\n",
       "| entrepreneur | entrepreneur  | 0.10695187    |\n",
       "| housemaid | housemaid     | 0.10937500    |\n",
       "| management | management    | 0.11936340    |\n",
       "| retired | retired       | 0.24778761    |\n",
       "| self-employed | self-employed | 0.13888889    |\n",
       "| services | services      | 0.07578947    |\n",
       "| student | student       | 0.31775701    |\n",
       "| technician | technician    | 0.09506173    |\n",
       "| unemployed | unemployed    | 0.15454545    |\n",
       "| unknown | unknown       | 0.03448276    |\n",
       "\n"
      ],
      "text/plain": [
       "              job           job_incidence\n",
       "admin.        admin.        0.12975207   \n",
       "blue-collar   blue-collar   0.08388313   \n",
       "entrepreneur  entrepreneur  0.10695187   \n",
       "housemaid     housemaid     0.10937500   \n",
       "management    management    0.11936340   \n",
       "retired       retired       0.24778761   \n",
       "self-employed self-employed 0.13888889   \n",
       "services      services      0.07578947   \n",
       "student       student       0.31775701   \n",
       "technician    technician    0.09506173   \n",
       "unemployed    unemployed    0.15454545   \n",
       "unknown       unknown       0.03448276   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the incidence rates per category of a variable\n",
    "tb <- table(train$job, train$subscribe)\n",
    "incidence_map <- data.frame('v1'=rownames(tb), 'v2'=tb[, '1'] / (tb[, '0'] + tb[, '1']))\n",
    "colnames(incidence_map) <- c('job', 'job_incidence')\n",
    "incidence_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>job</th><th scope=col>job_incidence</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>housemaid    </td><td>0.10937500   </td></tr>\n",
       "\t<tr><td>blue-collar  </td><td>0.08388313   </td></tr>\n",
       "\t<tr><td>self-employed</td><td>0.13888889   </td></tr>\n",
       "\t<tr><td>self-employed</td><td>0.13888889   </td></tr>\n",
       "\t<tr><td>blue-collar  </td><td>0.08388313   </td></tr>\n",
       "\t<tr><td>technician   </td><td>0.09506173   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " job & job\\_incidence\\\\\n",
       "\\hline\n",
       "\t housemaid     & 0.10937500   \\\\\n",
       "\t blue-collar   & 0.08388313   \\\\\n",
       "\t self-employed & 0.13888889   \\\\\n",
       "\t self-employed & 0.13888889   \\\\\n",
       "\t blue-collar   & 0.08388313   \\\\\n",
       "\t technician    & 0.09506173   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| job | job_incidence |\n",
       "|---|---|\n",
       "| housemaid     | 0.10937500    |\n",
       "| blue-collar   | 0.08388313    |\n",
       "| self-employed | 0.13888889    |\n",
       "| self-employed | 0.13888889    |\n",
       "| blue-collar   | 0.08388313    |\n",
       "| technician    | 0.09506173    |\n",
       "\n"
      ],
      "text/plain": [
       "  job           job_incidence\n",
       "1 housemaid     0.10937500   \n",
       "2 blue-collar   0.08388313   \n",
       "3 self-employed 0.13888889   \n",
       "4 self-employed 0.13888889   \n",
       "5 blue-collar   0.08388313   \n",
       "6 technician    0.09506173   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the categories with incidences\n",
    "tmp <- plyr::join(x=train, y=incidence_map, by='job', type=\"left\", match=\"all\")  # Left join\n",
    "head(tmp[, c('job', 'job_incidence')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable representation for all categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all categorical variables\n",
    "for (v in iv_cat_list) {\n",
    "    \n",
    "    # Find the incidence rates per category of a variable\n",
    "    tb <- table(train[, v], train[, 'subscribe'])\n",
    "    incidence_map <- data.frame('v1'=rownames(tb), 'v2'=tb[, '1'] / (tb[, '0'] + tb[, '1']))\n",
    "    colnames(incidence_map) <- c(v, paste0(v, '_incidence'))  # Rename the columns to join\n",
    "    \n",
    "    # Apply the variable representation to the train, valid and test data\n",
    "    train <- plyr::join(x=train, y=incidence_map, by=v, type=\"left\", match=\"all\")\n",
    "    valid <- plyr::join(x=valid, y=incidence_map, by=v, type=\"left\", match=\"all\")\n",
    "    test <- plyr::join(x=test, y=incidence_map, by=v, type=\"left\", match=\"all\")\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    test_holdout <- plyr::join(x=test_holdout, y=incidence_map, by=v, type=\"left\", match=\"all\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent categorical variables using weight-of-evidence conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the variable representation on a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>job</th><th scope=col>job_woe</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>admin.</th><td>admin.       </td><td>-1.9031527   </td></tr>\n",
       "\t<tr><th scope=row>blue-collar</th><td>blue-collar  </td><td>-2.3907194   </td></tr>\n",
       "\t<tr><th scope=row>entrepreneur</th><td>entrepreneur </td><td>-2.1222615   </td></tr>\n",
       "\t<tr><th scope=row>housemaid</th><td>housemaid    </td><td>-2.0971411   </td></tr>\n",
       "\t<tr><th scope=row>management</th><td>management   </td><td>-1.9984725   </td></tr>\n",
       "\t<tr><th scope=row>retired</th><td>retired      </td><td>-1.1104467   </td></tr>\n",
       "\t<tr><th scope=row>self-employed</th><td>self-employed</td><td>-1.8245493   </td></tr>\n",
       "\t<tr><th scope=row>services</th><td>services     </td><td>-2.5009805   </td></tr>\n",
       "\t<tr><th scope=row>student</th><td>student      </td><td>-0.7640989   </td></tr>\n",
       "\t<tr><th scope=row>technician</th><td>technician   </td><td>-2.2533403   </td></tr>\n",
       "\t<tr><th scope=row>unemployed</th><td>unemployed   </td><td>-1.6993861   </td></tr>\n",
       "\t<tr><th scope=row>unknown</th><td>unknown      </td><td>-3.3322045   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & job & job\\_woe\\\\\n",
       "\\hline\n",
       "\tadmin. & admin.        & -1.9031527   \\\\\n",
       "\tblue-collar & blue-collar   & -2.3907194   \\\\\n",
       "\tentrepreneur & entrepreneur  & -2.1222615   \\\\\n",
       "\thousemaid & housemaid     & -2.0971411   \\\\\n",
       "\tmanagement & management    & -1.9984725   \\\\\n",
       "\tretired & retired       & -1.1104467   \\\\\n",
       "\tself-employed & self-employed & -1.8245493   \\\\\n",
       "\tservices & services      & -2.5009805   \\\\\n",
       "\tstudent & student       & -0.7640989   \\\\\n",
       "\ttechnician & technician    & -2.2533403   \\\\\n",
       "\tunemployed & unemployed    & -1.6993861   \\\\\n",
       "\tunknown & unknown       & -3.3322045   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | job | job_woe |\n",
       "|---|---|---|\n",
       "| admin. | admin.        | -1.9031527    |\n",
       "| blue-collar | blue-collar   | -2.3907194    |\n",
       "| entrepreneur | entrepreneur  | -2.1222615    |\n",
       "| housemaid | housemaid     | -2.0971411    |\n",
       "| management | management    | -1.9984725    |\n",
       "| retired | retired       | -1.1104467    |\n",
       "| self-employed | self-employed | -1.8245493    |\n",
       "| services | services      | -2.5009805    |\n",
       "| student | student       | -0.7640989    |\n",
       "| technician | technician    | -2.2533403    |\n",
       "| unemployed | unemployed    | -1.6993861    |\n",
       "| unknown | unknown       | -3.3322045    |\n",
       "\n"
      ],
      "text/plain": [
       "              job           job_woe   \n",
       "admin.        admin.        -1.9031527\n",
       "blue-collar   blue-collar   -2.3907194\n",
       "entrepreneur  entrepreneur  -2.1222615\n",
       "housemaid     housemaid     -2.0971411\n",
       "management    management    -1.9984725\n",
       "retired       retired       -1.1104467\n",
       "self-employed self-employed -1.8245493\n",
       "services      services      -2.5009805\n",
       "student       student       -0.7640989\n",
       "technician    technician    -2.2533403\n",
       "unemployed    unemployed    -1.6993861\n",
       "unknown       unknown       -3.3322045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the WOE per category of a variable\n",
    "tb <- table(train$job, train$subscribe)\n",
    "woe_map <- data.frame('v1'=rownames(tb), 'v2'=log(tb[, '1'] / tb[, '0']))\n",
    "colnames(woe_map) <- c('job', 'job_woe')\n",
    "woe_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>job</th><th scope=col>job_woe</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>housemaid    </td><td>-2.097141    </td></tr>\n",
       "\t<tr><td>blue-collar  </td><td>-2.390719    </td></tr>\n",
       "\t<tr><td>self-employed</td><td>-1.824549    </td></tr>\n",
       "\t<tr><td>self-employed</td><td>-1.824549    </td></tr>\n",
       "\t<tr><td>blue-collar  </td><td>-2.390719    </td></tr>\n",
       "\t<tr><td>technician   </td><td>-2.253340    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " job & job\\_woe\\\\\n",
       "\\hline\n",
       "\t housemaid     & -2.097141    \\\\\n",
       "\t blue-collar   & -2.390719    \\\\\n",
       "\t self-employed & -1.824549    \\\\\n",
       "\t self-employed & -1.824549    \\\\\n",
       "\t blue-collar   & -2.390719    \\\\\n",
       "\t technician    & -2.253340    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| job | job_woe |\n",
       "|---|---|\n",
       "| housemaid     | -2.097141     |\n",
       "| blue-collar   | -2.390719     |\n",
       "| self-employed | -1.824549     |\n",
       "| self-employed | -1.824549     |\n",
       "| blue-collar   | -2.390719     |\n",
       "| technician    | -2.253340     |\n",
       "\n"
      ],
      "text/plain": [
       "  job           job_woe  \n",
       "1 housemaid     -2.097141\n",
       "2 blue-collar   -2.390719\n",
       "3 self-employed -1.824549\n",
       "4 self-employed -1.824549\n",
       "5 blue-collar   -2.390719\n",
       "6 technician    -2.253340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the categories with WOE\n",
    "tmp <- plyr::join(x=train, y=woe_map, by='job', type=\"left\", match=\"all\")  # Left join\n",
    "head(tmp[, c('job', 'job_woe')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the variable representation for all categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all categorical variables\n",
    "for (v in iv_cat_list) {\n",
    "    \n",
    "    # Find the incidence rates per category of a variable\n",
    "    tb <- table(train[, v], train[, 'subscribe'])\n",
    "    woe_map <- data.frame('v1'=rownames(tb), 'v2'=log(tb[, '1'] / tb[, '0']))\n",
    "    colnames(woe_map) <- c(v, paste0(v, '_woe'))  # Rename the columns to join\n",
    "    \n",
    "    # Apply the variable representation to the train, valid and test data\n",
    "    train <- plyr::join(x=train, y=woe_map, by=v, type=\"left\", match=\"all\")\n",
    "    valid <- plyr::join(x=valid, y=woe_map, by=v, type=\"left\", match=\"all\")\n",
    "    test <- plyr::join(x=test, y=woe_map, by=v, type=\"left\", match=\"all\")\n",
    "    \n",
    "    # Apply the binning to the test (holdout) data\n",
    "    test_holdout <- plyr::join(x=test_holdout, y=woe_map, by=v, type=\"left\", match=\"all\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Others variable transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transformation numerical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the variable age on train and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'age_log'] <- log(train[, 'age'])\n",
    "valid[, 'age_log'] <- log(valid[, 'age'])\n",
    "test[, 'age_log'] <- log(test[, 'age'])\n",
    "# Test (holdout)\n",
    "test_holdout[, 'age_log'] <- log(test_holdout[, 'age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize numerical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the variable age on train and test (holdout)\n",
    "# Train, valid, test\n",
    "train[, 'age_scaled'] <- scale(train[, 'age'], center=T, scale=T)  # sd = 1, mean = 0\n",
    "valid[, 'age_scaled'] <- scale(valid[, 'age'], center=T, scale=T)  # sd = 1, mean = 0\n",
    "test[, 'age_scaled'] <- scale(test[, 'age'], center=T, scale=T)  # sd = 1, mean = 0\n",
    "# Test (holdout)\n",
    "test_holdout[, 'age_scaled'] <- scale(test_holdout[, 'age'], center=T, scale=T)  # sd = 1, mean = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Variable selection\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Verbeke, W., Dejaeger, K., Martens, D., Hur, J., & Baesens, B. (2012). New insights into churn prediction in the telecommunication sector: A profit driven data mining approach. European Journal of Operational Research, 218(1), 211-229.\n",
    "\n",
    "Boruta: https://www.datacamp.com/community/tutorials/feature-selection-R-boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the updated list of categorical, boolean and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IV and DV list name\n",
    "# Dependent variable (DV)\n",
    "dv_list <- c('subscribe')\n",
    "# Independent variable (IV)\n",
    "iv_list <- setdiff(colnames(train), dv_list)  # Exclude the target variable\n",
    "iv_list <- setdiff(iv_list, 'client_id')  # Exclude the client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out categorical, boolean and numerical variable\n",
    "iv_cat_list <- c()  # List to store categorical variable\n",
    "iv_bool_list <- c()  # List to store boolean variable\n",
    "iv_num_list <- c()  # List to store numerical variable\n",
    "for (v in iv_list) {\n",
    "    if (class(train[, v]) == 'factor') {  # Factor == categorical variable\n",
    "        iv_cat_list <- c(iv_cat_list, v)\n",
    "    } else if (class(train[, v]) == 'logical') {  # Logical == boolean variable\n",
    "        iv_bool_list <- c(iv_bool_list, v)\n",
    "    } else {  # Non-factor + Non-logical == numerical variable\n",
    "        iv_num_list <- c(iv_num_list, v)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1. Variable correcting and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check and correct +/-Inf values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "21"
      ],
      "text/latex": [
       "21"
      ],
      "text/markdown": [
       "21"
      ],
      "text/plain": [
       "[1] 21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "18"
      ],
      "text/latex": [
       "18"
      ],
      "text/markdown": [
       "18"
      ],
      "text/plain": [
       "[1] 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing value\n",
    "# Train, valid, test\n",
    "sum(apply(sapply(train, is.infinite), 2, sum))\n",
    "sum(apply(sapply(valid, is.infinite), 2, sum))\n",
    "sum(apply(sapply(test, is.infinite), 2, sum))\n",
    "# Test (holdout)\n",
    "sum(apply(sapply(test_holdout, is.infinite), 2, sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute +/-Inf value by NA\n",
    "# Train, valid, test\n",
    "train[sapply(train, is.infinite)] <- NA\n",
    "valid[sapply(valid, is.infinite)] <- NA\n",
    "test[sapply(test, is.infinite)] <- NA\n",
    "# Test (holdout)\n",
    "test_holdout[sapply(test_holdout, is.infinite)] <- NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check and correct missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "21"
      ],
      "text/latex": [
       "21"
      ],
      "text/markdown": [
       "21"
      ],
      "text/plain": [
       "[1] 21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "20"
      ],
      "text/latex": [
       "20"
      ],
      "text/markdown": [
       "20"
      ],
      "text/plain": [
       "[1] 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing value\n",
    "# Train, valid, test\n",
    "sum(apply(is.na(train), 2, sum))\n",
    "sum(apply(is.na(valid), 2, sum))\n",
    "sum(apply(is.na(test), 2, sum))\n",
    "# Test (holdout)\n",
    "sum(apply(is.na(test_holdout), 2, sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing value in numerical variable by mean\n",
    "for (v in iv_num_list) {\n",
    "    # Train, valid, test\n",
    "    train[is.na(train[, v]), v] <- mean(train[, v], na.rm=T)\n",
    "    valid[is.na(valid[, v]), v] <- mean(valid[, v], na.rm=T)\n",
    "    test[is.na(test[, v]), v] <- mean(test[, v], na.rm=T)\n",
    "    \n",
    "    # Test (holdout)\n",
    "    test_holdout[is.na(test_holdout[, v]), v] <- mean(test_holdout[, v], na.rm=T)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop categorical variables (all were processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (v in iv_cat_list) {\n",
    "    # Train, valid, test\n",
    "    train[, v] <- NULL\n",
    "    valid[, v] <- NULL\n",
    "    test[, v] <- NULL\n",
    "    \n",
    "    # Test (holdout)\n",
    "    test_holdout[, v] <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert boolean variable to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean to int\n",
    "for (v in iv_bool_list) {\n",
    "    # Train, valid, test\n",
    "    train[, v] <- as.integer(train[, v])\n",
    "    valid[, v] <- as.integer(valid[, v])\n",
    "    test[, v] <- as.integer(test[, v])\n",
    "    \n",
    "    # Test (holdout)\n",
    "    test_holdout[, v] <- as.integer(test_holdout[, v])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop constant variable (i.e. variance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'woe.pdays.binned'</li>\n",
       "\t<li>'pdays.binned_incidence'</li>\n",
       "\t<li>'previous_freq_bin_incidence'</li>\n",
       "\t<li>'pdays.binned_woe'</li>\n",
       "\t<li>'previous_freq_bin_woe'</li>\n",
       "\t<li>'pdays_ge_median'</li>\n",
       "\t<li>'pdays.binned...Inf.999.'</li>\n",
       "\t<li>'pdays.binned..999. Inf.'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'woe.pdays.binned'\n",
       "\\item 'pdays.binned\\_incidence'\n",
       "\\item 'previous\\_freq\\_bin\\_incidence'\n",
       "\\item 'pdays.binned\\_woe'\n",
       "\\item 'previous\\_freq\\_bin\\_woe'\n",
       "\\item 'pdays\\_ge\\_median'\n",
       "\\item 'pdays.binned...Inf.999.'\n",
       "\\item 'pdays.binned..999. Inf.'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'woe.pdays.binned'\n",
       "2. 'pdays.binned_incidence'\n",
       "3. 'previous_freq_bin_incidence'\n",
       "4. 'pdays.binned_woe'\n",
       "5. 'previous_freq_bin_woe'\n",
       "6. 'pdays_ge_median'\n",
       "7. 'pdays.binned...Inf.999.'\n",
       "8. 'pdays.binned..999. Inf.'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"woe.pdays.binned\"            \"pdays.binned_incidence\"     \n",
       "[3] \"previous_freq_bin_incidence\" \"pdays.binned_woe\"           \n",
       "[5] \"previous_freq_bin_woe\"       \"pdays_ge_median\"            \n",
       "[7] \"pdays.binned...Inf.999.\"     \"pdays.binned..999. Inf.\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the constant variable\n",
    "var_list <- c()\n",
    "for (v in c(iv_num_list, iv_bool_list)) {\n",
    "    var_list <- c(var_list, var(train[, v], na.rm=T))\n",
    "}\n",
    "constant_var <- c(iv_num_list, iv_bool_list)[var_list == 0]\n",
    "constant_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the constant variable\n",
    "for (v in constant_var) {\n",
    "    # Train, valid, test\n",
    "    train[, v] <- NULL\n",
    "    valid[, v] <- NULL\n",
    "    test[, v] <- NULL\n",
    "    \n",
    "    # Test (holdout)\n",
    "    test_holdout[, v] <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library('caret')\n",
    "#Identifying numeric variables\n",
    "#numericData <- train[sapply(train[, -c(train$client_id, train$subscribe)], is.numeric)]\n",
    "# Calculate correlation matrix\n",
    "#descrCor <- cor(numericData)\n",
    "# find attributes that are highly corrected\n",
    "#highlyCorrelated <- findCorrelation(descrCor, cutoff=0.7)\n",
    "\n",
    "#highlyCorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove highly correlated variables\n",
    "# Train\n",
    "#train2 = train[,-c(highlyCorrelated)]\n",
    "# Valid\n",
    "#valid2 = valid[,-c(highlyCorrelated)]\n",
    "# Test\n",
    "#test2 = test[,-c(highlyCorrelated)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying stepwise regression to reduce features \n",
    "# Step 1: Define base intercept only model\n",
    "#base.mod <- lm(subscribe ~ 1 , data=train[,-1])  \n",
    "#\n",
    "## Step 2: Full model with all predictors\n",
    "#all.mod <- lm(subscribe ~ . , data= train[,-1]) \n",
    "#\n",
    "## Step 3: Perform step-wise algorithm. direction='both' implies both forward and backward stepwise\n",
    "#stepMod <- step(base.mod, scope = list(lower = base.mod, upper = all.mod), direction = \"both\", trace = 0, steps = 2000)  \n",
    "#\n",
    "## Step 4: Get the shortlisted variable.\n",
    "#shortlistedVars <- names(unlist(stepMod[[1]])) \n",
    "#shortlistedVars <- shortlistedVars[!shortlistedVars %in% \"(Intercept)\"] # remove intercept\n",
    "#\n",
    "## Show\n",
    "#print(shortlistedVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2. Variable selection: Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "FisherScore <- function(basetable, depvar, IV_list) {\n",
    "  \"\n",
    "  This function calculate the Fisher score of a variable.\n",
    "  \n",
    "  Ref:\n",
    "  ---\n",
    "  Verbeke, W., Dejaeger, K., Martens, D., Hur, J., & Baesens, B. (2012). New insights into churn prediction in the telecommunication sector: A profit driven data mining approach. European Journal of Operational Research, 218(1), 211-229.\n",
    "  \"\n",
    "  \n",
    "  # Get the unique values of dependent variable\n",
    "  DV <- unique(basetable[, depvar])\n",
    "  \n",
    "  IV_FisherScore <- c()\n",
    "  \n",
    "  for (v in IV_list) {\n",
    "    fs <- abs((mean(basetable[which(basetable[, depvar]==DV[1]), v]) - mean(basetable[which(basetable[, depvar]==DV[2]), v]))) /\n",
    "      sqrt((var(basetable[which(basetable[, depvar]==DV[1]), v]) + var(basetable[which(basetable[, depvar]==DV[2]), v])))\n",
    "    IV_FisherScore <- c(IV_FisherScore, fs)\n",
    "  }\n",
    "  \n",
    "  return(data.frame(IV=IV_list, fisher_score=IV_FisherScore))\n",
    "}\n",
    "\n",
    "varSelectionFisher <- function(basetable, depvar, IV_list, num_select=20) {\n",
    "  \"\n",
    "  This function will calculate the Fisher score for all IVs and select the best\n",
    "  top IVs.\n",
    "\n",
    "  Assumption: all variables of input dataset are converted into numeric type.\n",
    "  \"\n",
    "  \n",
    "  fs <- FisherScore(basetable, depvar, IV_list)  # Calculate Fisher Score for all IVs\n",
    "  num_select <- min(num_select, ncol(basetable))  # Top N IVs to be selected\n",
    "  return(as.vector(fs[order(fs$fisher_score, decreasing=T), ][1:num_select, 'IV']))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>IV</th><th scope=col>fisher_score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>age           </td><td>0.0519747     </td></tr>\n",
       "\t<tr><td>campaign      </td><td>0.1452536     </td></tr>\n",
       "\t<tr><td>pdays         </td><td>0.4518390     </td></tr>\n",
       "\t<tr><td>previous      </td><td>0.3604852     </td></tr>\n",
       "\t<tr><td>emp.var.rate  </td><td>0.6710263     </td></tr>\n",
       "\t<tr><td>cons.price.idx</td><td>0.3166176     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " IV & fisher\\_score\\\\\n",
       "\\hline\n",
       "\t age            & 0.0519747     \\\\\n",
       "\t campaign       & 0.1452536     \\\\\n",
       "\t pdays          & 0.4518390     \\\\\n",
       "\t previous       & 0.3604852     \\\\\n",
       "\t emp.var.rate   & 0.6710263     \\\\\n",
       "\t cons.price.idx & 0.3166176     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| IV | fisher_score |\n",
       "|---|---|\n",
       "| age            | 0.0519747      |\n",
       "| campaign       | 0.1452536      |\n",
       "| pdays          | 0.4518390      |\n",
       "| previous       | 0.3604852      |\n",
       "| emp.var.rate   | 0.6710263      |\n",
       "| cons.price.idx | 0.3166176      |\n",
       "\n"
      ],
      "text/plain": [
       "  IV             fisher_score\n",
       "1 age            0.0519747   \n",
       "2 campaign       0.1452536   \n",
       "3 pdays          0.4518390   \n",
       "4 previous       0.3604852   \n",
       "5 emp.var.rate   0.6710263   \n",
       "6 cons.price.idx 0.3166176   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Fisher Score for all variable\n",
    "# Get the IV and DV list\n",
    "dv_list <- c('subscribe')  # DV list\n",
    "iv_list <- setdiff(names(train), dv_list)  # IV list excluded DV\n",
    "iv_list <- setdiff(iv_list, 'client_id')  # Excluded the client_id\n",
    "fs <- FisherScore(train, dv_list, iv_list)\n",
    "head(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'nr.employed_freq_bin_woe'</li>\n",
       "\t<li>'woe.nr.employed.binned'</li>\n",
       "\t<li>'nr.employed.binned_woe'</li>\n",
       "\t<li>'nr.employed_freq_bin_incidence'</li>\n",
       "\t<li>'nr.employed.binned_incidence'</li>\n",
       "\t<li>'nr.employed_width_bin_woe'</li>\n",
       "\t<li>'nr.employed'</li>\n",
       "\t<li>'euribor3m.binned_woe'</li>\n",
       "\t<li>'woe.euribor3m.binned'</li>\n",
       "\t<li>'emp.var.rate_width_bin_woe'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'nr.employed\\_freq\\_bin\\_woe'\n",
       "\\item 'woe.nr.employed.binned'\n",
       "\\item 'nr.employed.binned\\_woe'\n",
       "\\item 'nr.employed\\_freq\\_bin\\_incidence'\n",
       "\\item 'nr.employed.binned\\_incidence'\n",
       "\\item 'nr.employed\\_width\\_bin\\_woe'\n",
       "\\item 'nr.employed'\n",
       "\\item 'euribor3m.binned\\_woe'\n",
       "\\item 'woe.euribor3m.binned'\n",
       "\\item 'emp.var.rate\\_width\\_bin\\_woe'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'nr.employed_freq_bin_woe'\n",
       "2. 'woe.nr.employed.binned'\n",
       "3. 'nr.employed.binned_woe'\n",
       "4. 'nr.employed_freq_bin_incidence'\n",
       "5. 'nr.employed.binned_incidence'\n",
       "6. 'nr.employed_width_bin_woe'\n",
       "7. 'nr.employed'\n",
       "8. 'euribor3m.binned_woe'\n",
       "9. 'woe.euribor3m.binned'\n",
       "10. 'emp.var.rate_width_bin_woe'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"nr.employed_freq_bin_woe\"       \"woe.nr.employed.binned\"        \n",
       " [3] \"nr.employed.binned_woe\"         \"nr.employed_freq_bin_incidence\"\n",
       " [5] \"nr.employed.binned_incidence\"   \"nr.employed_width_bin_woe\"     \n",
       " [7] \"nr.employed\"                    \"euribor3m.binned_woe\"          \n",
       " [9] \"woe.euribor3m.binned\"           \"emp.var.rate_width_bin_woe\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select top 50 variables according to the Fisher Score\n",
    "best_fs_var <- varSelectionFisher(train, dv_list, iv_list, num_select=50)\n",
    "head(best_fs_var, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply variable selection to the data\n",
    "# Train\n",
    "var_select <- names(train)[names(train) %in% best_fs_var]\n",
    "train_processed <- train[, c('client_id', var_select, 'subscribe')]\n",
    "# Valid\n",
    "var_select <- names(valid)[names(valid) %in% best_fs_var]\n",
    "valid_processed <- valid[, c('client_id', var_select, 'subscribe')]\n",
    "# Test\n",
    "var_select <- names(test)[names(test) %in% best_fs_var]\n",
    "test_processed <- test[, c('client_id', var_select, 'subscribe')]\n",
    "# Test (holdout)\n",
    "var_select <- names(test_holdout)[names(test_holdout) %in% best_fs_var]\n",
    "test_holdout_processed <- test_holdout[, c('client_id', var_select)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Finalize data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>4900</li>\n",
       "\t<li>52</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4900\n",
       "\\item 52\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4900\n",
       "2. 52\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4900   52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1050</li>\n",
       "\t<li>52</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1050\n",
       "\\item 52\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1050\n",
       "2. 52\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1050   52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1050</li>\n",
       "\t<li>52</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1050\n",
       "\\item 52\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1050\n",
       "2. 52\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1050   52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3000</li>\n",
       "\t<li>51</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3000\n",
       "\\item 51\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3000\n",
       "2. 51\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3000   51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if train and test (holdout) have same variables\n",
    "# Train, valid, test\n",
    "dim(train_processed)\n",
    "dim(valid_processed)\n",
    "dim(test_processed)\n",
    "# Test (holdout)\n",
    "dim(test_holdout_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the data columns\n",
    "for (v in colnames(train_processed)) {\n",
    "    \n",
    "    # Fix the column name\n",
    "    fix_name <- str_replace_all(v, \"[^[:alnum:] ]\", \"_\")\n",
    "    fix_name <- gsub(' +', '', fix_name) \n",
    "    \n",
    "    # Train, valid, test\n",
    "    colnames(train_processed)[colnames(train_processed) == v] <- fix_name\n",
    "    colnames(valid_processed)[colnames(valid_processed) == v] <- fix_name\n",
    "    colnames(test_processed)[colnames(test_processed) == v] <- fix_name\n",
    "    \n",
    "    # Test (holdout)\n",
    "    colnames(test_holdout_processed)[colnames(test_holdout_processed) == v] <- fix_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>client_id</th><th scope=col>pdays</th><th scope=col>emp_var_rate</th><th scope=col>euribor3m</th><th scope=col>nr_employed</th><th scope=col>pdays_999</th><th scope=col>woe_month_binned</th><th scope=col>woe_emp_var_rate_binned</th><th scope=col>woe_cons_price_idx_binned</th><th scope=col>woe_cons_conf_idx_binned</th><th scope=col>...</th><th scope=col>euribor3m_binned_woe</th><th scope=col>nr_employed_binned_woe</th><th scope=col>emp_var_rate_freq_bin_woe</th><th scope=col>euribor3m_freq_bin_woe</th><th scope=col>nr_employed_freq_bin_woe</th><th scope=col>emp_var_rate_width_bin_woe</th><th scope=col>cons_conf_idx_width_bin_woe</th><th scope=col>euribor3m_width_bin_woe</th><th scope=col>nr_employed_width_bin_woe</th><th scope=col>subscribe</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 2        </td><td>999       </td><td> 1.1      </td><td>4.858     </td><td>5191.0    </td><td>1         </td><td>-33.07799 </td><td>-97.77773 </td><td>-127.79599</td><td>  5.94528 </td><td>...       </td><td>-2.914726 </td><td>-2.901679 </td><td>-3.303663 </td><td>-3.175000 </td><td>-3.303663 </td><td>-3.003480 </td><td>-2.641675 </td><td>-2.935150 </td><td>-2.901679 </td><td>0         </td></tr>\n",
       "\t<tr><td> 4        </td><td>999       </td><td>-0.1      </td><td>4.153     </td><td>5195.8    </td><td>1         </td><td>-33.07799 </td><td> 45.95492 </td><td> -36.42063</td><td>-60.52865 </td><td>...       </td><td>-2.914726 </td><td>-2.901679 </td><td>-2.382628 </td><td>-3.175000 </td><td>-2.382628 </td><td>-2.387743 </td><td>-2.782441 </td><td>-2.654466 </td><td>-2.901679 </td><td>0         </td></tr>\n",
       "\t<tr><td> 5        </td><td>999       </td><td>-1.8      </td><td>1.299     </td><td>5099.1    </td><td>1         </td><td>-33.07799 </td><td> 45.95492 </td><td>  33.64920</td><td>-60.52865 </td><td>...       </td><td>-1.908453 </td><td>-1.882397 </td><td>-1.367265 </td><td>-1.968844 </td><td>-1.884736 </td><td>-1.473788 </td><td>-1.786074 </td><td>-1.129071 </td><td>-1.625715 </td><td>0         </td></tr>\n",
       "\t<tr><td> 7        </td><td>999       </td><td> 1.4      </td><td>4.864     </td><td>5228.1    </td><td>1         </td><td>-33.07799 </td><td>-97.77773 </td><td>  23.39432</td><td>-60.52865 </td><td>...       </td><td>-2.914726 </td><td>-2.901679 </td><td>-2.883266 </td><td>-2.881494 </td><td>-2.883266 </td><td>-3.003480 </td><td>-2.782441 </td><td>-2.935150 </td><td>-2.901679 </td><td>0         </td></tr>\n",
       "\t<tr><td> 8        </td><td>999       </td><td>-0.1      </td><td>4.153     </td><td>5195.8    </td><td>1         </td><td>-33.07799 </td><td> 45.95492 </td><td> -36.42063</td><td>-60.52865 </td><td>...       </td><td>-2.914726 </td><td>-2.901679 </td><td>-2.382628 </td><td>-3.175000 </td><td>-2.382628 </td><td>-2.387743 </td><td>-2.782441 </td><td>-2.654466 </td><td>-2.901679 </td><td>0         </td></tr>\n",
       "\t<tr><td>21        </td><td>999       </td><td> 1.4      </td><td>4.967     </td><td>5228.1    </td><td>1         </td><td>-33.07799 </td><td>-97.77773 </td><td> -36.42063</td><td>-97.00296 </td><td>...       </td><td>-2.914726 </td><td>-2.901679 </td><td>-2.883266 </td><td>-2.813411 </td><td>-2.883266 </td><td>-3.003480 </td><td>-2.641675 </td><td>-2.935150 </td><td>-2.901679 </td><td>0         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " client\\_id & pdays & emp\\_var\\_rate & euribor3m & nr\\_employed & pdays\\_999 & woe\\_month\\_binned & woe\\_emp\\_var\\_rate\\_binned & woe\\_cons\\_price\\_idx\\_binned & woe\\_cons\\_conf\\_idx\\_binned & ... & euribor3m\\_binned\\_woe & nr\\_employed\\_binned\\_woe & emp\\_var\\_rate\\_freq\\_bin\\_woe & euribor3m\\_freq\\_bin\\_woe & nr\\_employed\\_freq\\_bin\\_woe & emp\\_var\\_rate\\_width\\_bin\\_woe & cons\\_conf\\_idx\\_width\\_bin\\_woe & euribor3m\\_width\\_bin\\_woe & nr\\_employed\\_width\\_bin\\_woe & subscribe\\\\\n",
       "\\hline\n",
       "\t  2         & 999        &  1.1       & 4.858      & 5191.0     & 1          & -33.07799  & -97.77773  & -127.79599 &   5.94528  & ...        & -2.914726  & -2.901679  & -3.303663  & -3.175000  & -3.303663  & -3.003480  & -2.641675  & -2.935150  & -2.901679  & 0         \\\\\n",
       "\t  4         & 999        & -0.1       & 4.153      & 5195.8     & 1          & -33.07799  &  45.95492  &  -36.42063 & -60.52865  & ...        & -2.914726  & -2.901679  & -2.382628  & -3.175000  & -2.382628  & -2.387743  & -2.782441  & -2.654466  & -2.901679  & 0         \\\\\n",
       "\t  5         & 999        & -1.8       & 1.299      & 5099.1     & 1          & -33.07799  &  45.95492  &   33.64920 & -60.52865  & ...        & -1.908453  & -1.882397  & -1.367265  & -1.968844  & -1.884736  & -1.473788  & -1.786074  & -1.129071  & -1.625715  & 0         \\\\\n",
       "\t  7         & 999        &  1.4       & 4.864      & 5228.1     & 1          & -33.07799  & -97.77773  &   23.39432 & -60.52865  & ...        & -2.914726  & -2.901679  & -2.883266  & -2.881494  & -2.883266  & -3.003480  & -2.782441  & -2.935150  & -2.901679  & 0         \\\\\n",
       "\t  8         & 999        & -0.1       & 4.153      & 5195.8     & 1          & -33.07799  &  45.95492  &  -36.42063 & -60.52865  & ...        & -2.914726  & -2.901679  & -2.382628  & -3.175000  & -2.382628  & -2.387743  & -2.782441  & -2.654466  & -2.901679  & 0         \\\\\n",
       "\t 21         & 999        &  1.4       & 4.967      & 5228.1     & 1          & -33.07799  & -97.77773  &  -36.42063 & -97.00296  & ...        & -2.914726  & -2.901679  & -2.883266  & -2.813411  & -2.883266  & -3.003480  & -2.641675  & -2.935150  & -2.901679  & 0         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| client_id | pdays | emp_var_rate | euribor3m | nr_employed | pdays_999 | woe_month_binned | woe_emp_var_rate_binned | woe_cons_price_idx_binned | woe_cons_conf_idx_binned | ... | euribor3m_binned_woe | nr_employed_binned_woe | emp_var_rate_freq_bin_woe | euribor3m_freq_bin_woe | nr_employed_freq_bin_woe | emp_var_rate_width_bin_woe | cons_conf_idx_width_bin_woe | euribor3m_width_bin_woe | nr_employed_width_bin_woe | subscribe |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  2         | 999        |  1.1       | 4.858      | 5191.0     | 1          | -33.07799  | -97.77773  | -127.79599 |   5.94528  | ...        | -2.914726  | -2.901679  | -3.303663  | -3.175000  | -3.303663  | -3.003480  | -2.641675  | -2.935150  | -2.901679  | 0          |\n",
       "|  4         | 999        | -0.1       | 4.153      | 5195.8     | 1          | -33.07799  |  45.95492  |  -36.42063 | -60.52865  | ...        | -2.914726  | -2.901679  | -2.382628  | -3.175000  | -2.382628  | -2.387743  | -2.782441  | -2.654466  | -2.901679  | 0          |\n",
       "|  5         | 999        | -1.8       | 1.299      | 5099.1     | 1          | -33.07799  |  45.95492  |   33.64920 | -60.52865  | ...        | -1.908453  | -1.882397  | -1.367265  | -1.968844  | -1.884736  | -1.473788  | -1.786074  | -1.129071  | -1.625715  | 0          |\n",
       "|  7         | 999        |  1.4       | 4.864      | 5228.1     | 1          | -33.07799  | -97.77773  |   23.39432 | -60.52865  | ...        | -2.914726  | -2.901679  | -2.883266  | -2.881494  | -2.883266  | -3.003480  | -2.782441  | -2.935150  | -2.901679  | 0          |\n",
       "|  8         | 999        | -0.1       | 4.153      | 5195.8     | 1          | -33.07799  |  45.95492  |  -36.42063 | -60.52865  | ...        | -2.914726  | -2.901679  | -2.382628  | -3.175000  | -2.382628  | -2.387743  | -2.782441  | -2.654466  | -2.901679  | 0          |\n",
       "| 21         | 999        |  1.4       | 4.967      | 5228.1     | 1          | -33.07799  | -97.77773  |  -36.42063 | -97.00296  | ...        | -2.914726  | -2.901679  | -2.883266  | -2.813411  | -2.883266  | -3.003480  | -2.641675  | -2.935150  | -2.901679  | 0          |\n",
       "\n"
      ],
      "text/plain": [
       "  client_id pdays emp_var_rate euribor3m nr_employed pdays_999 woe_month_binned\n",
       "1  2        999    1.1         4.858     5191.0      1         -33.07799       \n",
       "2  4        999   -0.1         4.153     5195.8      1         -33.07799       \n",
       "3  5        999   -1.8         1.299     5099.1      1         -33.07799       \n",
       "4  7        999    1.4         4.864     5228.1      1         -33.07799       \n",
       "5  8        999   -0.1         4.153     5195.8      1         -33.07799       \n",
       "6 21        999    1.4         4.967     5228.1      1         -33.07799       \n",
       "  woe_emp_var_rate_binned woe_cons_price_idx_binned woe_cons_conf_idx_binned\n",
       "1 -97.77773               -127.79599                  5.94528               \n",
       "2  45.95492                -36.42063                -60.52865               \n",
       "3  45.95492                 33.64920                -60.52865               \n",
       "4 -97.77773                 23.39432                -60.52865               \n",
       "5  45.95492                -36.42063                -60.52865               \n",
       "6 -97.77773                -36.42063                -97.00296               \n",
       "  ... euribor3m_binned_woe nr_employed_binned_woe emp_var_rate_freq_bin_woe\n",
       "1 ... -2.914726            -2.901679              -3.303663                \n",
       "2 ... -2.914726            -2.901679              -2.382628                \n",
       "3 ... -1.908453            -1.882397              -1.367265                \n",
       "4 ... -2.914726            -2.901679              -2.883266                \n",
       "5 ... -2.914726            -2.901679              -2.382628                \n",
       "6 ... -2.914726            -2.901679              -2.883266                \n",
       "  euribor3m_freq_bin_woe nr_employed_freq_bin_woe emp_var_rate_width_bin_woe\n",
       "1 -3.175000              -3.303663                -3.003480                 \n",
       "2 -3.175000              -2.382628                -2.387743                 \n",
       "3 -1.968844              -1.884736                -1.473788                 \n",
       "4 -2.881494              -2.883266                -3.003480                 \n",
       "5 -3.175000              -2.382628                -2.387743                 \n",
       "6 -2.813411              -2.883266                -3.003480                 \n",
       "  cons_conf_idx_width_bin_woe euribor3m_width_bin_woe nr_employed_width_bin_woe\n",
       "1 -2.641675                   -2.935150               -2.901679                \n",
       "2 -2.782441                   -2.654466               -2.901679                \n",
       "3 -1.786074                   -1.129071               -1.625715                \n",
       "4 -2.782441                   -2.935150               -2.901679                \n",
       "5 -2.782441                   -2.654466               -2.901679                \n",
       "6 -2.641675                   -2.935150               -2.901679                \n",
       "  subscribe\n",
       "1 0        \n",
       "2 0        \n",
       "3 0        \n",
       "4 0        \n",
       "5 0        \n",
       "6 0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out to check\n",
    "head(train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methodology - Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling: cross-validation\n",
      "Measures:             auc.train   auc.test    \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 1:    0.7969752   0.7644118   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 2:    0.7835575   0.8109913   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 3:    0.7928269   0.7720556   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 4:    0.7984109   0.7510877   \n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"[Resample] iter 5:    0.7828740   0.8183251   \n",
      "\n",
      "\n",
      "Aggregated Result: auc.test.mean=0.7833743,auc.train.mean=0.7909289\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=5, predict=\"both\")\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.logreg\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc, setAggregation(mlr::auc, train.mean)))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.812795519022332"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.812795519022332"
      ],
      "text/markdown": [
       "**auc:** 0.812795519022332"
      ],
      "text/plain": [
       "      auc \n",
       "0.8127955 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=valid_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.831155041365683"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.831155041365683"
      ],
      "text/markdown": [
       "**auc:** 0.831155041365683"
      ],
      "text/plain": [
       "     auc \n",
       "0.831155 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: 0=0.50,1=0.50\n",
       "time: 0.00\n",
       "     prob.0     prob.1 response\n",
       "1 0.9289812 0.07101876        0\n",
       "2 0.9545322 0.04546785        0\n",
       "3 0.5926454 0.40735460        0\n",
       "4 0.9348046 0.06519543        0\n",
       "5 0.9651670 0.03483299        0\n",
       "6 0.9340336 0.06596637        0\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test (holdout) data\n",
    "pred <- predict(best_md, newdata=test_holdout_processed[, -1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_holdout$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'C:/Users/skamal/Downloads/lr_submission_clean1.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.randomForest for parameter set:\n",
      "          Type len Def               Constr Req Tunable Trafo\n",
      "ntree discrete   -   - 100,250,500,750,1000   -    TRUE     -\n",
      "mtry  discrete   -   -        2,4,5,7,10,14   -    TRUE     -\n",
      "With control class: TuneControlRandom\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: ntree=750; mtry=10\n",
      "[Tune-y] 1: auc.test.mean=0.7375089; time: 1.3 min\n",
      "[Tune-x] 2: ntree=100; mtry=10\n",
      "[Tune-y] 2: auc.test.mean=0.7204934; time: 0.2 min\n",
      "[Tune-x] 3: ntree=500; mtry=14\n",
      "[Tune-y] 3: auc.test.mean=0.7326837; time: 0.9 min\n",
      "[Tune-x] 4: ntree=100; mtry=7\n",
      "[Tune-y] 4: auc.test.mean=0.7203372; time: 0.2 min\n",
      "[Tune-x] 5: ntree=500; mtry=7\n",
      "[Tune-y] 5: auc.test.mean=0.7323995; time: 0.8 min\n",
      "[Tune-x] 6: ntree=500; mtry=7\n",
      "[Tune-y] 6: auc.test.mean=0.7320924; time: 0.8 min\n",
      "[Tune-x] 7: ntree=750; mtry=10\n",
      "[Tune-y] 7: auc.test.mean=0.7341538; time: 1.3 min\n",
      "[Tune-x] 8: ntree=750; mtry=5\n",
      "[Tune-y] 8: auc.test.mean=0.7316518; time: 1.1 min\n",
      "[Tune-x] 9: ntree=500; mtry=10\n",
      "[Tune-y] 9: auc.test.mean=0.7372555; time: 0.9 min\n",
      "[Tune-x] 10: ntree=500; mtry=7\n",
      "[Tune-y] 10: auc.test.mean=0.7274476; time: 0.8 min\n",
      "[Tune-x] 11: ntree=100; mtry=5\n",
      "[Tune-y] 11: auc.test.mean=0.7125404; time: 0.2 min\n",
      "[Tune-x] 12: ntree=750; mtry=5\n",
      "[Tune-y] 12: auc.test.mean=0.7303654; time: 1.1 min\n",
      "[Tune-x] 13: ntree=250; mtry=2\n",
      "[Tune-y] 13: auc.test.mean=0.7184182; time: 0.3 min\n",
      "[Tune-x] 14: ntree=100; mtry=14\n",
      "[Tune-y] 14: auc.test.mean=0.7268083; time: 0.2 min\n",
      "[Tune-x] 15: ntree=250; mtry=2\n",
      "[Tune-y] 15: auc.test.mean=0.7189521; time: 0.3 min\n",
      "[Tune-x] 16: ntree=250; mtry=10\n",
      "[Tune-y] 16: auc.test.mean=0.7324741; time: 0.4 min\n",
      "[Tune-x] 17: ntree=100; mtry=5\n",
      "[Tune-y] 17: auc.test.mean=0.7160904; time: 0.1 min\n",
      "[Tune-x] 18: ntree=250; mtry=14\n",
      "[Tune-y] 18: auc.test.mean=0.7310118; time: 0.5 min\n",
      "[Tune-x] 19: ntree=250; mtry=4\n",
      "[Tune-y] 19: auc.test.mean=0.7230545; time: 0.3 min\n",
      "[Tune-x] 20: ntree=1000; mtry=10\n",
      "[Tune-y] 20: auc.test.mean=0.7409299; time: 1.8 min\n",
      "[Tune-x] 21: ntree=250; mtry=7\n",
      "[Tune-y] 21: auc.test.mean=0.7315076; time: 0.4 min\n",
      "[Tune-x] 22: ntree=250; mtry=5\n",
      "[Tune-y] 22: auc.test.mean=0.7239755; time: 0.4 min\n",
      "[Tune-x] 23: ntree=500; mtry=10\n",
      "[Tune-y] 23: auc.test.mean=0.7397530; time: 0.9 min\n",
      "[Tune-x] 24: ntree=250; mtry=5\n",
      "[Tune-y] 24: auc.test.mean=0.7203472; time: 0.3 min\n",
      "[Tune-x] 25: ntree=500; mtry=10\n",
      "[Tune-y] 25: auc.test.mean=0.7320418; time: 0.8 min\n",
      "[Tune-x] 26: ntree=100; mtry=14\n",
      "[Tune-y] 26: auc.test.mean=0.7250607; time: 0.2 min\n",
      "[Tune-x] 27: ntree=100; mtry=2\n",
      "[Tune-y] 27: auc.test.mean=0.7136886; time: 0.1 min\n",
      "[Tune-x] 28: ntree=100; mtry=7\n",
      "[Tune-y] 28: auc.test.mean=0.7215616; time: 0.2 min\n",
      "[Tune-x] 29: ntree=750; mtry=4\n",
      "[Tune-y] 29: auc.test.mean=0.7283010; time: 1.0 min\n",
      "[Tune-x] 30: ntree=250; mtry=5\n",
      "[Tune-y] 30: auc.test.mean=0.7277718; time: 0.3 min\n",
      "[Tune-x] 31: ntree=1000; mtry=10\n",
      "[Tune-y] 31: auc.test.mean=0.7370280; time: 1.7 min\n",
      "[Tune-x] 32: ntree=1000; mtry=7\n",
      "[Tune-y] 32: auc.test.mean=0.7343669; time: 1.5 min\n",
      "[Tune-x] 33: ntree=500; mtry=5\n",
      "[Tune-y] 33: auc.test.mean=0.7306031; time: 0.7 min\n",
      "[Tune-x] 34: ntree=1000; mtry=10\n",
      "[Tune-y] 34: auc.test.mean=0.7393660; time: 1.7 min\n",
      "[Tune-x] 35: ntree=250; mtry=4\n",
      "[Tune-y] 35: auc.test.mean=0.7227982; time: 0.3 min\n",
      "[Tune-x] 36: ntree=500; mtry=7\n",
      "[Tune-y] 36: auc.test.mean=0.7301681; time: 0.8 min\n",
      "[Tune-x] 37: ntree=750; mtry=5\n",
      "[Tune-y] 37: auc.test.mean=0.7331471; time: 1.1 min\n",
      "[Tune-x] 38: ntree=500; mtry=10\n",
      "[Tune-y] 38: auc.test.mean=0.7321002; time: 0.8 min\n",
      "[Tune-x] 39: ntree=500; mtry=7\n",
      "[Tune-y] 39: auc.test.mean=0.7289390; time: 0.8 min\n",
      "[Tune-x] 40: ntree=750; mtry=5\n",
      "[Tune-y] 40: auc.test.mean=0.7304450; time: 1.1 min\n",
      "[Tune-x] 41: ntree=1000; mtry=10\n",
      "[Tune-y] 41: auc.test.mean=0.7402548; time: 1.7 min\n",
      "[Tune-x] 42: ntree=750; mtry=4\n",
      "[Tune-y] 42: auc.test.mean=0.7257168; time: 1.0 min\n",
      "[Tune-x] 43: ntree=500; mtry=7\n",
      "[Tune-y] 43: auc.test.mean=0.7329893; time: 0.8 min\n",
      "[Tune-x] 44: ntree=100; mtry=10\n",
      "[Tune-y] 44: auc.test.mean=0.7204078; time: 0.2 min\n",
      "[Tune-x] 45: ntree=750; mtry=4\n",
      "[Tune-y] 45: auc.test.mean=0.7339571; time: 1.0 min\n",
      "[Tune-x] 46: ntree=250; mtry=2\n",
      "[Tune-y] 46: auc.test.mean=0.7181627; time: 0.3 min\n",
      "[Tune-x] 47: ntree=100; mtry=5\n",
      "[Tune-y] 47: auc.test.mean=0.7140079; time: 0.1 min\n",
      "[Tune-x] 48: ntree=500; mtry=7\n",
      "[Tune-y] 48: auc.test.mean=0.7284574; time: 0.8 min\n",
      "[Tune-x] 49: ntree=1000; mtry=4\n",
      "[Tune-y] 49: auc.test.mean=0.7294837; time: 1.3 min\n",
      "[Tune-x] 50: ntree=1000; mtry=14\n",
      "[Tune-y] 50: auc.test.mean=0.7387383; time: 1.9 min\n",
      "[Tune-x] 51: ntree=250; mtry=14\n",
      "[Tune-y] 51: auc.test.mean=0.7329111; time: 0.5 min\n",
      "[Tune-x] 52: ntree=500; mtry=2\n",
      "[Tune-y] 52: auc.test.mean=0.7234303; time: 0.6 min\n",
      "[Tune-x] 53: ntree=100; mtry=14\n",
      "[Tune-y] 53: auc.test.mean=0.7217646; time: 0.2 min\n",
      "[Tune-x] 54: ntree=100; mtry=10\n",
      "[Tune-y] 54: auc.test.mean=0.7201896; time: 0.2 min\n",
      "[Tune-x] 55: ntree=250; mtry=7\n",
      "[Tune-y] 55: auc.test.mean=0.7266639; time: 0.4 min\n",
      "[Tune-x] 56: ntree=750; mtry=5\n",
      "[Tune-y] 56: auc.test.mean=0.7299044; time: 1.2 min\n",
      "[Tune-x] 57: ntree=100; mtry=5\n",
      "[Tune-y] 57: auc.test.mean=0.7182574; time: 0.2 min\n",
      "[Tune-x] 58: ntree=1000; mtry=7\n",
      "[Tune-y] 58: auc.test.mean=0.7349730; time: 1.7 min\n",
      "[Tune-x] 59: ntree=1000; mtry=2\n",
      "[Tune-y] 59: auc.test.mean=0.7257500; time: 1.2 min\n",
      "[Tune-x] 60: ntree=100; mtry=5\n",
      "[Tune-y] 60: auc.test.mean=0.7152915; time: 0.2 min\n",
      "[Tune-x] 61: ntree=100; mtry=4\n",
      "[Tune-y] 61: auc.test.mean=0.7114360; time: 0.2 min\n",
      "[Tune-x] 62: ntree=250; mtry=14\n",
      "[Tune-y] 62: auc.test.mean=0.7316275; time: 0.5 min\n",
      "[Tune-x] 63: ntree=750; mtry=4\n",
      "[Tune-y] 63: auc.test.mean=0.7266914; time: 1.2 min\n",
      "[Tune-x] 64: ntree=1000; mtry=4\n",
      "[Tune-y] 64: auc.test.mean=0.7311448; time: 1.5 min\n",
      "[Tune-x] 65: ntree=500; mtry=10\n",
      "[Tune-y] 65: auc.test.mean=0.7304027; time: 1.0 min\n",
      "[Tune-x] 66: ntree=100; mtry=14\n",
      "[Tune-y] 66: auc.test.mean=0.7224151; time: 0.2 min\n",
      "[Tune-x] 67: ntree=500; mtry=2\n",
      "[Tune-y] 67: auc.test.mean=0.7266603; time: 0.6 min\n",
      "[Tune-x] 68: ntree=500; mtry=10\n",
      "[Tune-y] 68: auc.test.mean=0.7352473; time: 1.0 min\n",
      "[Tune-x] 69: ntree=100; mtry=4\n",
      "[Tune-y] 69: auc.test.mean=0.7164361; time: 0.2 min\n",
      "[Tune-x] 70: ntree=1000; mtry=4\n",
      "[Tune-y] 70: auc.test.mean=0.7331945; time: 1.6 min\n",
      "[Tune-x] 71: ntree=100; mtry=14\n",
      "[Tune-y] 71: auc.test.mean=0.7227019; time: 0.2 min\n",
      "[Tune-x] 72: ntree=1000; mtry=7\n",
      "[Tune-y] 72: auc.test.mean=0.7394988; time: 1.8 min\n",
      "[Tune-x] 73: ntree=250; mtry=2\n",
      "[Tune-y] 73: auc.test.mean=0.7170238; time: 0.3 min\n",
      "[Tune-x] 74: ntree=1000; mtry=14\n",
      "[Tune-y] 74: auc.test.mean=0.7396513; time: 2.3 min\n",
      "[Tune-x] 75: ntree=100; mtry=5\n",
      "[Tune-y] 75: auc.test.mean=0.7217066; time: 0.2 min\n",
      "[Tune-x] 76: ntree=1000; mtry=4\n",
      "[Tune-y] 76: auc.test.mean=0.7290808; time: 1.6 min\n",
      "[Tune-x] 77: ntree=100; mtry=10\n",
      "[Tune-y] 77: auc.test.mean=0.7238235; time: 0.2 min\n",
      "[Tune-x] 78: ntree=250; mtry=7\n",
      "[Tune-y] 78: auc.test.mean=0.7260648; time: 0.5 min\n",
      "[Tune-x] 79: ntree=750; mtry=4\n",
      "[Tune-y] 79: auc.test.mean=0.7288043; time: 1.2 min\n",
      "[Tune-x] 80: ntree=1000; mtry=4\n",
      "[Tune-y] 80: auc.test.mean=0.7316226; time: 1.6 min\n",
      "[Tune-x] 81: ntree=250; mtry=5\n",
      "[Tune-y] 81: auc.test.mean=0.7256563; time: 0.4 min\n",
      "[Tune-x] 82: ntree=500; mtry=5\n",
      "[Tune-y] 82: auc.test.mean=0.7287624; time: 0.8 min\n",
      "[Tune-x] 83: ntree=750; mtry=2\n",
      "[Tune-y] 83: auc.test.mean=0.7302444; time: 0.9 min\n",
      "[Tune-x] 84: ntree=250; mtry=7\n",
      "[Tune-y] 84: auc.test.mean=0.7281311; time: 0.4 min\n",
      "[Tune-x] 85: ntree=100; mtry=5\n",
      "[Tune-y] 85: auc.test.mean=0.7196245; time: 0.2 min\n",
      "[Tune-x] 86: ntree=250; mtry=4\n",
      "[Tune-y] 86: auc.test.mean=0.7217313; time: 0.4 min\n",
      "[Tune-x] 87: ntree=750; mtry=2\n",
      "[Tune-y] 87: auc.test.mean=0.7291469; time: 0.9 min\n",
      "[Tune-x] 88: ntree=1000; mtry=4\n",
      "[Tune-y] 88: auc.test.mean=0.7319367; time: 1.4 min\n",
      "[Tune-x] 89: ntree=750; mtry=2\n",
      "[Tune-y] 89: auc.test.mean=0.7235241; time: 0.9 min\n",
      "[Tune-x] 90: ntree=250; mtry=4\n",
      "[Tune-y] 90: auc.test.mean=0.7226113; time: 0.3 min\n",
      "[Tune-x] 91: ntree=250; mtry=4\n",
      "[Tune-y] 91: auc.test.mean=0.7190877; time: 0.4 min\n",
      "[Tune-x] 92: ntree=1000; mtry=7\n",
      "[Tune-y] 92: auc.test.mean=0.7400640; time: 1.7 min\n",
      "[Tune-x] 93: ntree=1000; mtry=14\n",
      "[Tune-y] 93: auc.test.mean=0.7369219; time: 2.0 min\n",
      "[Tune-x] 94: ntree=500; mtry=4\n",
      "[Tune-y] 94: auc.test.mean=0.7302068; time: 0.7 min\n",
      "[Tune-x] 95: ntree=1000; mtry=5\n",
      "[Tune-y] 95: auc.test.mean=0.7340745; time: 1.5 min\n",
      "[Tune-x] 96: ntree=500; mtry=14\n",
      "[Tune-y] 96: auc.test.mean=0.7381708; time: 1.0 min\n",
      "[Tune-x] 97: ntree=500; mtry=4\n",
      "[Tune-y] 97: auc.test.mean=0.7282288; time: 0.8 min\n",
      "[Tune-x] 98: ntree=250; mtry=5\n",
      "[Tune-y] 98: auc.test.mean=0.7238581; time: 0.4 min\n",
      "[Tune-x] 99: ntree=250; mtry=5\n",
      "[Tune-y] 99: auc.test.mean=0.7272080; time: 0.4 min\n",
      "[Tune-x] 100: ntree=750; mtry=14\n",
      "[Tune-y] 100: auc.test.mean=0.7348437; time: 1.5 min\n",
      "[Tune-x] 101: ntree=750; mtry=4\n",
      "[Tune-y] 101: auc.test.mean=0.7323410; time: 1.1 min\n",
      "[Tune-x] 102: ntree=500; mtry=10\n",
      "[Tune-y] 102: auc.test.mean=0.7343108; time: 0.9 min\n",
      "[Tune-x] 103: ntree=250; mtry=7\n",
      "[Tune-y] 103: auc.test.mean=0.7248957; time: 0.4 min\n",
      "[Tune-x] 104: ntree=1000; mtry=7\n",
      "[Tune-y] 104: auc.test.mean=0.7378562; time: 1.6 min\n",
      "[Tune-x] 105: ntree=1000; mtry=4\n",
      "[Tune-y] 105: auc.test.mean=0.7339433; time: 1.4 min\n",
      "[Tune-x] 106: ntree=1000; mtry=5\n",
      "[Tune-y] 106: auc.test.mean=0.7324747; time: 1.5 min\n",
      "[Tune-x] 107: ntree=750; mtry=7\n",
      "[Tune-y] 107: auc.test.mean=0.7313076; time: 1.3 min\n",
      "[Tune-x] 108: ntree=250; mtry=10\n",
      "[Tune-y] 108: auc.test.mean=0.7252771; time: 0.5 min\n",
      "[Tune-x] 109: ntree=750; mtry=2\n",
      "[Tune-y] 109: auc.test.mean=0.7246960; time: 0.9 min\n",
      "[Tune-x] 110: ntree=1000; mtry=4\n",
      "[Tune-y] 110: auc.test.mean=0.7318981; time: 1.5 min\n",
      "[Tune-x] 111: ntree=500; mtry=4\n",
      "[Tune-y] 111: auc.test.mean=0.7316672; time: 0.7 min\n",
      "[Tune-x] 112: ntree=1000; mtry=4\n",
      "[Tune-y] 112: auc.test.mean=0.7349943; time: 1.4 min\n",
      "[Tune-x] 113: ntree=500; mtry=7\n",
      "[Tune-y] 113: auc.test.mean=0.7334150; time: 0.8 min\n",
      "[Tune-x] 114: ntree=1000; mtry=7\n",
      "[Tune-y] 114: auc.test.mean=0.7383348; time: 1.6 min\n",
      "[Tune-x] 115: ntree=1000; mtry=4\n",
      "[Tune-y] 115: auc.test.mean=0.7301067; time: 1.4 min\n",
      "[Tune-x] 116: ntree=100; mtry=14\n",
      "[Tune-y] 116: auc.test.mean=0.7287624; time: 0.2 min\n",
      "[Tune-x] 117: ntree=1000; mtry=4\n",
      "[Tune-y] 117: auc.test.mean=0.7308943; time: 1.4 min\n",
      "[Tune-x] 118: ntree=500; mtry=10\n",
      "[Tune-y] 118: auc.test.mean=0.7333754; time: 0.9 min\n",
      "[Tune-x] 119: ntree=750; mtry=5\n",
      "[Tune-y] 119: auc.test.mean=0.7339259; time: 1.1 min\n",
      "[Tune-x] 120: ntree=100; mtry=5\n",
      "[Tune-y] 120: auc.test.mean=0.7113014; time: 0.1 min\n",
      "[Tune-x] 121: ntree=100; mtry=7\n",
      "[Tune-y] 121: auc.test.mean=0.7159901; time: 0.2 min\n",
      "[Tune-x] 122: ntree=100; mtry=4\n",
      "[Tune-y] 122: auc.test.mean=0.7164115; time: 0.1 min\n",
      "[Tune-x] 123: ntree=100; mtry=14\n",
      "[Tune-y] 123: auc.test.mean=0.7287980; time: 0.2 min\n",
      "[Tune-x] 124: ntree=750; mtry=14\n",
      "[Tune-y] 124: auc.test.mean=0.7391644; time: 1.4 min\n",
      "[Tune-x] 125: ntree=1000; mtry=4\n",
      "[Tune-y] 125: auc.test.mean=0.7311802; time: 1.4 min\n",
      "[Tune-x] 126: ntree=750; mtry=14\n",
      "[Tune-y] 126: auc.test.mean=0.7409748; time: 1.5 min\n",
      "[Tune-x] 127: ntree=100; mtry=2\n",
      "[Tune-y] 127: auc.test.mean=0.7156157; time: 0.1 min\n",
      "[Tune-x] 128: ntree=100; mtry=10\n",
      "[Tune-y] 128: auc.test.mean=0.7206627; time: 0.2 min\n",
      "[Tune-x] 129: ntree=750; mtry=5\n",
      "[Tune-y] 129: auc.test.mean=0.7337736; time: 1.1 min\n",
      "[Tune-x] 130: ntree=750; mtry=4\n",
      "[Tune-y] 130: auc.test.mean=0.7279488; time: 1.0 min\n",
      "[Tune-x] 131: ntree=1000; mtry=4\n",
      "[Tune-y] 131: auc.test.mean=0.7316055; time: 1.4 min\n",
      "[Tune-x] 132: ntree=500; mtry=2\n",
      "[Tune-y] 132: auc.test.mean=0.7221146; time: 0.6 min\n",
      "[Tune-x] 133: ntree=750; mtry=2\n",
      "[Tune-y] 133: auc.test.mean=0.7243229; time: 0.9 min\n",
      "[Tune-x] 134: ntree=750; mtry=4\n",
      "[Tune-y] 134: auc.test.mean=0.7333777; time: 1.0 min\n",
      "[Tune-x] 135: ntree=250; mtry=7\n",
      "[Tune-y] 135: auc.test.mean=0.7230616; time: 0.4 min\n",
      "[Tune-x] 136: ntree=750; mtry=5\n",
      "[Tune-y] 136: auc.test.mean=0.7288888; time: 1.1 min\n",
      "[Tune-x] 137: ntree=500; mtry=7\n",
      "[Tune-y] 137: auc.test.mean=0.7296615; time: 0.8 min\n",
      "[Tune-x] 138: ntree=250; mtry=5\n",
      "[Tune-y] 138: auc.test.mean=0.7253966; time: 0.4 min\n",
      "[Tune-x] 139: ntree=500; mtry=4\n",
      "[Tune-y] 139: auc.test.mean=0.7275743; time: 0.7 min\n",
      "[Tune-x] 140: ntree=250; mtry=14\n",
      "[Tune-y] 140: auc.test.mean=0.7350964; time: 0.5 min\n",
      "[Tune-x] 141: ntree=1000; mtry=10\n",
      "[Tune-y] 141: auc.test.mean=0.7400947; time: 1.8 min\n",
      "[Tune-x] 142: ntree=250; mtry=14\n",
      "[Tune-y] 142: auc.test.mean=0.7349023; time: 0.5 min\n",
      "[Tune-x] 143: ntree=250; mtry=5\n",
      "[Tune-y] 143: auc.test.mean=0.7287271; time: 0.4 min\n",
      "[Tune-x] 144: ntree=100; mtry=2\n",
      "[Tune-y] 144: auc.test.mean=0.7122244; time: 0.1 min\n",
      "[Tune-x] 145: ntree=500; mtry=14\n",
      "[Tune-y] 145: auc.test.mean=0.7361891; time: 0.9 min\n",
      "[Tune-x] 146: ntree=750; mtry=2\n",
      "[Tune-y] 146: auc.test.mean=0.7299208; time: 0.8 min\n",
      "[Tune-x] 147: ntree=500; mtry=5\n",
      "[Tune-y] 147: auc.test.mean=0.7299504; time: 0.7 min\n",
      "[Tune-x] 148: ntree=500; mtry=14\n",
      "[Tune-y] 148: auc.test.mean=0.7345168; time: 0.9 min\n",
      "[Tune-x] 149: ntree=1000; mtry=14\n",
      "[Tune-y] 149: auc.test.mean=0.7392049; time: 1.9 min\n",
      "[Tune-x] 150: ntree=100; mtry=10\n",
      "[Tune-y] 150: auc.test.mean=0.7204401; time: 0.2 min\n",
      "[Tune] Result: ntree=750; mtry=14 : auc.test.mean=0.7409748\n"
     ]
    }
   ],
   "source": [
    "#Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.randomForest\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "  makeDiscreteParam('ntree', value=c(100, 250, 500, 750, 1000)),\n",
    "  makeDiscreteParam('mtry', value=round(sqrt((ncol(train_processed)-1) * c(0.1, 0.25, 0.5, 1, 2, 4))))\n",
    ")\n",
    "ctrl = makeTuneControlRandom(maxit = 150L)\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "rf_best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.746208263621154"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.746208263621154"
      ],
      "text/markdown": [
       "**auc:** 0.746208263621154"
      ],
      "text/plain": [
       "      auc \n",
       "0.7462083 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on valid data\n",
    "rf_pred <- predict(rf_best_md, newdata=valid_processed[, -1])\n",
    "performance(rf_pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.754810964160674"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.754810964160674"
      ],
      "text/markdown": [
       "**auc:** 0.754810964160674"
      ],
      "text/plain": [
       "     auc \n",
       "0.754811 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "rf_pred <- predict(rf_best_md, newdata=test_processed[, -1])\n",
    "performance(rf_pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: 0=0.50,1=0.50\n",
       "time: 0.09\n",
       "  prob.0 prob.1 response\n",
       "1  1.000  0.000        0\n",
       "2  1.000  0.000        0\n",
       "3  0.826  0.174        0\n",
       "4  1.000  0.000        0\n",
       "5  1.000  0.000        0\n",
       "6  1.000  0.000        0\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "rf_pred <- predict(rf_best_md, newdata=test_holdout_processed[, -1])\n",
    "rf_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_holdout$client_id, subscribe=pred$data$prob.1)\n",
    "write.csv(output, 'C:/Users/skamal/Downloads/rf_submission_clean1.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.gbm for parameter set:\n",
      "                      Type len Def       Constr Req Tunable Trafo\n",
      "distribution      discrete   -   -    bernoulli   -    TRUE     -\n",
      "n.trees            integer   -   - 100 to 1e+03   -    TRUE     -\n",
      "interaction.depth  integer   -   -      2 to 10   -    TRUE     -\n",
      "n.minobsinnode     integer   -   -     10 to 80   -    TRUE     -\n",
      "shrinkage          numeric   -   -    0.01 to 1   -    TRUE     -\n",
      "bag.fraction       numeric   -   -     0.1 to 1   -    TRUE     -\n",
      "With control class: TuneControlRandom\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: distribution=bernoulli; n.trees=889; interaction.depth=6; n.minobsinnode=29; shrinkage=0.825; bag.fraction=0.196\n",
      "[Tune-y] 1: auc.test.mean=0.4911197; time: 0.2 min\n",
      "[Tune-x] 2: distribution=bernoulli; n.trees=416; interaction.depth=4; n.minobsinnode=67; shrinkage=0.0684; bag.fraction=0.784\n",
      "[Tune-y] 2: auc.test.mean=0.7676765; time: 0.2 min\n",
      "[Tune-x] 3: distribution=bernoulli; n.trees=146; interaction.depth=9; n.minobsinnode=53; shrinkage=0.555; bag.fraction=0.274\n",
      "[Tune-y] 3: auc.test.mean=0.7313053; time: 0.1 min\n",
      "[Tune-x] 4: distribution=bernoulli; n.trees=182; interaction.depth=9; n.minobsinnode=39; shrinkage=0.519; bag.fraction=0.698\n",
      "[Tune-y] 4: auc.test.mean=0.7341082; time: 0.1 min\n",
      "[Tune-x] 5: distribution=bernoulli; n.trees=827; interaction.depth=2; n.minobsinnode=59; shrinkage=0.028; bag.fraction=0.317\n",
      "[Tune-y] 5: auc.test.mean=0.7656557; time: 0.1 min\n",
      "[Tune-x] 6: distribution=bernoulli; n.trees=200; interaction.depth=9; n.minobsinnode=13; shrinkage=0.502; bag.fraction=0.413\n",
      "[Tune-y] 6: auc.test.mean=0.7195399; time: 0.1 min\n",
      "[Tune-x] 7: distribution=bernoulli; n.trees=906; interaction.depth=9; n.minobsinnode=35; shrinkage=0.879; bag.fraction=0.617\n",
      "[Tune-y] 7: auc.test.mean=0.6690674; time: 0.8 min\n",
      "[Tune-x] 8: distribution=bernoulli; n.trees=259; interaction.depth=5; n.minobsinnode=48; shrinkage=0.718; bag.fraction=0.295\n",
      "[Tune-y] 8: auc.test.mean=0.7231592; time: 0.1 min\n",
      "[Tune-x] 9: distribution=bernoulli; n.trees=748; interaction.depth=5; n.minobsinnode=72; shrinkage=0.209; bag.fraction=0.619\n",
      "[Tune-y] 9: auc.test.mean=0.7474898; time: 0.4 min\n",
      "[Tune-x] 10: distribution=bernoulli; n.trees=227; interaction.depth=6; n.minobsinnode=72; shrinkage=0.961; bag.fraction=0.101\n",
      "[Tune-y] 10: auc.test.mean=0.7348673; time: 0.0 min\n",
      "[Tune-x] 11: distribution=bernoulli; n.trees=364; interaction.depth=9; n.minobsinnode=43; shrinkage=0.318; bag.fraction=0.256\n",
      "[Tune-y] 11: auc.test.mean=0.7340940; time: 0.2 min\n",
      "[Tune-x] 12: distribution=bernoulli; n.trees=157; interaction.depth=8; n.minobsinnode=38; shrinkage=0.109; bag.fraction=0.113\n",
      "[Tune-y] 12: auc.test.mean=0.7556311; time: 0.0 min\n",
      "[Tune-x] 13: distribution=bernoulli; n.trees=918; interaction.depth=2; n.minobsinnode=13; shrinkage=0.94; bag.fraction=0.112\n",
      "[Tune-y] 13: auc.test.mean=0.5286241; time: 0.1 min\n",
      "[Tune-x] 14: distribution=bernoulli; n.trees=876; interaction.depth=8; n.minobsinnode=24; shrinkage=0.462; bag.fraction=0.58\n",
      "[Tune-y] 14: auc.test.mean=0.6880489; time: 0.7 min\n",
      "[Tune-x] 15: distribution=bernoulli; n.trees=102; interaction.depth=2; n.minobsinnode=52; shrinkage=0.933; bag.fraction=0.513\n",
      "[Tune-y] 15: auc.test.mean=0.7655277; time: 0.0 min\n",
      "[Tune-x] 16: distribution=bernoulli; n.trees=539; interaction.depth=2; n.minobsinnode=25; shrinkage=0.982; bag.fraction=0.683\n",
      "[Tune-y] 16: auc.test.mean=0.6881236; time: 0.1 min\n",
      "[Tune-x] 17: distribution=bernoulli; n.trees=283; interaction.depth=6; n.minobsinnode=36; shrinkage=0.496; bag.fraction=0.605\n",
      "[Tune-y] 17: auc.test.mean=0.7369394; time: 0.2 min\n",
      "[Tune-x] 18: distribution=bernoulli; n.trees=405; interaction.depth=7; n.minobsinnode=72; shrinkage=0.272; bag.fraction=0.136\n",
      "[Tune-y] 18: auc.test.mean=0.7534511; time: 0.1 min\n",
      "[Tune-x] 19: distribution=bernoulli; n.trees=567; interaction.depth=3; n.minobsinnode=29; shrinkage=0.731; bag.fraction=0.471\n",
      "[Tune-y] 19: auc.test.mean=0.7201315; time: 0.2 min\n",
      "[Tune-x] 20: distribution=bernoulli; n.trees=969; interaction.depth=5; n.minobsinnode=32; shrinkage=0.777; bag.fraction=0.152\n",
      "[Tune-y] 20: auc.test.mean=0.5033332; time: 0.2 min\n",
      "[Tune-x] 21: distribution=bernoulli; n.trees=989; interaction.depth=7; n.minobsinnode=38; shrinkage=0.64; bag.fraction=0.375\n",
      "[Tune-y] 21: auc.test.mean=0.6930157; time: 0.6 min\n",
      "[Tune-x] 22: distribution=bernoulli; n.trees=583; interaction.depth=10; n.minobsinnode=41; shrinkage=0.547; bag.fraction=0.197\n",
      "[Tune-y] 22: auc.test.mean=0.7159991; time: 0.3 min\n",
      "[Tune-x] 23: distribution=bernoulli; n.trees=473; interaction.depth=9; n.minobsinnode=64; shrinkage=0.533; bag.fraction=0.602\n",
      "[Tune-y] 23: auc.test.mean=0.7263480; time: 0.4 min\n",
      "[Tune-x] 24: distribution=bernoulli; n.trees=302; interaction.depth=7; n.minobsinnode=50; shrinkage=0.0476; bag.fraction=0.597\n",
      "[Tune-y] 24: auc.test.mean=0.7621238; time: 0.2 min\n",
      "[Tune-x] 25: distribution=bernoulli; n.trees=698; interaction.depth=4; n.minobsinnode=74; shrinkage=0.665; bag.fraction=0.516\n",
      "[Tune-y] 25: auc.test.mean=0.7309405; time: 0.3 min\n",
      "[Tune-x] 26: distribution=bernoulli; n.trees=304; interaction.depth=8; n.minobsinnode=16; shrinkage=0.996; bag.fraction=0.546\n",
      "[Tune-y] 26: auc.test.mean=0.5902437; time: 0.2 min\n",
      "[Tune-x] 27: distribution=bernoulli; n.trees=489; interaction.depth=3; n.minobsinnode=51; shrinkage=0.957; bag.fraction=0.815\n",
      "[Tune-y] 27: auc.test.mean=0.6728852; time: 0.2 min\n",
      "[Tune-x] 28: distribution=bernoulli; n.trees=479; interaction.depth=6; n.minobsinnode=57; shrinkage=0.767; bag.fraction=0.723\n",
      "[Tune-y] 28: auc.test.mean=0.7194115; time: 0.3 min\n",
      "[Tune-x] 29: distribution=bernoulli; n.trees=779; interaction.depth=2; n.minobsinnode=28; shrinkage=0.334; bag.fraction=0.385\n",
      "[Tune-y] 29: auc.test.mean=0.7481409; time: 0.2 min\n",
      "[Tune-x] 30: distribution=bernoulli; n.trees=804; interaction.depth=7; n.minobsinnode=13; shrinkage=0.959; bag.fraction=0.927\n",
      "[Tune-y] 30: auc.test.mean=0.6543105; time: 0.5 min\n",
      "[Tune-x] 31: distribution=bernoulli; n.trees=470; interaction.depth=6; n.minobsinnode=59; shrinkage=0.23; bag.fraction=0.913\n",
      "[Tune-y] 31: auc.test.mean=0.7448065; time: 0.3 min\n",
      "[Tune-x] 32: distribution=bernoulli; n.trees=742; interaction.depth=8; n.minobsinnode=77; shrinkage=0.594; bag.fraction=0.623\n",
      "[Tune-y] 32: auc.test.mean=0.7117328; time: 0.6 min\n",
      "[Tune-x] 33: distribution=bernoulli; n.trees=599; interaction.depth=3; n.minobsinnode=74; shrinkage=0.582; bag.fraction=0.469\n",
      "[Tune-y] 33: auc.test.mean=0.7434192; time: 0.2 min\n",
      "[Tune-x] 34: distribution=bernoulli; n.trees=678; interaction.depth=7; n.minobsinnode=40; shrinkage=0.184; bag.fraction=0.149\n",
      "[Tune-y] 34: auc.test.mean=0.7451005; time: 0.2 min\n",
      "[Tune-x] 35: distribution=bernoulli; n.trees=433; interaction.depth=10; n.minobsinnode=64; shrinkage=0.202; bag.fraction=0.604\n",
      "[Tune-y] 35: auc.test.mean=0.7454841; time: 0.4 min\n",
      "[Tune-x] 36: distribution=bernoulli; n.trees=525; interaction.depth=2; n.minobsinnode=56; shrinkage=0.297; bag.fraction=0.804\n",
      "[Tune-y] 36: auc.test.mean=0.7643717; time: 0.1 min\n",
      "[Tune-x] 37: distribution=bernoulli; n.trees=691; interaction.depth=5; n.minobsinnode=45; shrinkage=0.327; bag.fraction=0.384\n",
      "[Tune-y] 37: auc.test.mean=0.7350238; time: 0.3 min\n",
      "[Tune-x] 38: distribution=bernoulli; n.trees=362; interaction.depth=3; n.minobsinnode=25; shrinkage=0.738; bag.fraction=0.445\n",
      "[Tune-y] 38: auc.test.mean=0.7156759; time: 0.1 min\n",
      "[Tune-x] 39: distribution=bernoulli; n.trees=609; interaction.depth=6; n.minobsinnode=15; shrinkage=0.38; bag.fraction=0.533\n",
      "[Tune-y] 39: auc.test.mean=0.7023875; time: 0.4 min\n",
      "[Tune-x] 40: distribution=bernoulli; n.trees=411; interaction.depth=9; n.minobsinnode=74; shrinkage=0.0191; bag.fraction=0.996\n",
      "[Tune-y] 40: auc.test.mean=0.7635783; time: 0.3 min\n",
      "[Tune-x] 41: distribution=bernoulli; n.trees=640; interaction.depth=10; n.minobsinnode=51; shrinkage=0.745; bag.fraction=0.254\n",
      "[Tune-y] 41: auc.test.mean=0.6561999; time: 0.4 min\n",
      "[Tune-x] 42: distribution=bernoulli; n.trees=745; interaction.depth=8; n.minobsinnode=70; shrinkage=0.944; bag.fraction=0.337\n",
      "[Tune-y] 42: auc.test.mean=0.6518661; time: 0.4 min\n",
      "[Tune-x] 43: distribution=bernoulli; n.trees=404; interaction.depth=7; n.minobsinnode=57; shrinkage=0.946; bag.fraction=0.829\n",
      "[Tune-y] 43: auc.test.mean=0.7034239; time: 0.3 min\n",
      "[Tune-x] 44: distribution=bernoulli; n.trees=816; interaction.depth=7; n.minobsinnode=42; shrinkage=0.619; bag.fraction=0.928\n",
      "[Tune-y] 44: auc.test.mean=0.6972955; time: 0.5 min\n",
      "[Tune-x] 45: distribution=bernoulli; n.trees=803; interaction.depth=8; n.minobsinnode=38; shrinkage=0.451; bag.fraction=0.719\n",
      "[Tune-y] 45: auc.test.mean=0.6987980; time: 0.6 min\n",
      "[Tune-x] 46: distribution=bernoulli; n.trees=832; interaction.depth=8; n.minobsinnode=70; shrinkage=0.29; bag.fraction=0.614\n",
      "[Tune-y] 46: auc.test.mean=0.7327376; time: 0.6 min\n",
      "[Tune-x] 47: distribution=bernoulli; n.trees=146; interaction.depth=5; n.minobsinnode=23; shrinkage=0.119; bag.fraction=0.388\n",
      "[Tune-y] 47: auc.test.mean=0.7712003; time: 0.1 min\n",
      "[Tune-x] 48: distribution=bernoulli; n.trees=248; interaction.depth=10; n.minobsinnode=51; shrinkage=0.43; bag.fraction=0.825\n",
      "[Tune-y] 48: auc.test.mean=0.7360106; time: 0.2 min\n",
      "[Tune-x] 49: distribution=bernoulli; n.trees=314; interaction.depth=6; n.minobsinnode=54; shrinkage=0.969; bag.fraction=0.115\n",
      "[Tune-y] 49: auc.test.mean=0.5550756; time: 0.1 min\n",
      "[Tune-x] 50: distribution=bernoulli; n.trees=618; interaction.depth=6; n.minobsinnode=26; shrinkage=0.293; bag.fraction=0.364\n",
      "[Tune-y] 50: auc.test.mean=0.7227978; time: 0.3 min\n",
      "[Tune-x] 51: distribution=bernoulli; n.trees=430; interaction.depth=5; n.minobsinnode=12; shrinkage=0.636; bag.fraction=0.685\n",
      "[Tune-y] 51: auc.test.mean=0.6932154; time: 0.2 min\n",
      "[Tune-x] 52: distribution=bernoulli; n.trees=910; interaction.depth=8; n.minobsinnode=50; shrinkage=0.863; bag.fraction=0.411\n",
      "[Tune-y] 52: auc.test.mean=0.6896885; time: 0.6 min\n",
      "[Tune-x] 53: distribution=bernoulli; n.trees=653; interaction.depth=7; n.minobsinnode=10; shrinkage=0.58; bag.fraction=0.334\n",
      "[Tune-y] 53: auc.test.mean=0.6633276; time: 0.4 min\n",
      "[Tune-x] 54: distribution=bernoulli; n.trees=851; interaction.depth=9; n.minobsinnode=36; shrinkage=0.468; bag.fraction=0.952\n",
      "[Tune-y] 54: auc.test.mean=0.6954450; time: 0.7 min\n",
      "[Tune-x] 55: distribution=bernoulli; n.trees=299; interaction.depth=4; n.minobsinnode=63; shrinkage=0.0921; bag.fraction=0.16\n",
      "[Tune-y] 55: auc.test.mean=0.7548658; time: 0.1 min\n",
      "[Tune-x] 56: distribution=bernoulli; n.trees=304; interaction.depth=2; n.minobsinnode=51; shrinkage=0.194; bag.fraction=0.381\n",
      "[Tune-y] 56: auc.test.mean=0.7673541; time: 0.1 min\n",
      "[Tune-x] 57: distribution=bernoulli; n.trees=377; interaction.depth=8; n.minobsinnode=57; shrinkage=0.223; bag.fraction=0.794\n",
      "[Tune-y] 57: auc.test.mean=0.7434741; time: 0.3 min\n",
      "[Tune-x] 58: distribution=bernoulli; n.trees=858; interaction.depth=7; n.minobsinnode=72; shrinkage=0.565; bag.fraction=0.937\n",
      "[Tune-y] 58: auc.test.mean=0.7164807; time: 0.5 min\n",
      "[Tune-x] 59: distribution=bernoulli; n.trees=594; interaction.depth=10; n.minobsinnode=32; shrinkage=0.558; bag.fraction=0.133\n",
      "[Tune-y] 59: auc.test.mean=0.6497177; time: 0.2 min\n",
      "[Tune-x] 60: distribution=bernoulli; n.trees=565; interaction.depth=3; n.minobsinnode=47; shrinkage=0.458; bag.fraction=0.135\n",
      "[Tune-y] 60: auc.test.mean=0.7403718; time: 0.1 min\n",
      "[Tune-x] 61: distribution=bernoulli; n.trees=183; interaction.depth=10; n.minobsinnode=20; shrinkage=0.401; bag.fraction=0.69\n",
      "[Tune-y] 61: auc.test.mean=0.7257727; time: 0.2 min\n",
      "[Tune-x] 62: distribution=bernoulli; n.trees=235; interaction.depth=4; n.minobsinnode=68; shrinkage=0.0643; bag.fraction=0.741\n",
      "[Tune-y] 62: auc.test.mean=0.7688093; time: 0.1 min\n",
      "[Tune-x] 63: distribution=bernoulli; n.trees=850; interaction.depth=6; n.minobsinnode=51; shrinkage=0.54; bag.fraction=0.247\n",
      "[Tune-y] 63: auc.test.mean=0.6982043; time: 0.3 min\n",
      "[Tune-x] 64: distribution=bernoulli; n.trees=212; interaction.depth=5; n.minobsinnode=61; shrinkage=0.285; bag.fraction=0.708\n",
      "[Tune-y] 64: auc.test.mean=0.7514589; time: 0.1 min\n",
      "[Tune-x] 65: distribution=bernoulli; n.trees=259; interaction.depth=9; n.minobsinnode=20; shrinkage=0.42; bag.fraction=0.708\n",
      "[Tune-y] 65: auc.test.mean=0.7216940; time: 0.2 min\n",
      "[Tune-x] 66: distribution=bernoulli; n.trees=576; interaction.depth=6; n.minobsinnode=27; shrinkage=0.922; bag.fraction=0.895\n",
      "[Tune-y] 66: auc.test.mean=0.6630439; time: 0.3 min\n",
      "[Tune-x] 67: distribution=bernoulli; n.trees=187; interaction.depth=8; n.minobsinnode=41; shrinkage=0.326; bag.fraction=0.53\n",
      "[Tune-y] 67: auc.test.mean=0.7466837; time: 0.1 min\n",
      "[Tune-x] 68: distribution=bernoulli; n.trees=927; interaction.depth=2; n.minobsinnode=61; shrinkage=0.089; bag.fraction=0.858\n",
      "[Tune-y] 68: auc.test.mean=0.7671715; time: 0.2 min\n",
      "[Tune-x] 69: distribution=bernoulli; n.trees=259; interaction.depth=9; n.minobsinnode=66; shrinkage=0.32; bag.fraction=0.181\n",
      "[Tune-y] 69: auc.test.mean=0.7524879; time: 0.1 min\n",
      "[Tune-x] 70: distribution=bernoulli; n.trees=405; interaction.depth=6; n.minobsinnode=55; shrinkage=0.151; bag.fraction=0.634\n",
      "[Tune-y] 70: auc.test.mean=0.7499935; time: 0.2 min\n",
      "[Tune-x] 71: distribution=bernoulli; n.trees=348; interaction.depth=6; n.minobsinnode=70; shrinkage=0.418; bag.fraction=0.867\n",
      "[Tune-y] 71: auc.test.mean=0.7414827; time: 0.2 min\n",
      "[Tune-x] 72: distribution=bernoulli; n.trees=995; interaction.depth=6; n.minobsinnode=58; shrinkage=0.323; bag.fraction=0.415\n",
      "[Tune-y] 72: auc.test.mean=0.7323874; time: 0.5 min\n",
      "[Tune-x] 73: distribution=bernoulli; n.trees=178; interaction.depth=4; n.minobsinnode=79; shrinkage=0.708; bag.fraction=0.535\n",
      "[Tune-y] 73: auc.test.mean=0.7424790; time: 0.1 min\n",
      "[Tune-x] 74: distribution=bernoulli; n.trees=898; interaction.depth=6; n.minobsinnode=31; shrinkage=0.697; bag.fraction=0.653\n",
      "[Tune-y] 74: auc.test.mean=0.6816992; time: 0.5 min\n",
      "[Tune-x] 75: distribution=bernoulli; n.trees=211; interaction.depth=6; n.minobsinnode=28; shrinkage=0.621; bag.fraction=0.962\n",
      "[Tune-y] 75: auc.test.mean=0.7335505; time: 0.1 min\n",
      "[Tune-x] 76: distribution=bernoulli; n.trees=510; interaction.depth=10; n.minobsinnode=11; shrinkage=0.337; bag.fraction=0.346\n",
      "[Tune-y] 76: auc.test.mean=0.6934344; time: 0.3 min\n",
      "[Tune-x] 77: distribution=bernoulli; n.trees=252; interaction.depth=7; n.minobsinnode=47; shrinkage=0.148; bag.fraction=0.996\n",
      "[Tune-y] 77: auc.test.mean=0.7565832; time: 0.2 min\n",
      "[Tune-x] 78: distribution=bernoulli; n.trees=600; interaction.depth=4; n.minobsinnode=21; shrinkage=0.183; bag.fraction=0.556\n",
      "[Tune-y] 78: auc.test.mean=0.7457079; time: 0.2 min\n",
      "[Tune-x] 79: distribution=bernoulli; n.trees=772; interaction.depth=10; n.minobsinnode=19; shrinkage=0.923; bag.fraction=0.658\n",
      "[Tune-y] 79: auc.test.mean=0.6019410; time: 0.7 min\n",
      "[Tune-x] 80: distribution=bernoulli; n.trees=846; interaction.depth=9; n.minobsinnode=70; shrinkage=0.351; bag.fraction=0.886\n",
      "[Tune-y] 80: auc.test.mean=0.7264638; time: 0.7 min\n",
      "[Tune-x] 81: distribution=bernoulli; n.trees=183; interaction.depth=8; n.minobsinnode=45; shrinkage=0.807; bag.fraction=0.166\n",
      "[Tune-y] 81: auc.test.mean=0.5908425; time: 0.1 min\n",
      "[Tune-x] 82: distribution=bernoulli; n.trees=206; interaction.depth=2; n.minobsinnode=61; shrinkage=0.722; bag.fraction=0.877\n",
      "[Tune-y] 82: auc.test.mean=0.7642207; time: 0.0 min\n",
      "[Tune-x] 83: distribution=bernoulli; n.trees=780; interaction.depth=10; n.minobsinnode=20; shrinkage=0.748; bag.fraction=0.794\n",
      "[Tune-y] 83: auc.test.mean=0.6558651; time: 0.7 min\n",
      "[Tune-x] 84: distribution=bernoulli; n.trees=195; interaction.depth=9; n.minobsinnode=39; shrinkage=0.927; bag.fraction=0.686\n",
      "[Tune-y] 84: auc.test.mean=0.7120635; time: 0.2 min\n",
      "[Tune-x] 85: distribution=bernoulli; n.trees=862; interaction.depth=2; n.minobsinnode=74; shrinkage=0.981; bag.fraction=0.353\n",
      "[Tune-y] 85: auc.test.mean=0.7261604; time: 0.2 min\n",
      "[Tune-x] 86: distribution=bernoulli; n.trees=814; interaction.depth=4; n.minobsinnode=12; shrinkage=0.0191; bag.fraction=0.533\n",
      "[Tune-y] 86: auc.test.mean=0.7704438; time: 0.3 min\n",
      "[Tune-x] 87: distribution=bernoulli; n.trees=136; interaction.depth=7; n.minobsinnode=26; shrinkage=0.557; bag.fraction=0.668\n",
      "[Tune-y] 87: auc.test.mean=0.7324002; time: 0.1 min\n",
      "[Tune-x] 88: distribution=bernoulli; n.trees=591; interaction.depth=3; n.minobsinnode=47; shrinkage=0.584; bag.fraction=0.898\n",
      "[Tune-y] 88: auc.test.mean=0.7426585; time: 0.2 min\n",
      "[Tune-x] 89: distribution=bernoulli; n.trees=207; interaction.depth=7; n.minobsinnode=37; shrinkage=0.563; bag.fraction=0.458\n",
      "[Tune-y] 89: auc.test.mean=0.7319012; time: 0.1 min\n",
      "[Tune-x] 90: distribution=bernoulli; n.trees=286; interaction.depth=4; n.minobsinnode=51; shrinkage=0.371; bag.fraction=0.595\n",
      "[Tune-y] 90: auc.test.mean=0.7514676; time: 0.1 min\n",
      "[Tune-x] 91: distribution=bernoulli; n.trees=832; interaction.depth=8; n.minobsinnode=21; shrinkage=0.489; bag.fraction=0.533\n",
      "[Tune-y] 91: auc.test.mean=0.6845001; time: 0.6 min\n",
      "[Tune-x] 92: distribution=bernoulli; n.trees=872; interaction.depth=5; n.minobsinnode=47; shrinkage=0.517; bag.fraction=0.696\n",
      "[Tune-y] 92: auc.test.mean=0.7128779; time: 0.4 min\n",
      "[Tune-x] 93: distribution=bernoulli; n.trees=122; interaction.depth=4; n.minobsinnode=10; shrinkage=0.15; bag.fraction=0.355\n",
      "[Tune-y] 93: auc.test.mean=0.7687428; time: 0.0 min\n",
      "[Tune-x] 94: distribution=bernoulli; n.trees=778; interaction.depth=2; n.minobsinnode=23; shrinkage=0.361; bag.fraction=0.368\n",
      "[Tune-y] 94: auc.test.mean=0.7571034; time: 0.1 min\n",
      "[Tune-x] 95: distribution=bernoulli; n.trees=675; interaction.depth=6; n.minobsinnode=18; shrinkage=0.152; bag.fraction=0.364\n",
      "[Tune-y] 95: auc.test.mean=0.7335458; time: 0.3 min\n",
      "[Tune-x] 96: distribution=bernoulli; n.trees=242; interaction.depth=5; n.minobsinnode=56; shrinkage=0.372; bag.fraction=0.712\n",
      "[Tune-y] 96: auc.test.mean=0.7511579; time: 0.1 min\n",
      "[Tune-x] 97: distribution=bernoulli; n.trees=188; interaction.depth=2; n.minobsinnode=48; shrinkage=0.402; bag.fraction=0.706\n",
      "[Tune-y] 97: auc.test.mean=0.7685975; time: 0.0 min\n",
      "[Tune-x] 98: distribution=bernoulli; n.trees=655; interaction.depth=3; n.minobsinnode=17; shrinkage=0.478; bag.fraction=0.859\n",
      "[Tune-y] 98: auc.test.mean=0.7256465; time: 0.2 min\n",
      "[Tune-x] 99: distribution=bernoulli; n.trees=284; interaction.depth=7; n.minobsinnode=46; shrinkage=0.0644; bag.fraction=0.771\n",
      "[Tune-y] 99: auc.test.mean=0.7612294; time: 0.2 min\n",
      "[Tune-x] 100: distribution=bernoulli; n.trees=262; interaction.depth=2; n.minobsinnode=74; shrinkage=0.992; bag.fraction=0.132\n",
      "[Tune-y] 100: auc.test.mean=0.7023983; time: 0.0 min\n",
      "[Tune-x] 101: distribution=bernoulli; n.trees=255; interaction.depth=9; n.minobsinnode=14; shrinkage=0.179; bag.fraction=0.362\n",
      "[Tune-y] 101: auc.test.mean=0.7373971; time: 0.2 min\n",
      "[Tune-x] 102: distribution=bernoulli; n.trees=285; interaction.depth=4; n.minobsinnode=11; shrinkage=0.695; bag.fraction=0.633\n",
      "[Tune-y] 102: auc.test.mean=0.7072632; time: 0.1 min\n",
      "[Tune-x] 103: distribution=bernoulli; n.trees=809; interaction.depth=6; n.minobsinnode=32; shrinkage=0.559; bag.fraction=0.43\n",
      "[Tune-y] 103: auc.test.mean=0.6963738; time: 0.4 min\n",
      "[Tune-x] 104: distribution=bernoulli; n.trees=561; interaction.depth=2; n.minobsinnode=52; shrinkage=0.843; bag.fraction=0.431\n",
      "[Tune-y] 104: auc.test.mean=0.7329651; time: 0.1 min\n",
      "[Tune-x] 105: distribution=bernoulli; n.trees=863; interaction.depth=8; n.minobsinnode=38; shrinkage=0.604; bag.fraction=0.471\n",
      "[Tune-y] 105: auc.test.mean=0.6834832; time: 0.6 min\n",
      "[Tune-x] 106: distribution=bernoulli; n.trees=875; interaction.depth=3; n.minobsinnode=56; shrinkage=0.422; bag.fraction=0.238\n",
      "[Tune-y] 106: auc.test.mean=0.7348181; time: 0.2 min\n",
      "[Tune-x] 107: distribution=bernoulli; n.trees=374; interaction.depth=6; n.minobsinnode=38; shrinkage=0.824; bag.fraction=0.529\n",
      "[Tune-y] 107: auc.test.mean=0.6997092; time: 0.2 min\n",
      "[Tune-x] 108: distribution=bernoulli; n.trees=632; interaction.depth=9; n.minobsinnode=11; shrinkage=0.785; bag.fraction=0.57\n",
      "[Tune-y] 108: auc.test.mean=0.6658106; time: 0.5 min\n",
      "[Tune-x] 109: distribution=bernoulli; n.trees=463; interaction.depth=8; n.minobsinnode=50; shrinkage=0.192; bag.fraction=0.701\n",
      "[Tune-y] 109: auc.test.mean=0.7454291; time: 0.3 min\n",
      "[Tune-x] 110: distribution=bernoulli; n.trees=888; interaction.depth=8; n.minobsinnode=44; shrinkage=0.832; bag.fraction=0.977\n",
      "[Tune-y] 110: auc.test.mean=0.6799423; time: 0.6 min\n",
      "[Tune-x] 111: distribution=bernoulli; n.trees=493; interaction.depth=8; n.minobsinnode=18; shrinkage=0.942; bag.fraction=0.112\n",
      "[Tune-y] 111: auc.test.mean=0.5751521; time: 0.1 min\n",
      "[Tune-x] 112: distribution=bernoulli; n.trees=827; interaction.depth=8; n.minobsinnode=67; shrinkage=0.878; bag.fraction=0.819\n",
      "[Tune-y] 112: auc.test.mean=0.6933713; time: 0.6 min\n",
      "[Tune-x] 113: distribution=bernoulli; n.trees=987; interaction.depth=8; n.minobsinnode=40; shrinkage=0.557; bag.fraction=0.326\n",
      "[Tune-y] 113: auc.test.mean=0.6936953; time: 0.5 min\n",
      "[Tune-x] 114: distribution=bernoulli; n.trees=839; interaction.depth=2; n.minobsinnode=34; shrinkage=0.175; bag.fraction=0.304\n",
      "[Tune-y] 114: auc.test.mean=0.7520263; time: 0.1 min\n",
      "[Tune-x] 115: distribution=bernoulli; n.trees=837; interaction.depth=2; n.minobsinnode=21; shrinkage=0.0417; bag.fraction=0.847\n",
      "[Tune-y] 115: auc.test.mean=0.7724785; time: 0.2 min\n",
      "[Tune-x] 116: distribution=bernoulli; n.trees=813; interaction.depth=3; n.minobsinnode=48; shrinkage=0.937; bag.fraction=0.907\n",
      "[Tune-y] 116: auc.test.mean=0.6656959; time: 0.2 min\n",
      "[Tune-x] 117: distribution=bernoulli; n.trees=784; interaction.depth=6; n.minobsinnode=41; shrinkage=0.475; bag.fraction=0.565\n",
      "[Tune-y] 117: auc.test.mean=0.7060221; time: 0.4 min\n",
      "[Tune-x] 118: distribution=bernoulli; n.trees=346; interaction.depth=9; n.minobsinnode=63; shrinkage=0.066; bag.fraction=0.712\n",
      "[Tune-y] 118: auc.test.mean=0.7556880; time: 0.3 min\n",
      "[Tune-x] 119: distribution=bernoulli; n.trees=579; interaction.depth=6; n.minobsinnode=61; shrinkage=0.531; bag.fraction=0.926\n",
      "[Tune-y] 119: auc.test.mean=0.7267770; time: 0.3 min\n",
      "[Tune-x] 120: distribution=bernoulli; n.trees=331; interaction.depth=3; n.minobsinnode=68; shrinkage=0.222; bag.fraction=0.286\n",
      "[Tune-y] 120: auc.test.mean=0.7593562; time: 0.1 min\n",
      "[Tune-x] 121: distribution=bernoulli; n.trees=263; interaction.depth=6; n.minobsinnode=65; shrinkage=0.884; bag.fraction=0.5\n",
      "[Tune-y] 121: auc.test.mean=0.7242938; time: 0.1 min\n",
      "[Tune-x] 122: distribution=bernoulli; n.trees=959; interaction.depth=2; n.minobsinnode=49; shrinkage=0.135; bag.fraction=0.547\n",
      "[Tune-y] 122: auc.test.mean=0.7643162; time: 0.2 min\n",
      "[Tune-x] 123: distribution=bernoulli; n.trees=672; interaction.depth=8; n.minobsinnode=44; shrinkage=0.413; bag.fraction=0.264\n",
      "[Tune-y] 123: auc.test.mean=0.7366393; time: 0.3 min\n",
      "[Tune-x] 124: distribution=bernoulli; n.trees=205; interaction.depth=10; n.minobsinnode=78; shrinkage=0.405; bag.fraction=0.607\n",
      "[Tune-y] 124: auc.test.mean=0.7433497; time: 0.2 min\n",
      "[Tune-x] 125: distribution=bernoulli; n.trees=321; interaction.depth=2; n.minobsinnode=47; shrinkage=0.335; bag.fraction=0.159\n",
      "[Tune-y] 125: auc.test.mean=0.7500116; time: 0.0 min\n",
      "[Tune-x] 126: distribution=bernoulli; n.trees=262; interaction.depth=9; n.minobsinnode=55; shrinkage=0.658; bag.fraction=0.404\n",
      "[Tune-y] 126: auc.test.mean=0.7244899; time: 0.2 min\n",
      "[Tune-x] 127: distribution=bernoulli; n.trees=229; interaction.depth=5; n.minobsinnode=19; shrinkage=0.857; bag.fraction=0.308\n",
      "[Tune-y] 127: auc.test.mean=0.6558118; time: 0.1 min\n",
      "[Tune-x] 128: distribution=bernoulli; n.trees=735; interaction.depth=5; n.minobsinnode=61; shrinkage=0.56; bag.fraction=0.527\n",
      "[Tune-y] 128: auc.test.mean=0.7215929; time: 0.4 min\n",
      "[Tune-x] 129: distribution=bernoulli; n.trees=728; interaction.depth=4; n.minobsinnode=34; shrinkage=0.356; bag.fraction=0.598\n",
      "[Tune-y] 129: auc.test.mean=0.7303928; time: 0.3 min\n",
      "[Tune-x] 130: distribution=bernoulli; n.trees=236; interaction.depth=7; n.minobsinnode=26; shrinkage=0.76; bag.fraction=0.386\n",
      "[Tune-y] 130: auc.test.mean=0.6895428; time: 0.1 min\n",
      "[Tune-x] 131: distribution=bernoulli; n.trees=263; interaction.depth=9; n.minobsinnode=65; shrinkage=0.134; bag.fraction=0.865\n",
      "[Tune-y] 131: auc.test.mean=0.7545893; time: 0.2 min\n",
      "[Tune-x] 132: distribution=bernoulli; n.trees=243; interaction.depth=3; n.minobsinnode=74; shrinkage=0.771; bag.fraction=0.332\n",
      "[Tune-y] 132: auc.test.mean=0.7421239; time: 0.1 min\n",
      "[Tune-x] 133: distribution=bernoulli; n.trees=247; interaction.depth=6; n.minobsinnode=16; shrinkage=0.308; bag.fraction=0.844\n",
      "[Tune-y] 133: auc.test.mean=0.7387829; time: 0.1 min\n",
      "[Tune-x] 134: distribution=bernoulli; n.trees=134; interaction.depth=6; n.minobsinnode=54; shrinkage=0.555; bag.fraction=0.392\n",
      "[Tune-y] 134: auc.test.mean=0.7404374; time: 0.1 min\n",
      "[Tune-x] 135: distribution=bernoulli; n.trees=334; interaction.depth=7; n.minobsinnode=74; shrinkage=0.599; bag.fraction=0.32\n",
      "[Tune-y] 135: auc.test.mean=0.7192080; time: 0.2 min\n",
      "[Tune-x] 136: distribution=bernoulli; n.trees=167; interaction.depth=7; n.minobsinnode=59; shrinkage=0.947; bag.fraction=0.371\n",
      "[Tune-y] 136: auc.test.mean=0.7104570; time: 0.1 min\n",
      "[Tune-x] 137: distribution=bernoulli; n.trees=305; interaction.depth=2; n.minobsinnode=20; shrinkage=0.428; bag.fraction=0.496\n",
      "[Tune-y] 137: auc.test.mean=0.7626409; time: 0.1 min\n",
      "[Tune-x] 138: distribution=bernoulli; n.trees=233; interaction.depth=3; n.minobsinnode=56; shrinkage=0.524; bag.fraction=0.777\n",
      "[Tune-y] 138: auc.test.mean=0.7545682; time: 0.1 min\n",
      "[Tune-x] 139: distribution=bernoulli; n.trees=709; interaction.depth=6; n.minobsinnode=37; shrinkage=0.28; bag.fraction=0.128\n",
      "[Tune-y] 139: auc.test.mean=0.7369110; time: 0.2 min\n",
      "[Tune-x] 140: distribution=bernoulli; n.trees=636; interaction.depth=3; n.minobsinnode=66; shrinkage=0.47; bag.fraction=0.937\n",
      "[Tune-y] 140: auc.test.mean=0.7460351; time: 0.2 min\n",
      "[Tune-x] 141: distribution=bernoulli; n.trees=417; interaction.depth=4; n.minobsinnode=61; shrinkage=0.0265; bag.fraction=0.287\n",
      "[Tune-y] 141: auc.test.mean=0.7618324; time: 0.1 min\n",
      "[Tune-x] 142: distribution=bernoulli; n.trees=430; interaction.depth=4; n.minobsinnode=51; shrinkage=0.373; bag.fraction=0.752\n",
      "[Tune-y] 142: auc.test.mean=0.7460266; time: 0.2 min\n",
      "[Tune-x] 143: distribution=bernoulli; n.trees=413; interaction.depth=7; n.minobsinnode=21; shrinkage=0.655; bag.fraction=0.158\n",
      "[Tune-y] 143: auc.test.mean=0.6285205; time: 0.1 min\n",
      "[Tune-x] 144: distribution=bernoulli; n.trees=474; interaction.depth=5; n.minobsinnode=63; shrinkage=0.194; bag.fraction=0.19\n",
      "[Tune-y] 144: auc.test.mean=0.7474185; time: 0.1 min\n",
      "[Tune-x] 145: distribution=bernoulli; n.trees=163; interaction.depth=4; n.minobsinnode=43; shrinkage=0.192; bag.fraction=0.971\n",
      "[Tune-y] 145: auc.test.mean=0.7638167; time: 0.1 min\n",
      "[Tune-x] 146: distribution=bernoulli; n.trees=184; interaction.depth=7; n.minobsinnode=26; shrinkage=0.757; bag.fraction=0.925\n",
      "[Tune-y] 146: auc.test.mean=0.7196600; time: 0.1 min\n",
      "[Tune-x] 147: distribution=bernoulli; n.trees=294; interaction.depth=10; n.minobsinnode=64; shrinkage=0.799; bag.fraction=0.977\n",
      "[Tune-y] 147: auc.test.mean=0.7227356; time: 0.3 min\n",
      "[Tune-x] 148: distribution=bernoulli; n.trees=276; interaction.depth=9; n.minobsinnode=12; shrinkage=0.0564; bag.fraction=0.607\n",
      "[Tune-y] 148: auc.test.mean=0.7559442; time: 0.2 min\n",
      "[Tune-x] 149: distribution=bernoulli; n.trees=923; interaction.depth=7; n.minobsinnode=56; shrinkage=0.274; bag.fraction=0.733\n",
      "[Tune-y] 149: auc.test.mean=0.7224471; time: 0.6 min\n",
      "[Tune-x] 150: distribution=bernoulli; n.trees=750; interaction.depth=2; n.minobsinnode=13; shrinkage=0.918; bag.fraction=0.514\n",
      "[Tune-y] 150: auc.test.mean=0.6684211; time: 0.2 min\n",
      "[Tune] Result: distribution=bernoulli; n.trees=837; interaction.depth=2; n.minobsinnode=21; shrinkage=0.0417; bag.fraction=0.847 : auc.test.mean=0.7724785\n"
     ]
    }
   ],
   "source": [
    "#Fit boosting model \n",
    "# Set up cross-validation\n",
    "#load GBM\n",
    "\n",
    "# Define the model\n",
    "g.gbm <- makeLearner(\"classif.gbm\", predict.type = \"prob\")\n",
    "\n",
    "train_task <- makeClassifTask(data=train_processed[, -1], target=\"subscribe\")\n",
    "valid_task <- makeClassifTask(data=valid_processed[, -1], target=\"subscribe\")\n",
    "test_task <- makeClassifTask(data=test_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "\n",
    "#normalize the variables\n",
    "#trainTask <- normalizeFeatures(train_task,method = \"standardize\")\n",
    "#validTask <- normalizeFeatures(valid_task,method = \"standardize\")\n",
    "#testTask <- normalizeFeatures(test_task,method = \"standardize\")\n",
    "#testholdTask <- normalizeFeatures(test_holdout_processed[, -1],method = \"standardize\")\n",
    "\n",
    "#3 fold cross validation\n",
    "set_cv <- makeResampleDesc(\"CV\",iters = 3L)\n",
    "\n",
    "#parameters for hypertuning\n",
    "gbm_par<- makeParamSet(\n",
    "makeDiscreteParam(\"distribution\", values = \"bernoulli\"),\n",
    "makeIntegerParam(\"n.trees\", lower = 100, upper = 1000), #number of trees\n",
    "makeIntegerParam(\"interaction.depth\", lower = 2, upper = 10), #depth of tree\n",
    "makeIntegerParam(\"n.minobsinnode\", lower = 10, upper = 80),\n",
    "makeNumericParam(\"shrinkage\",lower = 0.01, upper = 0.2),\n",
    "makeNumericParam(\"bag.fraction\",lower = 0.1, upper = 1)\n",
    ")\n",
    "\n",
    "#random search for 150 iterations\n",
    "rancontrol <- makeTuneControlRandom(maxit = 150L)\n",
    "\n",
    "\n",
    "#hypertuning with cross validation\n",
    "gb_tune <- tuneParams(learner = g.gbm, resampling = set_cv, task = train_task, par.set = gbm_par, control = rancontrol, measures =list(mlr::auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using best hyperparameters for modeling\n",
    "gbm <- setHyperPars(g.gbm, par.vals = gb_tune$x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "gb_best_md <- mlr::train(gbm, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.803620789990543"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.803620789990543"
      ],
      "text/markdown": [
       "**auc:** 0.803620789990543"
      ],
      "text/plain": [
       "      auc \n",
       "0.8036208 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on valid data\n",
    "gb_pred <- predict(gb_best_md, newdata=valid_processed[, -1])\n",
    "performance(gb_pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.821192840334205"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.821192840334205"
      ],
      "text/markdown": [
       "**auc:** 0.821192840334205"
      ],
      "text/plain": [
       "      auc \n",
       "0.8211928 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "gb_pred <- predict(gb_best_md, newdata=test_processed[, -1])\n",
    "performance(gb_pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction: 3000 observations\n",
       "predict.type: prob\n",
       "threshold: 0=0.50,1=0.50\n",
       "time: 0.05\n",
       "      prob.1    prob.0 response\n",
       "1 0.05882029 0.9411797        0\n",
       "2 0.05032549 0.9496745        0\n",
       "3 0.45079148 0.5492085        0\n",
       "4 0.05193031 0.9480697        0\n",
       "5 0.04033182 0.9596682        0\n",
       "6 0.05417536 0.9458246        0\n",
       "... (#rows: 3000, #cols: 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "gb_pred <- predict(gb_best_md, newdata=test_holdout_processed[, -1])\n",
    "gb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predicted file\n",
    "output <- data.frame(client_id=test_holdout$client_id, subscribe=gb_pred$data$prob.1)\n",
    "write.csv(output, 'C:/Users/skamal/Downloads/gbm_submission_clean3.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'xgboost' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"cannot remove prior installation of package 'xgboost'\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\skamal\\AppData\\Local\\Temp\\RtmpYPm7ns\\downloaded_packages\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(xgboost): there is no package called 'xgboost'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(xgboost): there is no package called 'xgboost'\nTraceback:\n",
      "1. library(xgboost)"
     ]
    }
   ],
   "source": [
    "#install.packages('devtools')\n",
    "#install.packages(\"xgboost\")\n",
    "#devtools::install_github('dmlc/xgboost',subdir='R-package')\n",
    "#library(xgboost)\n",
    "\n",
    "# 3-fold cross validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=3)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.xgboost\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "\n",
    "train_task <- makeClassifTask(data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "makeIntegerParam(\"nrounds\",lower=200,upper=600),\n",
    "makeIntegerParam(\"max_depth\",lower=3,upper=10),\n",
    "makeNumericParam(\"lambda\",lower=0.55,upper=0.60),\n",
    "makeNumericParam(\"eta\", lower = 0.001, upper = 0.5),\n",
    "makeNumericParam(\"subsample\", lower = 0.10, upper = 0.80),\n",
    "makeNumericParam(\"min_child_weight\",lower=1,upper=5),\n",
    "makeNumericParam(\"colsample_bytree\",lower = 0.2,upper = 0.8)\n",
    ")\n",
    "\n",
    "ctrl = makeTuneControlRandom(maxit = 100L)\n",
    "#\n",
    "## Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "#    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "#    \n",
    "} else {\n",
    "   \n",
    "\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "        \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "xg_best_md <- mlr::train(best_learner, trainTask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on valid data\n",
    "xg_pred <- predict(xg_best_md, newdata=valid_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "xg_pred <- predict(xg_best_md, newdata=test_processed[, -1])\n",
    "performance(pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Support Vector Machine Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'kernlab' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\skamal\\AppData\\Local\\Temp\\RtmpYPm7ns\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'kernlab' was built under R version 3.6.1\"\n",
      "Attaching package: 'kernlab'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    alpha\n",
      "\n",
      "[Tune] Started tuning learner classif.ksvm for parameter set:\n",
      "          Type len Def                   Constr Req Tunable Trafo\n",
      "C     discrete   -   - 0.00390625,0.0625,0.25,1   -    TRUE     -\n",
      "sigma discrete   -   -   0.00390625,0.0625,1,16   -    TRUE     -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: C=0.00390625; sigma=0.00390625\n",
      "[Tune-y] 1: auc.test.mean=0.6356732; time: 0.1 min\n",
      "[Tune-x] 2: C=0.0625; sigma=0.00390625\n",
      "[Tune-y] 2: auc.test.mean=0.6523059; time: 0.1 min\n",
      "[Tune-x] 3: C=0.25; sigma=0.00390625\n",
      "[Tune-y] 3: auc.test.mean=0.6718434; time: 0.1 min\n",
      "[Tune-x] 4: C=1; sigma=0.00390625\n",
      "[Tune-y] 4: auc.test.mean=0.5547750; time: 0.1 min\n",
      "[Tune-x] 5: C=0.00390625; sigma=0.0625\n",
      "[Tune-y] 5: auc.test.mean=0.6203126; time: 0.1 min\n",
      "[Tune-x] 6: C=0.0625; sigma=0.0625\n",
      "[Tune-y] 6: auc.test.mean=0.5958400; time: 0.1 min\n",
      "[Tune-x] 7: C=0.25; sigma=0.0625\n",
      "[Tune-y] 7: auc.test.mean=0.6697200; time: 0.1 min\n",
      "[Tune-x] 8: C=1; sigma=0.0625\n",
      "[Tune-y] 8: auc.test.mean=0.6232773; time: 0.1 min\n",
      "[Tune-x] 9: C=0.00390625; sigma=1\n",
      "[Tune-y] 9: auc.test.mean=0.6313144; time: 0.1 min\n",
      "[Tune-x] 10: C=0.0625; sigma=1\n",
      "[Tune-y] 10: auc.test.mean=0.6887581; time: 0.1 min\n",
      "[Tune-x] 11: C=0.25; sigma=1\n",
      "[Tune-y] 11: auc.test.mean=0.6534037; time: 0.1 min\n",
      "[Tune-x] 12: C=1; sigma=1\n",
      "[Tune-y] 12: auc.test.mean=0.6583405; time: 0.1 min\n",
      "[Tune-x] 13: C=0.00390625; sigma=16\n",
      "[Tune-y] 13: auc.test.mean=0.6196543; time: 0.0 min\n",
      "[Tune-x] 14: C=0.0625; sigma=16\n",
      "[Tune-y] 14: auc.test.mean=0.6401173; time: 0.1 min\n",
      "[Tune-x] 15: C=0.25; sigma=16\n",
      "[Tune-y] 15: auc.test.mean=0.6545957; time: 0.1 min\n",
      "[Tune-x] 16: C=1; sigma=16\n",
      "[Tune-y] 16: auc.test.mean=0.6364439; time: 0.1 min\n",
      "[Tune] Result: C=0.0625; sigma=1 : auc.test.mean=0.6887581\n"
     ]
    }
   ],
   "source": [
    "# install package \n",
    "install.packages('kernlab')\n",
    "library(kernlab)\n",
    "\n",
    "# 3-fold cross validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=3)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.ksvm\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "train_task <- makeClassifTask(data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "makeDiscreteParam(\"C\", values = 2^c(-8,-4,-2,0)), #cost parameters\n",
    "makeDiscreteParam(\"sigma\", values = 2^c(-8,-4,0,4)) #RBF Kernel Parameter\n",
    ")\n",
    "\n",
    "ctrl <- makeTuneControlGrid()\n",
    "#\n",
    "## Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "      par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "#    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "#    \n",
    "} else {\n",
    "   \n",
    "\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "        \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "svm_best_md <- mlr::train(best_learner, train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.612770058921947"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.612770058921947"
      ],
      "text/markdown": [
       "**auc:** 0.612770058921947"
      ],
      "text/plain": [
       "      auc \n",
       "0.6127701 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction on valid data\n",
    "svm_pred <- predict(svm_best_md, newdata=valid_processed[, -1])\n",
    "performance(svm_pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "svm_pred <- predict(svm_best_md, newdata=test_processed[, -1])\n",
    "performance(svm_pred, measures=mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. Methodology - Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"package 'Metrics' is in use and will not be installed\"Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"package 'DMwR' is in use and will not be installed\""
     ]
    }
   ],
   "source": [
    "# install packages \n",
    "library(caret)\n",
    "install.packages('Metrics')\n",
    "library(Metrics)\n",
    "install.packages(\"DMwR\")\n",
    "library(DMwR)\n",
    "library(data.table)\n",
    "library(ggplot2)\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(e1071) \n",
    "library(dplyr)\n",
    "install.packages(\"ROCR\")\n",
    "library(ROCR)\n",
    "library(MASS)\n",
    "library(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the subscribe variable to factor - some models give errors if this not done\n",
    "train_processed$subscribe <- as.factor(train_processed$subscribe)\n",
    "valid_processed$subscribe <- as.factor(valid_processed$subscribe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Logistic Regression - WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = subscribe ~ ., family = binomial(link = \"logit\"), \n",
       "    data = train_processed[, -1])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9195  -0.3838  -0.3062  -0.2653   2.6252  \n",
       "\n",
       "Coefficients: (21 not defined because of singularities)\n",
       "                                     Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)                        -1.863e+02  2.915e+02  -0.639   0.5227  \n",
       "pdays                              -6.862e-02  4.258e-02  -1.612   0.1070  \n",
       "emp_var_rate                        2.701e+00  2.191e+00   1.233   0.2176  \n",
       "euribor3m                           2.516e+00  1.079e+00   2.332   0.0197 *\n",
       "nr_employed                         3.918e-02  5.872e-02   0.667   0.5047  \n",
       "pdays_999                           6.656e+01  4.226e+01   1.575   0.1153  \n",
       "nremply_ge_mean                    -4.752e+01  8.421e+02  -0.056   0.9550  \n",
       "pdays_ge_mean                              NA         NA      NA       NA  \n",
       "emp_varrate_positive                1.474e+01  7.783e+02   0.019   0.9849  \n",
       "emp_varrate_ge_mean                        NA         NA      NA       NA  \n",
       "woe_month_binned                   -1.332e-02  1.195e-02  -1.115   0.2648  \n",
       "woe_emp_var_rate_binned             1.615e-01  5.412e+00   0.030   0.9762  \n",
       "woe_cons_price_idx_binned          -2.240e-02  1.316e-02  -1.702   0.0887 .\n",
       "woe_cons_conf_idx_binned            9.593e-03  8.794e-03   1.091   0.2753  \n",
       "woe_euribor3m_binned               -2.942e-03  4.716e-03  -0.624   0.5327  \n",
       "woe_nr_employed_binned             -9.700e-02  6.020e+00  -0.016   0.9871  \n",
       "month_binned_nov_aug_jun_jul_may   -8.826e-01  1.447e+00  -0.610   0.5419  \n",
       "emp_var_rate_binned___0_1_Inf_             NA         NA      NA       NA  \n",
       "euribor3m_binned___Inf_1_262_       3.283e-01  7.201e-01   0.456   0.6485  \n",
       "euribor3m_binned__4_076_Inf_               NA         NA      NA       NA  \n",
       "nr_employed_binned___Inf_5076_2_           NA         NA      NA       NA  \n",
       "nr_employed_binned__5099_1_Inf_            NA         NA      NA       NA  \n",
       "euribor3m_width_bin__0_634_1_5162_ -8.047e+00  8.887e+00  -0.905   0.3653  \n",
       "month_incidence                     1.036e+01  1.012e+01   1.024   0.3057  \n",
       "month_binned_incidence                     NA         NA      NA       NA  \n",
       "emp_var_rate_binned_incidence              NA         NA      NA       NA  \n",
       "cons_price_idx_binned_incidence     1.393e+01  1.109e+01   1.256   0.2093  \n",
       "cons_conf_idx_binned_incidence     -2.877e+00  7.888e+00  -0.365   0.7153  \n",
       "euribor3m_binned_incidence                 NA         NA      NA       NA  \n",
       "nr_employed_binned_incidence               NA         NA      NA       NA  \n",
       "emp_var_rate_freq_bin_incidence    -7.921e+01  3.226e+03  -0.025   0.9804  \n",
       "euribor3m_freq_bin_incidence       -4.486e+00  5.991e+00  -0.749   0.4540  \n",
       "nr_employed_freq_bin_incidence      5.240e+01  3.238e+03   0.016   0.9871  \n",
       "emp_var_rate_width_bin_incidence   -8.584e-01  5.740e+00  -0.150   0.8811  \n",
       "cons_conf_idx_width_bin_incidence   1.733e+01  1.092e+01   1.587   0.1126  \n",
       "euribor3m_width_bin_incidence      -4.097e+01  4.768e+01  -0.859   0.3903  \n",
       "nr_employed_width_bin_incidence     1.385e+01  1.346e+01   1.030   0.3032  \n",
       "month_woe                          -7.907e-01  1.929e+00  -0.410   0.6819  \n",
       "month_binned_woe                           NA         NA      NA       NA  \n",
       "emp_var_rate_binned_woe                    NA         NA      NA       NA  \n",
       "cons_price_idx_binned_woe                  NA         NA      NA       NA  \n",
       "cons_conf_idx_binned_woe                   NA         NA      NA       NA  \n",
       "euribor3m_binned_woe                       NA         NA      NA       NA  \n",
       "nr_employed_binned_woe                     NA         NA      NA       NA  \n",
       "emp_var_rate_freq_bin_woe                  NA         NA      NA       NA  \n",
       "euribor3m_freq_bin_woe              1.232e+00  9.047e-01   1.362   0.1733  \n",
       "nr_employed_freq_bin_woe                   NA         NA      NA       NA  \n",
       "emp_var_rate_width_bin_woe                 NA         NA      NA       NA  \n",
       "cons_conf_idx_width_bin_woe        -2.328e+00  1.690e+00  -1.377   0.1684  \n",
       "euribor3m_width_bin_woe                    NA         NA      NA       NA  \n",
       "nr_employed_width_bin_woe                  NA         NA      NA       NA  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 3527.6  on 4899  degrees of freedom\n",
       "Residual deviance: 2794.6  on 4870  degrees of freedom\n",
       "AIC: 2854.6\n",
       "\n",
       "Number of Fisher Scoring iterations: 11\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train logistic regression model and view results\n",
    "log = glm(subscribe ~ ., family=binomial(link=\"logit\"),data=train_processed[, -1])\n",
    "summary(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "        predicted\n",
       "observed   0   1\n",
       "       0 920  12\n",
       "       1  94  24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on validation set\n",
    "log.pred = plogis(predict(log, newdata = valid_processed[, -1]))\n",
    "\n",
    "# if probabibility is > 0.5 consider as subscribe\n",
    "log.pred2 <- ifelse(log.pred > 0.5,1,0)\n",
    "\n",
    "# look at the confusion matrix \n",
    "table(observed=valid_processed$subscribe,predicted=log.pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.9293853 </td><td>0.07061475</td></tr>\n",
       "\t<tr><td>0.9641667 </td><td>0.03583332</td></tr>\n",
       "\t<tr><td>0.9277255 </td><td>0.07227447</td></tr>\n",
       "\t<tr><td>0.9654199 </td><td>0.03458010</td></tr>\n",
       "\t<tr><td>0.8876674 </td><td>0.11233265</td></tr>\n",
       "\t<tr><td>0.9295502 </td><td>0.07044980</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " 0 & 1\\\\\n",
       "\\hline\n",
       "\t 0.9293853  & 0.07061475\\\\\n",
       "\t 0.9641667  & 0.03583332\\\\\n",
       "\t 0.9277255  & 0.07227447\\\\\n",
       "\t 0.9654199  & 0.03458010\\\\\n",
       "\t 0.8876674  & 0.11233265\\\\\n",
       "\t 0.9295502  & 0.07044980\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 1 |\n",
       "|---|---|\n",
       "| 0.9293853  | 0.07061475 |\n",
       "| 0.9641667  | 0.03583332 |\n",
       "| 0.9277255  | 0.07227447 |\n",
       "| 0.9654199  | 0.03458010 |\n",
       "| 0.8876674  | 0.11233265 |\n",
       "| 0.9295502  | 0.07044980 |\n",
       "\n"
      ],
      "text/plain": [
       "  0         1         \n",
       "1 0.9293853 0.07061475\n",
       "2 0.9641667 0.03583332\n",
       "3 0.9277255 0.07227447\n",
       "4 0.9654199 0.03458010\n",
       "5 0.8876674 0.11233265\n",
       "6 0.9295502 0.07044980"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert output to a form that has 2 columns - probability for 0 and 1\n",
    "log_df <- data.frame(log.pred)\n",
    "log_df$one <- log_df$log.pred\n",
    "log_df$zero <- 1 - log_df$log.pred\n",
    "log_df <- log_df[-1]\n",
    "log_df[, '0'] <- log_df[, 'zero'] \n",
    "log_df[, '1'] <- log_df[, 1]\n",
    "log_df <- log_df[-1]\n",
    "log_df <- log_df[-1]\n",
    "head(log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8127955\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8127955\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAujhNTU1oaGh8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\nhAQIEBIgQEiAACEBAoQECBASIEBIgMB/qmUbDWZYan0AAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  import ROCR package for ROC curve plotting - AUC is 81% without resampling\n",
    "library(ROCR)\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_log_roc_curve <- log_df\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(valid_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_log_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.log.valid <- performance(pred, measure = \"auc\")\n",
    " print(auc.log.valid@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.899047619047619"
      ],
      "text/latex": [
       "0.899047619047619"
      ],
      "text/markdown": [
       "0.899047619047619"
      ],
      "text/plain": [
       "[1] 0.8990476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.203389830508475"
      ],
      "text/latex": [
       "0.203389830508475"
      ],
      "text/markdown": [
       "0.203389830508475"
      ],
      "text/plain": [
       "[1] 0.2033898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on validation set -  89.9% accuracy without oversampling\n",
    "log_acc_valid <- accuracy(valid_processed$subscribe, log.pred2)\n",
    "log_acc_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Logistic Regression -  RESAMPLING WITH SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2284 1713 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resample the data in the train set using SMOTE - makes the classes more balanced \n",
    "# undersamples majority class (0) and oversamples minority class (1)\n",
    "set.seed(1)\n",
    "up_train <- SMOTE(subscribe ~ ., data  = train_processed[, -51])                         \n",
    "table(up_train$subscribe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = subscribe ~ ., family = binomial(link = \"logit\"), \n",
       "    data = up_train[, -1])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-3.0875  -0.8061  -0.5920   0.8347   1.9135  \n",
       "\n",
       "Coefficients: (21 not defined because of singularities)\n",
       "                                     Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)                        -1.535e+02  2.738e+02  -0.561   0.5750  \n",
       "pdays                              -8.219e-02  5.764e-02  -1.426   0.1539  \n",
       "emp_var_rate                        4.802e+00  2.498e+00   1.922   0.0546 .\n",
       "euribor3m                           1.725e+00  9.523e-01   1.811   0.0701 .\n",
       "nr_employed                         3.458e-02  5.772e-02   0.599   0.5492  \n",
       "pdays_999                           7.959e+01  5.717e+01   1.392   0.1639  \n",
       "nremply_ge_mean                    -3.653e+01  2.846e+01  -1.283   0.1994  \n",
       "pdays_ge_mean                              NA         NA      NA       NA  \n",
       "emp_varrate_positive                1.543e+01  3.143e+01   0.491   0.6234  \n",
       "emp_varrate_ge_mean                        NA         NA      NA       NA  \n",
       "woe_month_binned                   -1.508e-02  1.210e-02  -1.246   0.2129  \n",
       "woe_emp_var_rate_binned             1.926e-01  2.868e-01   0.671   0.5019  \n",
       "woe_cons_price_idx_binned          -1.764e-02  1.090e-02  -1.617   0.1058  \n",
       "woe_cons_conf_idx_binned            1.034e-02  8.171e-03   1.266   0.2056  \n",
       "woe_euribor3m_binned               -1.934e-03  3.185e-03  -0.607   0.5437  \n",
       "woe_nr_employed_binned             -6.287e-03  1.352e-02  -0.465   0.6418  \n",
       "month_binned_nov_aug_jun_jul_may   -9.803e-01  1.437e+00  -0.682   0.4952  \n",
       "emp_var_rate_binned___0_1_Inf_             NA         NA      NA       NA  \n",
       "euribor3m_binned___Inf_1_262_       3.618e-01  4.947e-01   0.731   0.4646  \n",
       "euribor3m_binned__4_076_Inf_               NA         NA      NA       NA  \n",
       "nr_employed_binned___Inf_5076_2_           NA         NA      NA       NA  \n",
       "nr_employed_binned__5099_1_Inf_            NA         NA      NA       NA  \n",
       "euribor3m_width_bin__0_634_1_5162_ -5.540e+00  6.071e+00  -0.912   0.3615  \n",
       "month_incidence                     1.036e+01  9.720e+00   1.066   0.2863  \n",
       "month_binned_incidence                     NA         NA      NA       NA  \n",
       "emp_var_rate_binned_incidence              NA         NA      NA       NA  \n",
       "cons_price_idx_binned_incidence     1.149e+01  1.003e+01   1.146   0.2517  \n",
       "cons_conf_idx_binned_incidence     -5.012e+00  7.701e+00  -0.651   0.5151  \n",
       "euribor3m_binned_incidence                 NA         NA      NA       NA  \n",
       "nr_employed_binned_incidence               NA         NA      NA       NA  \n",
       "emp_var_rate_freq_bin_incidence    -7.217e+01  1.642e+02  -0.439   0.6603  \n",
       "euribor3m_freq_bin_incidence       -6.238e+00  3.934e+00  -1.586   0.1128  \n",
       "nr_employed_freq_bin_incidence             NA         NA      NA       NA  \n",
       "emp_var_rate_width_bin_incidence   -7.254e+00  6.032e+00  -1.203   0.2291  \n",
       "cons_conf_idx_width_bin_incidence   1.213e+01  1.129e+01   1.075   0.2826  \n",
       "euribor3m_width_bin_incidence      -2.969e+01  3.240e+01  -0.917   0.3594  \n",
       "nr_employed_width_bin_incidence     1.529e+01  1.366e+01   1.120   0.2629  \n",
       "month_woe                          -4.701e-01  1.759e+00  -0.267   0.7893  \n",
       "month_binned_woe                           NA         NA      NA       NA  \n",
       "emp_var_rate_binned_woe                    NA         NA      NA       NA  \n",
       "cons_price_idx_binned_woe                  NA         NA      NA       NA  \n",
       "cons_conf_idx_binned_woe                   NA         NA      NA       NA  \n",
       "euribor3m_binned_woe                       NA         NA      NA       NA  \n",
       "nr_employed_binned_woe                     NA         NA      NA       NA  \n",
       "emp_var_rate_freq_bin_woe                  NA         NA      NA       NA  \n",
       "euribor3m_freq_bin_woe              1.303e+00  5.847e-01   2.228   0.0259 *\n",
       "nr_employed_freq_bin_woe                   NA         NA      NA       NA  \n",
       "emp_var_rate_width_bin_woe                 NA         NA      NA       NA  \n",
       "cons_conf_idx_width_bin_woe        -1.532e+00  1.730e+00  -0.885   0.3759  \n",
       "euribor3m_width_bin_woe                    NA         NA      NA       NA  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 5459.2  on 3996  degrees of freedom\n",
       "Residual deviance: 4212.0  on 3968  degrees of freedom\n",
       "AIC: 4270\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert target variable to factor in order for the model to work correctly\n",
    "up_train$subscribe <- as.factor(up_train$subscribe)\n",
    "\n",
    "# train the logistic regression model on resampled train data\n",
    "log.up = glm(subscribe ~ ., family=binomial(link=\"logit\"),data=up_train[, -1])\n",
    "summary(log.up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "        predicted\n",
       "observed   0   1\n",
       "       0 801 131\n",
       "       1  47  71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test on validation set\n",
    "log.pred.up = plogis(predict(log.up, newdata = valid_processed[, -1]))\n",
    "\n",
    "# if probabibility is > 0.5 consider as subscribe\n",
    "log.pred.up2 <- ifelse(log.pred.up > 0.5,1,0)\n",
    "\n",
    "# look at the confusion matrix\n",
    "table(observed=valid_processed$subscribe,predicted=log.pred.up2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.7093839</td><td>0.2906161</td></tr>\n",
       "\t<tr><td>0.8309753</td><td>0.1690247</td></tr>\n",
       "\t<tr><td>0.6826308</td><td>0.3173692</td></tr>\n",
       "\t<tr><td>0.8392439</td><td>0.1607561</td></tr>\n",
       "\t<tr><td>0.6243371</td><td>0.3756629</td></tr>\n",
       "\t<tr><td>0.7097393</td><td>0.2902607</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " 0 & 1\\\\\n",
       "\\hline\n",
       "\t 0.7093839 & 0.2906161\\\\\n",
       "\t 0.8309753 & 0.1690247\\\\\n",
       "\t 0.6826308 & 0.3173692\\\\\n",
       "\t 0.8392439 & 0.1607561\\\\\n",
       "\t 0.6243371 & 0.3756629\\\\\n",
       "\t 0.7097393 & 0.2902607\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 1 |\n",
       "|---|---|\n",
       "| 0.7093839 | 0.2906161 |\n",
       "| 0.8309753 | 0.1690247 |\n",
       "| 0.6826308 | 0.3173692 |\n",
       "| 0.8392439 | 0.1607561 |\n",
       "| 0.6243371 | 0.3756629 |\n",
       "| 0.7097393 | 0.2902607 |\n",
       "\n"
      ],
      "text/plain": [
       "  0         1        \n",
       "1 0.7093839 0.2906161\n",
       "2 0.8309753 0.1690247\n",
       "3 0.6826308 0.3173692\n",
       "4 0.8392439 0.1607561\n",
       "5 0.6243371 0.3756629\n",
       "6 0.7097393 0.2902607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert output to a form that has 2 columns - probability for 0 and 1\n",
    "log_df_up <- data.frame(log.pred.up)\n",
    "log_df_up$one <- log_df_up$log.pred.up\n",
    "log_df_up$zero <- 1 - log_df_up$log.pred.up\n",
    "log_df_up <- log_df_up[-1]\n",
    "log_df_up[, '0'] <- log_df_up[, 'zero'] \n",
    "log_df_up[, '1'] <- log_df_up[, 1]\n",
    "log_df_up <- log_df_up[-1]\n",
    "log_df_up <- log_df_up[-1]\n",
    "head(log_df_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8082582\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8082582\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAujhNTU1oaGh8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\nACEBAoQECPwH4NAa+1ud21YAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  import ROCR package for ROC curve plotting - AUC is 80.8% with resampling, slight drop from the initial model (81%)\n",
    "library(ROCR)\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_log_up_roc_curve <- log_df_up\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(valid_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_log_up_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.log.valid.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.log.valid.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.83047619047619"
      ],
      "text/latex": [
       "0.83047619047619"
      ],
      "text/markdown": [
       "0.83047619047619"
      ],
      "text/plain": [
       "[1] 0.8304762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.601694915254237"
      ],
      "text/latex": [
       "0.601694915254237"
      ],
      "text/markdown": [
       "0.601694915254237"
      ],
      "text/plain": [
       "[1] 0.6016949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuarcay on validation set - 83% with resampling - accuracy decreases from model without resampling\n",
    "log_acc_valid_up <- accuracy(valid_processed$subscribe, log.pred.up2)\n",
    "log_acc_valid_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Decision Tree Model - WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tree\n",
      "Warning message:\n",
      "\"package 'tree' was built under R version 3.6.2\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Classification tree:\n",
       "tree(formula = subscribe ~ ., data = train_processed[, -1])\n",
       "Variables actually used in tree construction:\n",
       "[1] \"nr_employed\"      \"pdays\"            \"woe_month_binned\"\n",
       "Number of terminal nodes:  4 \n",
       "Residual mean deviance:  0.5868 = 2873 / 4896 \n",
       "Misclassification error rate: 0.1033 = 506 / 4900 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(tree)\n",
    "# Fit the classification tree\n",
    "classtree <- tree(subscribe ~ ., data=train_processed[, -1])\n",
    "summary(classtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classification tree\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "plot(classtree, type='uniform')\n",
    "text(classtree, pretty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node), split, n, deviance, yval, (yprob)\n",
       "      * denotes terminal node\n",
       "\n",
       "1) root 4900 3528.0 0 ( 0.88347 0.11653 )  \n",
       "  2) nr_employed < 5087.65 632  862.7 0 ( 0.57278 0.42722 )  \n",
       "    4) pdays < 15.5 145  170.8 1 ( 0.27586 0.72414 ) *\n",
       "    5) pdays > 15.5 487  623.6 0 ( 0.66119 0.33881 ) *\n",
       "  3) nr_employed > 5087.65 4268 2177.0 0 ( 0.92948 0.07052 )  \n",
       "    6) woe_month_binned < 17.527 3920 1706.0 0 ( 0.94337 0.05663 ) *\n",
       "    7) woe_month_binned > 17.527 348  372.8 0 ( 0.77299 0.22701 ) *"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the structure of the tree \n",
    "classtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               \n",
       "tree_pred_valid   0   1\n",
       "              0 924  97\n",
       "              1   8  21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on the validation set \n",
    "tree_pred_valid <- predict(classtree, newdata=valid_processed[, -1], type='class')\n",
    "tree_pred_proba_valid <- predict(classtree, newdata=valid_processed[, -1], type='vector')\n",
    "\n",
    "# look at the confusion matrix\n",
    "table(tree_pred_valid, valid_processed$subscribe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7465902\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7465902\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nCEDV/g9eu7KctH9vuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the AUC - AUC is 74.6% without oversampling\n",
    "#  import ROCR package for ROC curve plotting:\n",
    "library(ROCR)\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_tree_roc_curve <- predict(classtree,valid_processed[, -1],type=\"vector\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(valid_processed$subscribe)\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_tree_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.tree.valid <- performance(pred, measure = \"auc\")\n",
    " print(auc.tree.valid@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.9"
      ],
      "text/latex": [
       "0.9"
      ],
      "text/markdown": [
       "0.9"
      ],
      "text/plain": [
       "[1] 0.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(predicted[actual == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - 90% accuracy without oversampling\n",
    "tree_acc_valid <- accuracy(valid_processed$subscribe, tree_pred_valid)\n",
    "tree_acc_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Decision Tree - WITH OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2284 1713 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resample the data in the train set using SMOTE - makes the classes more balanced \n",
    "# undersamples majority class (0) and oversamples minority class (1)\n",
    "set.seed(1)\n",
    "up_train <- SMOTE(subscribe ~ ., data  = train_processed[, -51])                         \n",
    "table(up_train$subscribe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Classification tree:\n",
       "tree(formula = subscribe ~ ., data = up_train[, -1])\n",
       "Variables actually used in tree construction:\n",
       "[1] \"nr_employed\"                  \"pdays\"                       \n",
       "[3] \"woe_month_binned\"             \"euribor3m_freq_bin_incidence\"\n",
       "[5] \"euribor3m_freq_bin_woe\"      \n",
       "Number of terminal nodes:  6 \n",
       "Residual mean deviance:  1.039 = 4145 / 3991 \n",
       "Misclassification error rate: 0.2337 = 934 / 3997 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert target variable to factor for the model to run without error \n",
    "up_train$subscribe <- as.factor(up_train$subscribe)\n",
    "\n",
    "classtree.up <- tree(subscribe ~ ., data=up_train[, -1])\n",
    "summary(classtree.up) \n",
    "# with resampling the misclassification error rate goes up from 10% to 23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nmkYIQNU0QgCqphECUDWNEICqaYQAVO0/GhZhvY40G+wAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classification tree\n",
    "options(repr.plot.width=15, repr.plot.height=6)\n",
    "plot(classtree.up, type='uniform')\n",
    "text(classtree.up, pretty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node), split, n, deviance, yval, (yprob)\n",
       "      * denotes terminal node\n",
       "\n",
       " 1) root 3997 5459.00 0 ( 0.57143 0.42857 )  \n",
       "   2) nr_employed < 5087.65 997  962.40 1 ( 0.18756 0.81244 )  \n",
       "     4) pdays < 8.96413 289   80.16 1 ( 0.03114 0.96886 ) *\n",
       "     5) pdays > 8.96413 708  798.50 1 ( 0.25141 0.74859 ) *\n",
       "   3) nr_employed > 5087.65 3000 3670.00 0 ( 0.69900 0.30100 )  \n",
       "     6) woe_month_binned < -28.3375 2628 2975.00 0 ( 0.74658 0.25342 )  \n",
       "      12) euribor3m_freq_bin_incidence < 0.0531358 1156 1077.00 0 ( 0.82353 0.17647 ) *\n",
       "      13) euribor3m_freq_bin_incidence > 0.0531358 1472 1832.00 0 ( 0.68614 0.31386 )  \n",
       "        26) euribor3m_freq_bin_woe < -2.81499 54    0.00 1 ( 0.00000 1.00000 ) *\n",
       "        27) euribor3m_freq_bin_woe > -2.81499 1418 1702.00 0 ( 0.71227 0.28773 ) *\n",
       "     7) woe_month_binned > -28.3375 372  487.40 1 ( 0.36290 0.63710 ) *"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the structure of the tree\n",
    "classtree.up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  \n",
       "tree_pred_valid_up   0   1\n",
       "                 0 805  47\n",
       "                 1 127  71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on the validation set \n",
    "\n",
    "tree_pred_valid_up <- predict(classtree.up, newdata=valid_processed[, -1], type='class')\n",
    "tree_pred_proba_valid_up <- predict(classtree.up, newdata=valid_processed[, -1], type='vector')\n",
    "\n",
    "# look at the confusion matrix\n",
    "table(tree_pred_valid_up, valid_processed$subscribe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7781107\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7781107\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD4dm3///+pGrSCAAAACXBIWXMA\nABJ0AAASdAHeZh94AAAgAElEQVR4nO3diVbqyBqA0eoAgiJweP+XbQKozBAyVfLvve7yYBSS\nmxY/K2PaAkBgqe8FAIA+CSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEA\noQkhAKEJIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJ\nIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEAoQkhAKEJIQChCSEA\noQkhAKEJIQChCSEAoQkhtCb9mH3+Tlt+FClNPpZ/3/X9MUmpmH1dPvvedKBZQgitSX+mhynr\n6e+EzfGbZj9Tiu+zJ9+bDjRMCKE1JyFM+zHhpvibUBxKOD35ntXJc+9NB5omhNCaXcP2/27m\nKU3KB+Uob7HeDQw/y+2lxynF5+Z0ysG96UDjhBBa8xPCn0ffu3+O2znXh4Heate79WHKarJY\n/z7zevrPax3/3f2znqT57hU/9pM/Dq+8mRepmP+9DvCcEEJrLkO4GxjOf7622D+eH7eZXrqe\nfh3CSbnnsfidXOw+ro+bXu1VhAqEEFrzE6/1x2Hz5vRkd99qfwDNbsrN4dv19OsQ7nyVxSwP\nQF0eEvuzC7Jo4f8MjJYQQmtOD5b53p6OEH8+OZuyvfjizSl/Idwfd7o6bBs9bBn93E/cfJSF\nBF4lhNCakw4uj5+ffbFeCA+nIk5S2rXvcDDOrHy8/6LDa+B1Qgit+c3gYvPz+dkX64Xw8JqL\ncvj3tZvF6fxsG4UKhBBas49WeQ798QjQydU+wsmdkwSvp1+H8DB9Xb7OcZfiyQi08f8vMF7e\nL9CaY5CmPxeWOT1qdF77qNHjF8ojcI6nKRYCCG/wvoHW/NSqOB698v27Z688zLMc833/nS/4\nfXoe4fX047bQ76sQfqU0O2Zz9vvywOuEEFrzU6vvn5125XXTytPd1/OrK8ss7lxZ5md6sR9B\nfhdXIdzsN4Xudxh+HS5M+vV7aVPgBUIIrfmt1c+QbX11rdGzq4+enDp4Nf3jfP/fyW7A8ivH\n8P0+yRn18DohhNacHtFyGLOd3H3iWL3N75TJ2Sn0l9PXh0/m1yEst7J+/T3cf1fb/89gTIQQ\nWvNXq/nvds/9/QiL0/sRXt+h8Ob01W7kN/26Pljm5FSK8lqjk92c7CiEKoQQgNCEEIDQhBCA\n0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCE\nEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA\n0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0DoIYQKAjrxRqebD18MsAKAk\nhACEJoQAhCaEAITWaQi/F7P9fsnZ/LutWQBAJR2GcDM5OUZn2sosAKCiDkM4T8XXav9ovSzS\nvI1ZAEBFHYawSKvfx6tUtDELAKiowxCenbP4+ARGIQSgI0aEAITW7T7C5Xr/yD5CAHLR5ekT\n05OjRiebVmYBANV0ex7hfH8eYTFbOI8QgDy4sgwAoQkhAKEJIQCh9RVC5xECkIV8QljzdsEA\njN2/a/8d1HlVm0YB6MGNqD11fOp/JxpYEiEEoKYaUXvRfw3H75QQAnCi/ai9qM32nRFCgEj6\nidqrumrfGSEEGLOsOndLZwO/u4QQYFRyD1+p9/ad6fR+hC+fISGEAC/Kfsh30P/A764OQ/gp\nhAC1DSR8pXzbd6bLTaOrYtr2LABGZzjh22Y98Lur032Eq8e3421iFgBDN6Ah394Q23em24Nl\nPtOq7VkADM3AwlcaevvOOGoUoGNDG/IdDH7gd5cQArRtkOErjbZ9Z4QQoGnDHPIdjHfgd5cQ\nAtQ15PCV4rXvjBACVDbw8G1DDvzuEkKAp4Y+5NvTvjuEEODaGMJX0r4XCCHASIZ8BwZ+VQkh\nENJ4wlfSvjqEEAhhREO+AwO/xgghMEqjC19J+1ohhMA4jDF8WwO/LgghMEyjHPLtaV/HhBAY\niNGGr6R9PRJCIFPjHfIdGPjlQgiBXIw8fCXty5EQAn0Z+5DvwMAve0IIdCVG+EraNyhCCLQm\nTPi2Bn5DJoRAY+IM+fa0bySEEHhfrPCVtG+EhBB4XbAh34GB39gJIfBAxPCVtC8SIQROhBzy\nHRj4hSWEEFrg8JW0j60QQjSxw7c18OOaEMK4BR/y7WkfDwkhjFDw8JW0j5cJIYxJ6PoZ+PEe\nIYRRiFpA7aM+IYRhi1dAAz8aJoQwUKEKqH20SAhhaIIU0MCPrgghDMboC6h99EIIIX9jLqD2\n0TshhIyNt4DiRz6EEHI03gIeG9j3QsAfIYSsjLmAW2NAsiSEkIdRF9AwkJwJIfRs5AXUQLIn\nhNCX0RfQplCGQQihc+MvoGEgQyKE0J0IBdRABkcIoQMxCmhTKMMkhNCmIAU0DGTIhBBaEaaA\nGsjgCSE0K1ABbQplHIQQGhKpgIaBjIkQQl2xCqiBjI4QwtuiFdCmUMZJCKG6cAU0DGTMhBAq\nCVdADWT0hBAqCNZAm0IJQQjhZZEyKIHEIYTwojAZ1ECCEUJ4SYgM2hRKSEIILxh/BiWQuIQQ\nnhp5BjWQ4IQQnhhxBm0Kha0QwhNjzaAEwg8hhAdGmUENhDNCCHeNLoM2hcINQgh3jCuDEgj3\nCCHcNKIMaiA8JIRww0gyaFMovEAI4coYMiiB8CohhAuDz6AGQiVCCGcGnUGbQuENXYZw/ZGK\nxXb7OUnFvKVZQD3DzaAEwrs6DOGmSDufi/JjmrYyC6hloBnUQKilwxDO024cOC/Sx2a72T9u\nfhZQwwAzaFMoNKDDEBb7J6a02f9TtDELeNe/oWVQAqEpHYYwpb+PP/80PAt4z7AqqIHQqB5G\nhOXHjREh+RhOBm0KhRb0sI9wvjk+bn4WUN1AMiiB0BZHjRLbEDKogdAq5xESWe4ZtCkUOuDK\nMsSVdQYlELoihESVbwY1EDolhMSUZwZtCoUe9BVC5xHSpwwzKIHQl3xCmE41MQu4I7cMaiD0\nyqZRoskpgzaFQgaEkFiyyaAEQi6EkEjyyKAGQlY6DeH3YrbfAzibf7c1C7iv/wzaFAoZ6vIS\na5OTo2FcYo2u9ZxBCYRcdXrR7eJrtX+0XhYuuk23+sygBkLWOr0N0+r38cptmOhSXxm0KRQG\noPMb8976pLFZwC29ZFACYSiMCBm77jOogTAo3e4jXK73j+wjpCv/us2gTaEwQF2ePjE9OWp0\nsmllFnCqywpKIAxVt+cRzvfnERazhfMIaV9nGdRAGDRXlmGkOsmgTaEwAkLIKLWfQQmEsRBC\nRqjlDGogjIoQMjotZtCmUBghIWRk2sqgBMJYCSGj0koGNRBGTQgZkcYzaFMoBCCEjEazGZRA\niEIIGYkGM6iBEIoQMgoNZdCmUAhICBmBJjIogRCVEDJ4tTOogRCaEDJw9TKogYAQMmjvZ9Du\nQOBACBmwNzMogcAJIWSw3smgBgKXhJCBqppBm0KB24SQIfpXKYMSCDwghAxPhQpqIPCMEDI0\nL2bQplDgNULIsLySQQkEKhBChuRpBjUQqEoIGY6HGbQpFHiPEDIU9zMogUANQsgw3MmgBgJ1\nCSFDcCODNoUCzRBC8neZQQkEGiSE5O4sgxoINE0IydtvBm0KBdohhOTskEEJBFokhORrl0EN\nBNomhGTKplCgG0JIfvYJfO/m8wBVCSFZOQ4D37n5PMBbhJBMnGwKlUGgQ0JI/873Bsog0Ckh\npFdXR8TIINAxIaQnt44K/SeDQOeEkO7dOTFCBYE+CCGdun9yoAwC/RBCOvL4BHkZBPoihLTv\n6TViZBDojxDSqleukyaDQJ+EkJa8eq1QGQT6JYQ0r8LlsmUQ6JsQ0qhqt4yQQaB/QkhDqt82\nSQaBHAgh9b1150AZBPIghNTy7t1zZRDIRe0QLmdpN2G2bmh5bs2CLNW5g7wMAvmoG8JpSmUI\nU9FoCYUwbzUSWJJBICc1Q/iZppsyhJ/po7FF2gphxmo2cCuDQG5qhrBIm20ZwsOHxghhhups\nCv0jg0BuaoZwv1lUCMeukQSWZBDIT80QTo4jwlWaNLZIWyHMSGMN3MogkKdm9hEui/TZ2CJt\nhTALzWwK/SODQJ7qHjU6SwfTphboehZ0ruEElmQQyFUj5xGm2VdDi3NzFnSohQaWFZRBIFuu\nLMNR05tCf6kgkDUhpKVh4JEMAplr4PSJvaJoYmluzYJWtdnArQwCA9BQCNfOIxyc1jaF/pFB\nYABqhHCZTjmPcEDaT2BJBoFBqDMinJx28LvnpeI13TRwK4PAYDS1j7BZQtiCDjaF/pFBYDAc\nNRpBlwksySAwIE2F8Hv2/ImbeXlo6WKS0vTJCfhC2JiuG7iVQWBg6oZw/ruX8Onz1sXumzbF\nK5dkE8IGdLop9I8MAgNTM4R/HVw+fd5Hmm12Hz7WuyZ+pHnDS8WJfhJYkkFgcGrfmPdrO03r\n9TQ9P2o0pc3xw3a7SQ9PwBfCt/XXwK0MAoPUwFGji91ocPXC7Sf2W0+LdPJJk0tFT5tC/8gg\nMEgNhHBZ3ovwhX2EH2lVVnNVPt48DqcQVtN3AksyCAxUzRDO0td2nSbb7xdCuErFfLWdFbsS\nLieP9ykK4ctyaOBWBoEBqxnCZRnAaXmwzMfzJy6LvyvRLJpeqnh63xT6RwaBAat7+sSi/Owj\nPT4I9NfXx/6ybLPFuvGlCiWfBJZkEBg0V5YZmLwauJVBYPDq7iN8bSRYZxYcZbQp9I8MAoPn\nottDkGMCSzIIjEDNEE4O58e/8SLOI3xVng0sKyiDwBjUDOFmNn3vRoTXITy7ze9brzlKmVbQ\nYBAYjdqbRltplxAeySBA24QwZzII0DqnT+Qr0+GgDALj0mkIvxez/eBxNn+yY1EIt7kOB2UQ\nGJsOQ7iZnGxIdWPeJ/IcDsogMD4dhnCeiq/9rSe262XhxrwPySBAVzoMYXG4A9Peyo15H5FB\ngM50GMKU7n3S2CzGIcvhoAwCY2VEmB0ZBOhSt/sIl4fbL9lHeF+Ow0EZBMasdgiXs3Ir5+zJ\nDQb3pidHjU4eXqM0bAhlEKBrdUM4PVxUJhWvlPB7vj+PsJgtnEd4kwwCdK5mCD/TdFOG8DN9\nNLZI26ghzHA4KIPA+NUMYZE2hwNAXWu0NhkE6EMDN+YVwibkNxyUQSCGBm7MWzZwlSaNLdI2\nYAhlEKAvzewjXBbps7FF2sYLoQwC9KbuUaOzly6iXWsWo5fdcFAGgUgaOY8wzb4aWpybsxi5\nzDL4TwaBWNyYt2eZDQdVEAinZggfXh/mfWFCKIMAfat7+sR02dii3JnFmMkgQO9qnz6R0vzJ\n9dLeECOEeQ0HZRAIqu4+wvVi18LJouFNpBFCKIMAWWjgYJn1vEgNbyINEEIZBMhDM0eNfiaX\nWKskq+GgDAKhNTEi3G8dbfRMwrGHUAYBstHIPsJi/srdCN+dxejkNByUQSC8Bo4a/XDUaBUy\nCJCV2ucRNnxxtetZjIwMAuTFlWU6ldFwUAYB9mqE8HBT3l89L9UgyCBAdoSwO/kMB2UQ4Je7\nT3RFBgGyJIQdkUGAPNU9avTnk6JoYmluzWIUshkOyiDAhYZCuLaP8BEZBMhWjRAu06lJz0uV\nsVyGgzIIcEOdEeHktIONXl5mTCHMJIP/ZBDgpqb2ETZrRCHMJYN9LwFArhw12qo8hoMyCHCf\nE+rbJIMA2RPC9mQxHJRBgMdsGm2LDAIMghC2RAYBhqFuCD8n2+160vDZE8MPYQ7DQRkEeEXN\nEC7LfYNFuYvQeYQnZBBgMGqGcJq+tqs02X6laWOLtB16CDMYDsogwKsaOKF+leZNn1k/5BDK\nIMCgNBDCWVoK4S8ZBBiW2ptGV8tUbG0a/dF7B2UQoJr6B8uktCgHhMvGFmkrhG+TQYCqap8+\nUZR7CLeTr4aW58YshqTfDsogQHVOqG9Srx2UQYB3CGGTegyhDAK8p3YIv6YppVmzW0aHGsL+\nOiiDAO+qG8Lp8d4TjR40OtAQ9tZBGQR4X80QfqaiPFx0WaTPppbochaD0VcHZRCgjpohnKTV\n/t/yMmsNEsJX/ZNBgHoauLLM+YNGDDGEfXRQBQFqa2xEWDSzPNezGIgeOiiDAA2wj7AhnYdQ\nBgEa4ajRZnTdQRkEaEj98whnziPsvIMyCNAYV5ZpRKchlEGABglhE7rsoAwCNKqZTaMfjd6E\naXAh7LCDMgjQsKYOlpk1tUDXs8hfZyGUQYDG1Qzh3OkT3XVQBgFaUDOEhUusddVBGQRohUus\n1dVNB2UQoCW1N43+jAgb3UkohOdkEKA1dQ+WWez3EX4XYa8s00EHZRCgRbU3jZ7pcal60n4H\nZRCgVUJYT9shlEGAlrmyTC0td1AGAVonhHW020EZBOiAENbRZghlEKATQlhDex38J4MAHekl\nhE+PqhlGCFvroAoCdEcI39dSCGUQoEsdhrDCqRaDCGE7HZRBgG51GMLvYlQhbKWDMgjQtdoh\nXM7Kps3WLzxxM0vT/feNYtNoCyGUQYDuNXJj3t204pUSbr9S+tqOI4TNd1AGAfpQM4Sfabop\ns/aZPl567nqaZpsxhLDxDsogQD9q35j3mLWXrzO6SMVy+CFsuoMyCNCXBm7MWy2E29Xk+dW5\ng4VQBgH6UzOEk+OIcJUmr7/Ax+BD2GgHZRCgT83sI1wW6bOxRdpmH8ImOyiDAP2qe9To7HhW\nYKg71DcXQhkE6Fsj5xGm2VflFxnwCfWNdVAGAfrX190nrkPYyq3u29BUB2UQIAduw1RZMyGU\nQYA8CGFVjXRQBgFyUfs8wla2ZmYcwiY6KIMA+eg0hN+Lw0Gms/l340vVlfohlEGAnDSzafR7\nOnv+vM3kJJuPT7fIN4S1OyiDAHlpaB/h5oWLbs9T8bXaP1ovizRveKm6UbeDMgiQm6YOlnlh\n02iRVr+PV6moPIsM1O5gI0sBQIMaCuHn47Adnnd5te5qs8hBzRDqIEB+GjtYZvH0ecMfEeog\nwPg0FMLJC9fcnqdiebiP/UD3EdowCjBCXZ5QPz05anSyaWUWrTIgBBihmiGcPRzYXfqe788j\nLGaLIZ5HqIMAY9TAHepbkGMIdRBglBq4Q30LxhdCHQTIVM0QbmbTJ1s535JhCHUQYJxcdPs1\nOggwUkL4mloh1EGAfLkf4UsMCAHGqkYIWzpi9HQWudBBgNESwhfoIMB4CeEL7CAEGC8hfE4H\nAUZMCJ/SQYAxqxXCMz0vVXvqhFAHAXInhM/oIMCo2TT6hA2jAOMmhE8YEAKMmxA+poMAIyeE\nD+kgwNgJ4UM1QqiDAIPgotuP6CDA6AnhAzoIMH5CeJ8OAgQghPcJIUAAQniXDgJEIIT36CBA\nCEJ4z/sh1EGAARHCO3QQIAYhvE0HAYIQwtveDqEOAgyLEN6kgwBRCOEtNowChCGEtxgQAoQh\nhDfoIEAcQnhNBwECEcJr74ZQBwEGSAiv6CBAJEJ4SQcBQhHCC3YQAsQihBcMCAFiEcJzOggQ\njBCe0UGAaITwzJsh1EGAwRLCUzoIEI4QntBBgHiE8MR7IdRBgCETwj8GhAABCeEvHQSISAh/\n2TAKEJEQ/tBBgJCE8EgHAWISwgMdBAhKCA/eCqEOAgyfEO7pIEBUQliyYRQgLCEsGRAChCWE\nWx0EiEwIdRAgNCF8L4Q6CDASQqiDAKEJoQ4ChCaEb4RQBwHGI3wIDQgBYoseQh0ECC54CHUQ\nIDohrEoHAUYldgh1ECC80CHUQQC6DOHmI6Xp8vgiD18l2xDqIMDYdBjCTZFKs8OLZBBCA0IA\nugzhPH3uavhZTPcv0n8IdRCATkNYHJ64LibrgYZQBwHGp8MQ/rRvM53mEEIdBGDbaQgnafPz\naNp/CHUQgFKHIfxMH8dH6zQdXgh1EGCUujx9Yv5bv2XqO4Q6CMBepyfUr2Y/j9Yf/YZQBwE4\niHllGTsIATgSwpfoIMBYhQyhDgLwo68Q9nmwjA4C8CufEKZTTczirqoh1EGAEQu4aVQHAfgT\nL4Q6CMAJIXxCBwHGrdMQfi9mh1sSzr/bmsVTBoQAnOryxryTk6Nhpq3M4jkdBOBMpzfmLb5W\n+0frZZHmbcziORtGATjT6Y15V7+PV6loYxZP6SAA53q4Me/1J43N4hkdBOBCrBFhtRDqIEAA\n3e4jXK73j/raR6iDAFzq8vSJ6clRo5NNK7N4SAcBuNLteYTz/XmExWzRx3mEdhACcC3QlWUM\nCAG4FieEOgjADWFCqIMA3CKEt+ggQBhRQqiDANwUJIQ6CMBtQnhFBwEiiRFCA0IA7ggRQh0E\n4B4hvKCDALFECKEOAnBXgBDqIAD3jT+EOgjAA0J4QgcB4hl9CA0IAXhk7CHUQQAeEsJfOggQ\n0chDqIMAPCaERzoIEJMQHuggQFDjDqEOAvCEEJZ0ECAsISwJIUBYQrjVQYDIhFAHAUIbdQh1\nEIBnhFAHAUILH0IdBIgtegh1ECC44CHUQYDohBCA0MYcQh0E4KnQIdRBACKHUAcBiBxCHQQg\ncgh1EIDtqEOogwA8FzWEOgjAnhACEFrQEOogAAcxQ6iDAByNN4Q6CMALIoZQBwH4FTCEOgjA\nn3gh1EEATgghAKGNNoQ6CMArooVQBwE4EyyEOgjAuVgh1EEALoQKoQ4CcClSCHUQgCtjDaEO\nAvASIQQgtDgh1EEAbggTQh0E4JYoIdRBAG4aaQh1EIDXxAihDgJwR4gQ6iAA90QIoQ4CcJcQ\nAhDaOEOogwC8aPwh1EEAHhh9CHUQgEfGHkIdBOChkYdQBwF4rNMQfi9mqTSbf7c1iz0dBOBV\nHYZwM0l/pq3M4ugnhDoIwDMdhnCeiq/V/tF6WaR5G7M4EkIAXtVhCIu0+n28SkUbszg6hlAH\nAXiqwxCmdO+TxmZxdAihDgLw3HhHhDoIwAu63Ue4XO8ftbyPUAcBeFmXp09MT44anWxamcVe\nGUIdBOAl3Z5HON+fR1jMFq2eR/ifDgLwqjFeWeY/HQTgVUIIQGgjDKEOAvC6vkLY4nmE/+kg\nAC/LJ4TpVJ2X/u/5twDA0Qg3jQLA64QQgNCEEIDQRnljXgB41ShvzAsArxrljXkB4FWjvA0T\nALxqlDfmBYBXGRECENoYb8wLAC8b4415AeBlY7wxLwC8zJVlAAhNCAEITQgBCE0IAQhNCAEI\nLdMQAkBH3qhU8+FrVO7Llx9rrCprrCIrrCprrKqu11ju/4VyX778WGNVWWMVWWFVWWNVCeG5\n3JcvP9ZYVdZYRVZYVdZYVUJ4Lvfly481VpU1VpEVVpU1VpUQnst9+fJjjVVljVVkhVVljVUl\nhOdyX778WGNVWWMVWWFVWWNVCeG53JcvP9ZYVdZYRVZYVdZYVUJ4Lvfly481VpU1VpEVVpU1\nVpUQnst9+fJjjVVljVVkhVVljVUlhOdyX778WGNVWWMVWWFVWWNVCeG53JcvP9ZYVdZYRVZY\nVdZYVUJ4Lvfly481VpU1VpEVVpU1VpUQAkCHhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA\n0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQsgzhvEjFfPNoAueuVtDnxBp76NaP\n1HeW74ZMXK2w1UdKH+velid/l2ts49fYU5/nb8Hu1liOb/1pKk0eTODc1Qqa7ycU3nT33PqR\n2hQ5vhsycbXCln7EHrtcY+visMb87XDfKp29BTv8xZ/hW/87Favtqkjfdydw7moFrdLHpvzr\n6qPPpcrZzR+pWcrw3ZCJ6xVW7CZsZmne40Jl7WqNfezX1dyb8r7d6jp9C3b5iz/Dt/48LXcf\nv9Li7gTOXa2g2eE/q1/s99z6kfpK1tddVyvsa/9rfZOK/pYpb1drLHlTPvGZpmdrp8tf/Bn+\nV5mlcuPBKs3uTuDcvRXkPXfPjTW2vngXcupqhX2kVY+LMwBXa+y44d2fDnft/rY6ewt2+Ys/\nw7f+1V9O/pR64s4K2qRpDwszCDfW2DSt/YTddbXCJmm7KPZb4Lnpao0tjptGbdi6Z3XxO6zL\nX/wZvvWFsKo7K+hzv2WBG67X2CJ9+Qm778abcrY/9KO3Jcrd9Y/YZ3m0TPHZ1wINghD+EcKq\nbq+gdWFb8j1Xa2y//cVP2F033pTlwTIfxjf33Ppbq2SFPSKEf4SwqpsraFPYMHrX9Za+8jwA\nP2F33XhTlvsI105quudqjX2Wm0Z3fzoYEj4ghH+Ky//7VxM4d3MFTf2Kuu9yjX3styL7Cbvr\n6kfMX6dPXK2xSSp3qG786fDI2c9Tl7/4M/w5PhwrtL48anTtqNF7bqyg9WTqxN37LtdY+tXn\nUmXsxpty/48Vds/VGvOnwwtuHDXazS/+DP+rLPZ/nS//TtW9msC56xW0dMDoQ5drTAifuPOm\nXPs5u+dqjR3GN868fOjsDdjlL/4M3/iuLFPV1Qry++mJ2z9SMnjXjR+xyabc4/XV51Ll7GqN\nzVN51cy5v+cfcWWZE5P9n+b7X+WH9XIygVsu19iH8c0TVz9j54+4dLXCFt6Uj12tsak19tTP\nW7DzX/w5vvUPV2nfPzysj5MJ3HK5xmzoe+bqZ+z8EZeuV9hy6k35yPUa82vsqfMQdviL31sf\ngNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQ\nhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQ\ngNCEEIDQhBCA0IQQgNCEEIDQhBCA0IQQGpJ+XEyt+aK7D8u3XmhZa8YQhxBCQ1oL4SS980IT\nb254jfcKNOR2qWqG8P2XaGDGEIP3CjRECGGYvFegIaflWc5SKua/U5fTlKaHfXafk1R8nj1p\nfvzO/WBrvBsAAALBSURBVNcmh6/9PmH39ePm1pQ2abL/4iRtbrzOZpJmJzP+3Uh78Y3AJSGE\nhpyEcHHYWTg/Tv08fFrmaLZ/ND150uJ3wvT3a39POA3h7hvWuy+uy2+5fp1ZOb+/Gf+E8PIb\ngUtCCA05OVYmpa/t9uv4cLst0qr8dDeeW6bpZruZpuXfk4rVdlUcvv/34d8Tjgk8vNBXWmzL\nyi5vvc5uwtWMb8wQuCSE0JCrg0Z/e5R+OzQrt2puN+VGzJ/vKb+0LCfMjg+np084C+F2v220\nPBz0xut8ny7Jz4frbwQuCSE05OzolPVyMf3t0Tyl2Wp1+J6LWh4f/fXu6gmnIfxI6+36d8Pn\njde5mPG9czqAE94e0JDT2ExPtpLuPiyK3SfF+uUQnj7hNITfabGL5PeDEF7MWAjhOW8PaMhJ\nbD7S5HO5PunRdjmf/Ozyu/WkyxCePeEvhNtiUv7v/utczVgB4SnvEmjI5d7BsxAeH80uj1o5\n7Ntbpo+/fYSz0ydchHCePvcHzNx4ndszvvpG4JIQQkPOQvi9Xf3tqpscjuWcHI8M3X6exu5w\nqOjy7KjRvyccQrje/jVuf/TLjde5nvH61jcCl4QQGnISwvlxx9z3YerX72fHfXjl3r+fJ+2n\n7Dv1dx7h19nTJ7sn/Lz85HhK4PXrXM748KyrbwQuCSE05HR33McuaN/7rZx/V5Y5nN/wuQvU\nx/r0SbOfy8lsP4uzK8t8H1/0e/IXwq+fTZ3Xr3Mx48Ozrr4RuCSE0CcHs0DvvAuhT0IIvfMu\nhD4JIfTOuxD6JITQO+9CAEITQgBCE0IAQhNCAEITQgBCE0IAQhNCAEITQgBCE0IAQhNCAEIT\nQgBCE0IAQhNCAEITQgBCE0IAQhNCAEITQgBCE0IAQhNCAEITQgBCE0IAQhNCAEITQgBCE0IA\nQhNCAEITQgBCE0IAQvsfWHmyiYhm//gAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the AUC - AUC with resmpling is 77.8%, improvement from 74.6% AUC without resampling\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_tree_up_roc_curve <- predict(classtree.up,valid_processed[, -1],type=\"vector\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(valid_processed$subscribe)\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_tree_up_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.tree.up.valid <- performance(pred, measure = \"auc\")\n",
    " print(auc.tree.up.valid@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.834285714285714"
      ],
      "text/latex": [
       "0.834285714285714"
      ],
      "text/markdown": [
       "0.834285714285714"
      ],
      "text/plain": [
       "[1] 0.8342857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(predicted[actual == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - accuracy is 83.4% with oversampling, decrease from first model (90%)\n",
    "tree_acc_valid_up <- accuracy(valid_processed$subscribe, tree_pred_valid_up)\n",
    "tree_acc_valid_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Random Forest Model - WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best hyperparameters \n",
    "#modellist <- list()\n",
    "#for (ntrees in c(1000, 1500, 2000, 2500)) {\n",
    "#    for (mtrys in c(2, 6, 10, 14)) {\n",
    "#        fit <- randomForest(subscribe ~ ., data=train_processed[, -1], ntree=ntrees, mtry=mtrys, importance = TRUE) \n",
    "#        key <- toString(ntrees + mtrys)\n",
    "#        modellist[[key]] <- fit\n",
    "#}\n",
    "#}\n",
    "## compare results\n",
    "#results <- modellist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(formula = subscribe ~ ., data = train_processed[,      -1], ntree = 2500, mtry = 14, importance = TRUE) \n",
       "               Type of random forest: classification\n",
       "                     Number of trees: 2500\n",
       "No. of variables tried at each split: 14\n",
       "\n",
       "        OOB estimate of  error rate: 10.45%\n",
       "Confusion matrix:\n",
       "     0   1 class.error\n",
       "0 4257  72  0.01663202\n",
       "1  440 131  0.77057793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model on the train set - tried different combinations for ntree and mtry and checked improvement on validation set\n",
    "# the parameters selected here gave the best results from the combinations tried \n",
    "# ntrees tried 800, 1000, 1500, 2000, 2500\n",
    "# mtry tried 2, 6, 8, 10, 14\n",
    "rdf =  randomForest(subscribe ~ ., data=train_processed[, -1], ntree=2500,mtry=14, importance = TRUE) \n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        predicted\n",
       "observed   0   1\n",
       "       0 912  20\n",
       "       1  94  24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model on validation set \n",
    "rdf.pred = predict(rdf, newdata = valid_processed[, -1], type='response')\n",
    "table(observed=valid_processed$subscribe,predicted=rdf.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.108571428571429"
      ],
      "text/latex": [
       "0.108571428571429"
      ],
      "text/markdown": [
       "0.108571428571429"
      ],
      "text/plain": [
       "[1] 0.1085714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# error of 11%\n",
    "(94+20)/(912+20+94+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7575244\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7575244\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nSUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate AUC - 75.7% AUC on validation set without resampling\n",
    "\n",
    "#  import ROCR package for ROC curve plotting:\n",
    "library(ROCR)\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "\n",
    "prediction_rf_roc_curve <- predict(rdf,valid_processed[, -1],type=\"prob\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(valid_processed$subscribe)\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_rf_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.rf.valid <- performance(pred, measure = \"auc\")\n",
    " print(auc.rf.valid@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.891428571428571"
      ],
      "text/latex": [
       "0.891428571428571"
      ],
      "text/markdown": [
       "0.891428571428571"
      ],
      "text/plain": [
       "[1] 0.8914286"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(predicted[actual == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metrics on validation set - 89.1% accuracy without oversampling\n",
    "rf_acc_valid <- accuracy(valid_processed$subscribe, rdf.pred)\n",
    "rf_acc_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Random Forest Model - WITH RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"package 'DMwR' is in use and will not be installed\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2284 1713 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resample the data in the train set using SMOTE - makes the classes more balanced \n",
    "# undersamples majority class (0) and oversamples minority class (1)\n",
    "set.seed(1)\n",
    "up_train <- SMOTE(subscribe ~ ., data  = train_processed[, -1])                         \n",
    "table(up_train$subscribe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(formula = subscribe ~ ., data = up_train[, -1],      ntree = 2500, mtry = 14, importance = TRUE) \n",
       "               Type of random forest: classification\n",
       "                     Number of trees: 2500\n",
       "No. of variables tried at each split: 14\n",
       "\n",
       "        OOB estimate of  error rate: 24.34%\n",
       "Confusion matrix:\n",
       "     0    1 class.error\n",
       "0 1963  321   0.1405429\n",
       "1  652 1061   0.3806188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert target variable to factor for the model to run without error \n",
    "up_train$subscribe <- as.factor(up_train$subscribe)\n",
    "\n",
    "# train model on train set - use same parameters as last model\n",
    "rdf_up =  randomForest(subscribe ~ ., data=up_train[, -1], ntree=2500,mtry=14, importance = TRUE) \n",
    "\n",
    "rdf_up # class error for class 1 has reduced from 76% to 36%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        predicted\n",
       "observed   0   1\n",
       "       0 804 128\n",
       "       1  50  68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model on the validation set\n",
    "rdf.pred.up = predict(rdf_up, newdata = valid_processed[, -1], type='response')\n",
    "\n",
    "# look at confusion matrix\n",
    "table(observed=valid_processed$subscribe,predicted=rdf.pred.up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.154285714285714"
      ],
      "text/latex": [
       "0.154285714285714"
      ],
      "text/markdown": [
       "0.154285714285714"
      ],
      "text/plain": [
       "[1] 0.1542857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# error rate of 16% with resampling - goes up from  earlier 11% \n",
    "(50+128)/(50+128+804+68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7895859\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7895859\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nqooJEQD0AAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate AUC - 78.9% AUC on validation set with resampling, improvement from earlier 75.7%\n",
    "\n",
    "\n",
    "#  import ROCR package for ROC curve plotting:\n",
    "library(ROCR)\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "\n",
    "prediction_rfup_roc_curve <- predict(rdf_up,valid_processed[, -1],type=\"prob\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(valid_processed$subscribe)\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_rfup_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.rf.valid.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.rf.valid.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.83047619047619"
      ],
      "text/latex": [
       "0.83047619047619"
      ],
      "text/markdown": [
       "0.83047619047619"
      ],
      "text/plain": [
       "[1] 0.8304762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(predicted[actual == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - 83% accuracy with oversampling\n",
    "\n",
    "rf_acc_valid_up <- accuracy(valid_processed$subscribe, rdf.pred.up)\n",
    "rf_acc_valid_up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. Gradient Boosting Model - WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gbm(formula = subscribe ~ ., distribution = \"bernoulli\", data = train_processed[, \n",
       "    -1], n.trees = 1500, interaction.depth = 4, shrinkage = 0.01)\n",
       "A gradient boosted model with bernoulli loss function.\n",
       "1500 iterations were performed.\n",
       "There were 50 predictors of which 25 had non-zero influence."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# had to convert target variable to character for the model to run without an error \n",
    "train_processed$subscribe <- as.character(train_processed$subscribe)\n",
    "\n",
    "# train gradient boosting model on train set. \n",
    "# Different combinations of parameters tried - ones with best results on validation set used \n",
    "# tried n.trees 500, 1000, 1500, 2000\n",
    "# tried shrinkage 0.001, 0.01, 0.05, 0.1\n",
    "# treid interaction depth 4, 6\n",
    "gb =gbm(subscribe ~ . , data = train_processed[, -1],distribution = \"bernoulli\", n.trees = 1500,\n",
    "                  shrinkage = 0.01, interaction.depth = 4)\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.286838415369997</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0567028254012986</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.309936577378519</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.12378719553553</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.051325292414123</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.319789800174937</li>\n",
       "\t<li>0.0475228526033046</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.242693548241618</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.156640602669229</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.318965613363371</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.692682493500445</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.301623350281344</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.242693548241618</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0464270858827943</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.647904094865453</li>\n",
       "\t<li>0.260792897962035</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.156640602669229</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.251617582557877</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.34785931541269</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.258712838246946</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.734477161981361</li>\n",
       "\t<li>0.360037084694594</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.279810622634911</li>\n",
       "\t<li>0.270028648122021</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.270028648122021</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.189232757039775</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.165601552319954</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.519796715009369</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.544188966127827</li>\n",
       "\t<li>0.588806593071476</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0944724841414203</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.443020363910909</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.332697309396516</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.656113508095257</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.236846188140466</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.198168559641112</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.270028648122021</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.110413644477516</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.235329391866312</li>\n",
       "\t<li>0.189232757039775</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0542637800793991</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.812770695473956</li>\n",
       "\t<li>0.426748380590427</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.54417557359277</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.156640602669229</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.337551731815556</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.315385545774235</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.189232757039775</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.21666774342788</li>\n",
       "\t<li>0.051325292414123</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.242693548241618</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.211413539724586</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.412431684610209</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.701484024934113</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.274032647713637</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.767902341446961</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.661739374609349</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.286808161322413</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.051325292414123</li>\n",
       "\t<li>0.209895197355668</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.274032647713637</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0437803287299971</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.667030514786486</li>\n",
       "\t<li>0.375299959140913</li>\n",
       "\t<li>0.567056783145755</li>\n",
       "\t<li>0.803023353377945</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.196487036236837</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0567028254012986</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.349483527966234</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.741582361568306</li>\n",
       "\t<li>0.312322443993547</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.640205542193933</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.432939205946586</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.574051883632546</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.713159373291857</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.319789800174937</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.364628814072281</li>\n",
       "\t<li>0.31352787212269</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.534630617119234</li>\n",
       "\t<li>0.498816523122167</li>\n",
       "\t<li>0.432939205946586</li>\n",
       "\t<li>0.639614040785452</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.307508437108477</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.216034253653193</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0464270858827943</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.432244956899108</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.4495065626597</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.678254135311586</li>\n",
       "\t<li>0.244254321794204</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.209895197355668</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.689924229013034</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0513187824044823</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.900272243728593</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0437803287299971</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.197972627878753</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.312322443993547</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.279810622634911</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.863778078605876</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.417594488922819</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0475228526033046</li>\n",
       "\t<li>0.0475228526033046</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0464270858827943</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.34785931541269</li>\n",
       "\t<li>0.21666774342788</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.165601552319954</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.244569129829729</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0542637800793991</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.274565303006101</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0475228526033046</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.884938987337465</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.691769676544765</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.250503227106907</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0513187824044823</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.27361065837508</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.379354997019281</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.305754482222158</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.311617450825154</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.279810622634911</li>\n",
       "\t<li>0.0542637800793991</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.688175318821066</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0513187824044823</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.256076268019483</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.811462237690797</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.191843848732917</li>\n",
       "\t<li>0.690114515233374</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0437803287299971</li>\n",
       "\t<li>0.284387025183037</li>\n",
       "\t<li>0.598790655327105</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.379979925545675</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.622941137331631</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.189232757039775</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.165601552319954</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0721575750736133</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0437803287299971</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.229403410942524</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0567028254012986</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.319789800174937</li>\n",
       "\t<li>0.274032647713637</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.309353138467764</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.235926066878306</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0437803287299971</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.784384923120806</li>\n",
       "\t<li>0.0435260095063634</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.237500129498932</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.253743103386435</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.235926066878306</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.802037086883042</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.197972627878753</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.339494934326037</li>\n",
       "\t<li>0.761863088622674</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0878686885357587</li>\n",
       "\t<li>0.80661033239096</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.063312536431413</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.251549885166514</li>\n",
       "\t<li>0.0513187824044823</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.279810622634911</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.260792897962035</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.209603598808645</li>\n",
       "\t<li>0.34785931541269</li>\n",
       "\t<li>0.252121559285981</li>\n",
       "\t<li>0.0437803287299971</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.312322443993547</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0878686885357587</li>\n",
       "\t<li>0.0464270858827943</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.293367608396109</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.191263037518618</li>\n",
       "\t<li>0.265626858976541</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0464270858827943</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.678254135311586</li>\n",
       "\t<li>0.737992319524266</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.439398623216433</li>\n",
       "\t<li>0.237500129498932</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.766848590215638</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0878686885357587</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0765758454701296</li>\n",
       "\t<li>0.461866473513337</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0475228526033046</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.601932800760852</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.051325292414123</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.382676812147653</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.279810622634911</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.344657162779725</li>\n",
       "\t<li>0.161398727448971</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.432939205946586</li>\n",
       "\t<li>0.187173649288501</li>\n",
       "\t<li>0.312322443993547</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.792636349614848</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.251617582557877</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.253957190767119</li>\n",
       "\t<li>0.231631097262436</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.189232757039775</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0653810456920552</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.209895197355668</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.235926066878306</li>\n",
       "\t<li>0.237500129498932</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.347531056255353</li>\n",
       "\t<li>0.12378719553553</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.483745589366804</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.416097304372128</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.165601552319954</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0513187824044823</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0470288916896563</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0475228526033046</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.598790655327105</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.371024294944453</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.341454682864037</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.6328550668449</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.765534738762068</li>\n",
       "\t<li>0.255792264796675</li>\n",
       "\t<li>0.236846188140466</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0544272976968682</li>\n",
       "\t<li>0.0538687944265217</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0490214531502574</li>\n",
       "\t<li>0.400516813923643</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "\t<li>0.0878686885357587</li>\n",
       "\t<li>0.395701573579991</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.615521663397242</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.375493676268522</li>\n",
       "\t<li>0.0467794145372378</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0962106361767415</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.156640602669229</li>\n",
       "\t<li>0.0701340179492015</li>\n",
       "\t<li>0.0567028254012986</li>\n",
       "\t<li>0.0695160138076883</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0835203679657271</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0657939687931545</li>\n",
       "\t<li>0.0551708376756284</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0490962990063064</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.04370054580617</li>\n",
       "\t<li>0.0552492736542768</li>\n",
       "\t<li>0.106414006924995</li>\n",
       "\t<li>0.337551731815556</li>\n",
       "\t<li>0.0502434078176246</li>\n",
       "\t<li>0.114856405438865</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.664358678509347</li>\n",
       "\t<li>0.165601552319954</li>\n",
       "\t<li>0.375299959140913</li>\n",
       "\t<li>0.0470075575525019</li>\n",
       "\t<li>0.0393536392854195</li>\n",
       "\t<li>0.412994068873526</li>\n",
       "\t<li>0.21666774342788</li>\n",
       "\t<li>0.051325292414123</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.189232757039775</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0396366452377635</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.416097304372128</li>\n",
       "\t<li>0.0460036020211568</li>\n",
       "\t<li>0.0394402944942955</li>\n",
       "\t<li>0.0402895636381069</li>\n",
       "\t<li>0.415458248473933</li>\n",
       "\t<li>0.0434150169222341</li>\n",
       "\t<li>0.0880917555294811</li>\n",
       "\t<li>0.0546790356122431</li>\n",
       "\t<li>0.0392310802440331</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.0705376363419421</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0396650289448398</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0505422648624419</li>\n",
       "\t<li>0.0560397955266855</li>\n",
       "\t<li>0.0929694896320363</li>\n",
       "\t<li>0.0643366036373718</li>\n",
       "\t<li>0.0611540814230824</li>\n",
       "\t<li>0.051325292414123</li>\n",
       "\t<li>0.0497069746627195</li>\n",
       "\t<li>0.0590500539589063</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.286838415369997\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.114856405438865\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0567028254012986\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.309936577378519\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.12378719553553\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.051325292414123\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.319789800174937\n",
       "\\item 0.0475228526033046\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.242693548241618\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.156640602669229\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.318965613363371\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.692682493500445\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.301623350281344\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.242693548241618\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0464270858827943\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.647904094865453\n",
       "\\item 0.260792897962035\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.156640602669229\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.251617582557877\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.34785931541269\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.258712838246946\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.734477161981361\n",
       "\\item 0.360037084694594\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.279810622634911\n",
       "\\item 0.270028648122021\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.270028648122021\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.189232757039775\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.165601552319954\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.519796715009369\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.544188966127827\n",
       "\\item 0.588806593071476\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0944724841414203\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.114856405438865\n",
       "\\item 0.443020363910909\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.332697309396516\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.656113508095257\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.236846188140466\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.198168559641112\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.114856405438865\n",
       "\\item 0.270028648122021\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.110413644477516\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.235329391866312\n",
       "\\item 0.189232757039775\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0542637800793991\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.812770695473956\n",
       "\\item 0.426748380590427\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.54417557359277\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.156640602669229\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.337551731815556\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.315385545774235\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.189232757039775\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.21666774342788\n",
       "\\item 0.051325292414123\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.242693548241618\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.211413539724586\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.412431684610209\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.701484024934113\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.274032647713637\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.767902341446961\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.661739374609349\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.286808161322413\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.051325292414123\n",
       "\\item 0.209895197355668\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.274032647713637\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0437803287299971\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.667030514786486\n",
       "\\item 0.375299959140913\n",
       "\\item 0.567056783145755\n",
       "\\item 0.803023353377945\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.196487036236837\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0567028254012986\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.349483527966234\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.741582361568306\n",
       "\\item 0.312322443993547\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.640205542193933\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.432939205946586\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.574051883632546\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.713159373291857\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.319789800174937\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.364628814072281\n",
       "\\item 0.31352787212269\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.534630617119234\n",
       "\\item 0.498816523122167\n",
       "\\item 0.432939205946586\n",
       "\\item 0.639614040785452\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.307508437108477\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.216034253653193\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0464270858827943\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.432244956899108\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.4495065626597\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.678254135311586\n",
       "\\item 0.244254321794204\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.209895197355668\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.689924229013034\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0513187824044823\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.900272243728593\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0437803287299971\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.197972627878753\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.312322443993547\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.279810622634911\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.863778078605876\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.417594488922819\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0475228526033046\n",
       "\\item 0.0475228526033046\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0464270858827943\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.34785931541269\n",
       "\\item 0.21666774342788\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.165601552319954\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.244569129829729\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0542637800793991\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.274565303006101\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0475228526033046\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.884938987337465\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.691769676544765\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.250503227106907\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0513187824044823\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.114856405438865\n",
       "\\item 0.27361065837508\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.379354997019281\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.305754482222158\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.311617450825154\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.279810622634911\n",
       "\\item 0.0542637800793991\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.688175318821066\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0513187824044823\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.256076268019483\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.811462237690797\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.191843848732917\n",
       "\\item 0.690114515233374\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0437803287299971\n",
       "\\item 0.284387025183037\n",
       "\\item 0.598790655327105\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.379979925545675\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.622941137331631\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.189232757039775\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.165601552319954\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0721575750736133\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0437803287299971\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.229403410942524\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0567028254012986\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.319789800174937\n",
       "\\item 0.274032647713637\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.309353138467764\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.235926066878306\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0437803287299971\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.784384923120806\n",
       "\\item 0.0435260095063634\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.237500129498932\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.253743103386435\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.235926066878306\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.802037086883042\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.197972627878753\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.339494934326037\n",
       "\\item 0.761863088622674\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0878686885357587\n",
       "\\item 0.80661033239096\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.063312536431413\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.251549885166514\n",
       "\\item 0.0513187824044823\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.279810622634911\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.04370054580617\n",
       "\\item 0.260792897962035\n",
       "\\item 0.114856405438865\n",
       "\\item 0.209603598808645\n",
       "\\item 0.34785931541269\n",
       "\\item 0.252121559285981\n",
       "\\item 0.0437803287299971\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.312322443993547\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0878686885357587\n",
       "\\item 0.0464270858827943\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.293367608396109\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.191263037518618\n",
       "\\item 0.265626858976541\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0464270858827943\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.678254135311586\n",
       "\\item 0.737992319524266\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.439398623216433\n",
       "\\item 0.237500129498932\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.766848590215638\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0878686885357587\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0765758454701296\n",
       "\\item 0.461866473513337\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0475228526033046\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.601932800760852\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.051325292414123\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.382676812147653\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.279810622634911\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.344657162779725\n",
       "\\item 0.161398727448971\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.432939205946586\n",
       "\\item 0.187173649288501\n",
       "\\item 0.312322443993547\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.792636349614848\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.251617582557877\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.253957190767119\n",
       "\\item 0.231631097262436\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.189232757039775\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0653810456920552\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.209895197355668\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.235926066878306\n",
       "\\item 0.237500129498932\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.347531056255353\n",
       "\\item 0.12378719553553\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.483745589366804\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.416097304372128\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.165601552319954\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0513187824044823\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0470288916896563\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.106414006924995\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0475228526033046\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.598790655327105\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.371024294944453\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.341454682864037\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.6328550668449\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.765534738762068\n",
       "\\item 0.255792264796675\n",
       "\\item 0.236846188140466\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0544272976968682\n",
       "\\item 0.0538687944265217\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0490214531502574\n",
       "\\item 0.400516813923643\n",
       "\\item 0.0590500539589063\n",
       "\\item 0.0878686885357587\n",
       "\\item 0.395701573579991\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.615521663397242\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.375493676268522\n",
       "\\item 0.0467794145372378\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0962106361767415\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.156640602669229\n",
       "\\item 0.0701340179492015\n",
       "\\item 0.0567028254012986\n",
       "\\item 0.0695160138076883\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0835203679657271\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0657939687931545\n",
       "\\item 0.0551708376756284\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0490962990063064\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.04370054580617\n",
       "\\item 0.0552492736542768\n",
       "\\item 0.106414006924995\n",
       "\\item 0.337551731815556\n",
       "\\item 0.0502434078176246\n",
       "\\item 0.114856405438865\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.664358678509347\n",
       "\\item 0.165601552319954\n",
       "\\item 0.375299959140913\n",
       "\\item 0.0470075575525019\n",
       "\\item 0.0393536392854195\n",
       "\\item 0.412994068873526\n",
       "\\item 0.21666774342788\n",
       "\\item 0.051325292414123\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.189232757039775\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0396366452377635\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.416097304372128\n",
       "\\item 0.0460036020211568\n",
       "\\item 0.0394402944942955\n",
       "\\item 0.0402895636381069\n",
       "\\item 0.415458248473933\n",
       "\\item 0.0434150169222341\n",
       "\\item 0.0880917555294811\n",
       "\\item 0.0546790356122431\n",
       "\\item 0.0392310802440331\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.0705376363419421\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0396650289448398\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0505422648624419\n",
       "\\item 0.0560397955266855\n",
       "\\item 0.0929694896320363\n",
       "\\item 0.0643366036373718\n",
       "\\item 0.0611540814230824\n",
       "\\item 0.051325292414123\n",
       "\\item 0.0497069746627195\n",
       "\\item 0.0590500539589063\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.0590500539589063\n",
       "2. 0.0538687944265217\n",
       "3. 0.0721575750736133\n",
       "4. 0.0392310802440331\n",
       "5. 0.0929694896320363\n",
       "6. 0.0611540814230824\n",
       "7. 0.286838415369997\n",
       "8. 0.0880917555294811\n",
       "9. 0.0701340179492015\n",
       "10. 0.0657939687931545\n",
       "11. 0.0470288916896563\n",
       "12. 0.0490962990063064\n",
       "13. 0.0467794145372378\n",
       "14. 0.0490962990063064\n",
       "15. 0.0765758454701296\n",
       "16. 0.0490962990063064\n",
       "17. 0.0497069746627195\n",
       "18. 0.0502434078176246\n",
       "19. 0.114856405438865\n",
       "20. 0.106414006924995\n",
       "21. 0.0567028254012986\n",
       "22. 0.0502434078176246\n",
       "23. 0.0538687944265217\n",
       "24. 0.0929694896320363\n",
       "25. 0.309936577378519\n",
       "26. 0.0962106361767415\n",
       "27. 0.12378719553553\n",
       "28. 0.0546790356122431\n",
       "29. 0.051325292414123\n",
       "30. 0.0434150169222341\n",
       "31. 0.319789800174937\n",
       "32. 0.0475228526033046\n",
       "33. 0.0695160138076883\n",
       "34. 0.242693548241618\n",
       "35. 0.0394402944942955\n",
       "36. 0.156640602669229\n",
       "37. 0.0643366036373718\n",
       "38. 0.0392310802440331\n",
       "39. 0.0721575750736133\n",
       "40. 0.0611540814230824\n",
       "41. 0.0490214531502574\n",
       "42. 0.0470075575525019\n",
       "43. 0.0505422648624419\n",
       "44. 0.0653810456920552\n",
       "45. 0.0552492736542768\n",
       "46. 0.0538687944265217\n",
       "47. 0.0396650289448398\n",
       "48. 0.0502434078176246\n",
       "49. 0.0490214531502574\n",
       "50. 0.0490962990063064\n",
       "51. 0.0538687944265217\n",
       "52. 0.0705376363419421\n",
       "53. 0.0880917555294811\n",
       "54. 0.0470288916896563\n",
       "55. 0.0460036020211568\n",
       "56. 0.0470075575525019\n",
       "57. 0.318965613363371\n",
       "58. 0.0653810456920552\n",
       "59. 0.692682493500445\n",
       "60. 0.0392310802440331\n",
       "61. 0.0396650289448398\n",
       "62. 0.301623350281344\n",
       "63. 0.0392310802440331\n",
       "64. 0.0538687944265217\n",
       "65. 0.0502434078176246\n",
       "66. 0.0611540814230824\n",
       "67. 0.0611540814230824\n",
       "68. 0.0721575750736133\n",
       "69. 0.0460036020211568\n",
       "70. 0.0653810456920552\n",
       "71. 0.0611540814230824\n",
       "72. 0.242693548241618\n",
       "73. 0.0657939687931545\n",
       "74. 0.0470288916896563\n",
       "75. 0.0394402944942955\n",
       "76. 0.0392310802440331\n",
       "77. 0.0393536392854195\n",
       "78. 0.0560397955266855\n",
       "79. 0.0392310802440331\n",
       "80. 0.0551708376756284\n",
       "81. 0.0464270858827943\n",
       "82. 0.0611540814230824\n",
       "83. 0.0460036020211568\n",
       "84. 0.647904094865453\n",
       "85. 0.260792897962035\n",
       "86. 0.0402895636381069\n",
       "87. 0.0701340179492015\n",
       "88. 0.0611540814230824\n",
       "89. 0.0434150169222341\n",
       "90. 0.156640602669229\n",
       "91. 0.0396366452377635\n",
       "92. 0.0765758454701296\n",
       "93. 0.251617582557877\n",
       "94. 0.0497069746627195\n",
       "95. 0.106414006924995\n",
       "96. 0.0392310802440331\n",
       "97. 0.0560397955266855\n",
       "98. 0.0611540814230824\n",
       "99. 0.0653810456920552\n",
       "100. 0.0470288916896563\n",
       "101. 0.0392310802440331\n",
       "102. 0.0402895636381069\n",
       "103. 0.0590500539589063\n",
       "104. 0.0470288916896563\n",
       "105. 0.0392310802440331\n",
       "106. 0.0611540814230824\n",
       "107. 0.34785931541269\n",
       "108. 0.0490214531502574\n",
       "109. 0.114856405438865\n",
       "110. 0.0392310802440331\n",
       "111. 0.0611540814230824\n",
       "112. 0.0765758454701296\n",
       "113. 0.258712838246946\n",
       "114. 0.0538687944265217\n",
       "115. 0.0538687944265217\n",
       "116. 0.734477161981361\n",
       "117. 0.360037084694594\n",
       "118. 0.0560397955266855\n",
       "119. 0.0653810456920552\n",
       "120. 0.279810622634911\n",
       "121. 0.270028648122021\n",
       "122. 0.0470075575525019\n",
       "123. 0.270028648122021\n",
       "124. 0.0929694896320363\n",
       "125. 0.0470075575525019\n",
       "126. 0.0490214531502574\n",
       "127. 0.0393536392854195\n",
       "128. 0.0643366036373718\n",
       "129. 0.0402895636381069\n",
       "130. 0.189232757039775\n",
       "131. 0.0393536392854195\n",
       "132. 0.0880917555294811\n",
       "133. 0.0560397955266855\n",
       "134. 0.0470288916896563\n",
       "135. 0.0392310802440331\n",
       "136. 0.0392310802440331\n",
       "137. 0.0929694896320363\n",
       "138. 0.165601552319954\n",
       "139. 0.0611540814230824\n",
       "140. 0.0393536392854195\n",
       "141. 0.0552492736542768\n",
       "142. 0.0962106361767415\n",
       "143. 0.519796715009369\n",
       "144. 0.0705376363419421\n",
       "145. 0.0505422648624419\n",
       "146. 0.0552492736542768\n",
       "147. 0.0497069746627195\n",
       "148. 0.0470288916896563\n",
       "149. 0.0701340179492015\n",
       "150. 0.0880917555294811\n",
       "151. 0.0393536392854195\n",
       "152. 0.0835203679657271\n",
       "153. 0.544188966127827\n",
       "154. 0.588806593071476\n",
       "155. 0.0962106361767415\n",
       "156. 0.0705376363419421\n",
       "157. 0.0701340179492015\n",
       "158. 0.0929694896320363\n",
       "159. 0.0944724841414203\n",
       "160. 0.0611540814230824\n",
       "161. 0.114856405438865\n",
       "162. 0.443020363910909\n",
       "163. 0.0929694896320363\n",
       "164. 0.0392310802440331\n",
       "165. 0.0705376363419421\n",
       "166. 0.0611540814230824\n",
       "167. 0.0490962990063064\n",
       "168. 0.0505422648624419\n",
       "169. 0.0402895636381069\n",
       "170. 0.0657939687931545\n",
       "171. 0.0611540814230824\n",
       "172. 0.0394402944942955\n",
       "173. 0.332697309396516\n",
       "174. 0.04370054580617\n",
       "175. 0.0551708376756284\n",
       "176. 0.0552492736542768\n",
       "177. 0.0470288916896563\n",
       "178. 0.0544272976968682\n",
       "179. 0.656113508095257\n",
       "180. 0.395701573579991\n",
       "181. 0.0396366452377635\n",
       "182. 0.114856405438865\n",
       "183. 0.0502434078176246\n",
       "184. 0.0765758454701296\n",
       "185. 0.236846188140466\n",
       "186. 0.0695160138076883\n",
       "187. 0.0835203679657271\n",
       "188. 0.0393536392854195\n",
       "189. 0.0721575750736133\n",
       "190. 0.0657939687931545\n",
       "191. 0.0611540814230824\n",
       "192. 0.0657939687931545\n",
       "193. 0.0396366452377635\n",
       "194. 0.0552492736542768\n",
       "195. 0.198168559641112\n",
       "196. 0.0467794145372378\n",
       "197. 0.0705376363419421\n",
       "198. 0.0560397955266855\n",
       "199. 0.114856405438865\n",
       "200. 0.270028648122021\n",
       "201. 0.0490962990063064\n",
       "202. 0.0657939687931545\n",
       "203. 0.0653810456920552\n",
       "204. 0.0467794145372378\n",
       "205. 0.0552492736542768\n",
       "206. 0.0505422648624419\n",
       "207. 0.0695160138076883\n",
       "208. 0.0392310802440331\n",
       "209. 0.0392310802440331\n",
       "210. 0.0434150169222341\n",
       "211. 0.0546790356122431\n",
       "212. 0.0611540814230824\n",
       "213. 0.0490214531502574\n",
       "214. 0.0695160138076883\n",
       "215. 0.0962106361767415\n",
       "216. 0.0392310802440331\n",
       "217. 0.0701340179492015\n",
       "218. 0.0460036020211568\n",
       "219. 0.114856405438865\n",
       "220. 0.0611540814230824\n",
       "221. 0.0701340179492015\n",
       "222. 0.110413644477516\n",
       "223. 0.0552492736542768\n",
       "224. 0.0505422648624419\n",
       "225. 0.0657939687931545\n",
       "226. 0.0929694896320363\n",
       "227. 0.0657939687931545\n",
       "228. 0.0552492736542768\n",
       "229. 0.0394402944942955\n",
       "230. 0.0551708376756284\n",
       "231. 0.235329391866312\n",
       "232. 0.189232757039775\n",
       "233. 0.106414006924995\n",
       "234. 0.0880917555294811\n",
       "235. 0.0542637800793991\n",
       "236. 0.0929694896320363\n",
       "237. 0.0546790356122431\n",
       "238. 0.812770695473956\n",
       "239. 0.426748380590427\n",
       "240. 0.0721575750736133\n",
       "241. 0.0396366452377635\n",
       "242. 0.54417557359277\n",
       "243. 0.0701340179492015\n",
       "244. 0.0470075575525019\n",
       "245. 0.156640602669229\n",
       "246. 0.0835203679657271\n",
       "247. 0.337551731815556\n",
       "248. 0.0611540814230824\n",
       "249. 0.0653810456920552\n",
       "250. 0.0505422648624419\n",
       "251. 0.0392310802440331\n",
       "252. 0.0497069746627195\n",
       "253. 0.0643366036373718\n",
       "254. 0.0467794145372378\n",
       "255. 0.315385545774235\n",
       "256. 0.106414006924995\n",
       "257. 0.0396366452377635\n",
       "258. 0.0392310802440331\n",
       "259. 0.0962106361767415\n",
       "260. 0.0396650289448398\n",
       "261. 0.0490962990063064\n",
       "262. 0.0470288916896563\n",
       "263. 0.0502434078176246\n",
       "264. 0.0701340179492015\n",
       "265. 0.189232757039775\n",
       "266. 0.0394402944942955\n",
       "267. 0.0393536392854195\n",
       "268. 0.0490962990063064\n",
       "269. 0.106414006924995\n",
       "270. 0.0552492736542768\n",
       "271. 0.0393536392854195\n",
       "272. 0.21666774342788\n",
       "273. 0.051325292414123\n",
       "274. 0.0590500539589063\n",
       "275. 0.0396366452377635\n",
       "276. 0.242693548241618\n",
       "277. 0.0551708376756284\n",
       "278. 0.395701573579991\n",
       "279. 0.0611540814230824\n",
       "280. 0.211413539724586\n",
       "281. 0.0701340179492015\n",
       "282. 0.0502434078176246\n",
       "283. 0.412431684610209\n",
       "284. 0.0552492736542768\n",
       "285. 0.0657939687931545\n",
       "286. 0.0392310802440331\n",
       "287. 0.0467794145372378\n",
       "288. 0.0505422648624419\n",
       "289. 0.701484024934113\n",
       "290. 0.0490214531502574\n",
       "291. 0.274032647713637\n",
       "292. 0.0552492736542768\n",
       "293. 0.114856405438865\n",
       "294. 0.0653810456920552\n",
       "295. 0.767902341446961\n",
       "296. 0.0962106361767415\n",
       "297. 0.0392310802440331\n",
       "298. 0.0962106361767415\n",
       "299. 0.661739374609349\n",
       "300. 0.0490214531502574\n",
       "301. 0.286808161322413\n",
       "302. 0.0962106361767415\n",
       "303. 0.0392310802440331\n",
       "304. 0.051325292414123\n",
       "305. 0.209895197355668\n",
       "306. 0.0505422648624419\n",
       "307. 0.274032647713637\n",
       "308. 0.0502434078176246\n",
       "309. 0.0437803287299971\n",
       "310. 0.0657939687931545\n",
       "311. 0.0765758454701296\n",
       "312. 0.667030514786486\n",
       "313. 0.375299959140913\n",
       "314. 0.567056783145755\n",
       "315. 0.803023353377945\n",
       "316. 0.0470288916896563\n",
       "317. 0.0552492736542768\n",
       "318. 0.0538687944265217\n",
       "319. 0.0835203679657271\n",
       "320. 0.0460036020211568\n",
       "321. 0.0590500539589063\n",
       "322. 0.0590500539589063\n",
       "323. 0.0393536392854195\n",
       "324. 0.0460036020211568\n",
       "325. 0.0394402944942955\n",
       "326. 0.0611540814230824\n",
       "327. 0.0560397955266855\n",
       "328. 0.0929694896320363\n",
       "329. 0.0490214531502574\n",
       "330. 0.0392310802440331\n",
       "331. 0.196487036236837\n",
       "332. 0.0396366452377635\n",
       "333. 0.0590500539589063\n",
       "334. 0.0546790356122431\n",
       "335. 0.0392310802440331\n",
       "336. 0.0567028254012986\n",
       "337. 0.04370054580617\n",
       "338. 0.0392310802440331\n",
       "339. 0.0544272976968682\n",
       "340. 0.0435260095063634\n",
       "341. 0.0929694896320363\n",
       "342. 0.0502434078176246\n",
       "343. 0.0880917555294811\n",
       "344. 0.0765758454701296\n",
       "345. 0.0394402944942955\n",
       "346. 0.349483527966234\n",
       "347. 0.0392310802440331\n",
       "348. 0.741582361568306\n",
       "349. 0.312322443993547\n",
       "350. 0.0490962990063064\n",
       "351. 0.0396650289448398\n",
       "352. 0.0962106361767415\n",
       "353. 0.0396366452377635\n",
       "354. 0.0505422648624419\n",
       "355. 0.0538687944265217\n",
       "356. 0.0929694896320363\n",
       "357. 0.0701340179492015\n",
       "358. 0.0470288916896563\n",
       "359. 0.114856405438865\n",
       "360. 0.0392310802440331\n",
       "361. 0.0962106361767415\n",
       "362. 0.0611540814230824\n",
       "363. 0.0590500539589063\n",
       "364. 0.0392310802440331\n",
       "365. 0.0835203679657271\n",
       "366. 0.640205542193933\n",
       "367. 0.0653810456920552\n",
       "368. 0.114856405438865\n",
       "369. 0.0434150169222341\n",
       "370. 0.0505422648624419\n",
       "371. 0.432939205946586\n",
       "372. 0.0402895636381069\n",
       "373. 0.0505422648624419\n",
       "374. 0.0470075575525019\n",
       "375. 0.574051883632546\n",
       "376. 0.395701573579991\n",
       "377. 0.0765758454701296\n",
       "378. 0.713159373291857\n",
       "379. 0.0490962990063064\n",
       "380. 0.0611540814230824\n",
       "381. 0.319789800174937\n",
       "382. 0.106414006924995\n",
       "383. 0.0505422648624419\n",
       "384. 0.0538687944265217\n",
       "385. 0.0538687944265217\n",
       "386. 0.0611540814230824\n",
       "387. 0.0490962990063064\n",
       "388. 0.0435260095063634\n",
       "389. 0.0835203679657271\n",
       "390. 0.364628814072281\n",
       "391. 0.31352787212269\n",
       "392. 0.0695160138076883\n",
       "393. 0.0402895636381069\n",
       "394. 0.534630617119234\n",
       "395. 0.498816523122167\n",
       "396. 0.432939205946586\n",
       "397. 0.639614040785452\n",
       "398. 0.0393536392854195\n",
       "399. 0.307508437108477\n",
       "400. 0.0490962990063064\n",
       "401. 0.0393536392854195\n",
       "402. 0.0470075575525019\n",
       "403. 0.0396650289448398\n",
       "404. 0.0392310802440331\n",
       "405. 0.0705376363419421\n",
       "406. 0.0590500539589063\n",
       "407. 0.0880917555294811\n",
       "408. 0.0721575750736133\n",
       "409. 0.0402895636381069\n",
       "410. 0.0552492736542768\n",
       "411. 0.216034253653193\n",
       "412. 0.0470075575525019\n",
       "413. 0.0464270858827943\n",
       "414. 0.0470075575525019\n",
       "415. 0.0653810456920552\n",
       "416. 0.0701340179492015\n",
       "417. 0.0497069746627195\n",
       "418. 0.0590500539589063\n",
       "419. 0.0490962990063064\n",
       "420. 0.0392310802440331\n",
       "421. 0.106414006924995\n",
       "422. 0.0611540814230824\n",
       "423. 0.0552492736542768\n",
       "424. 0.0560397955266855\n",
       "425. 0.0470288916896563\n",
       "426. 0.0611540814230824\n",
       "427. 0.0880917555294811\n",
       "428. 0.0467794145372378\n",
       "429. 0.0502434078176246\n",
       "430. 0.0835203679657271\n",
       "431. 0.04370054580617\n",
       "432. 0.0929694896320363\n",
       "433. 0.0402895636381069\n",
       "434. 0.0505422648624419\n",
       "435. 0.0701340179492015\n",
       "436. 0.0505422648624419\n",
       "437. 0.0695160138076883\n",
       "438. 0.0552492736542768\n",
       "439. 0.0611540814230824\n",
       "440. 0.0765758454701296\n",
       "441. 0.432244956899108\n",
       "442. 0.0467794145372378\n",
       "443. 0.4495065626597\n",
       "444. 0.0393536392854195\n",
       "445. 0.0505422648624419\n",
       "446. 0.678254135311586\n",
       "447. 0.244254321794204\n",
       "448. 0.0705376363419421\n",
       "449. 0.209895197355668\n",
       "450. 0.0590500539589063\n",
       "451. 0.689924229013034\n",
       "452. 0.0460036020211568\n",
       "453. 0.0392310802440331\n",
       "454. 0.0643366036373718\n",
       "455. 0.0460036020211568\n",
       "456. 0.0765758454701296\n",
       "457. 0.0392310802440331\n",
       "458. 0.0502434078176246\n",
       "459. 0.0701340179492015\n",
       "460. 0.0470288916896563\n",
       "461. 0.106414006924995\n",
       "462. 0.0590500539589063\n",
       "463. 0.0513187824044823\n",
       "464. 0.0657939687931545\n",
       "465. 0.0490214531502574\n",
       "466. 0.0490962990063064\n",
       "467. 0.0962106361767415\n",
       "468. 0.900272243728593\n",
       "469. 0.0611540814230824\n",
       "470. 0.0437803287299971\n",
       "471. 0.0396650289448398\n",
       "472. 0.0502434078176246\n",
       "473. 0.0538687944265217\n",
       "474. 0.0490962990063064\n",
       "475. 0.0396366452377635\n",
       "476. 0.0551708376756284\n",
       "477. 0.0657939687931545\n",
       "478. 0.0590500539589063\n",
       "479. 0.0653810456920552\n",
       "480. 0.0467794145372378\n",
       "481. 0.0392310802440331\n",
       "482. 0.0394402944942955\n",
       "483. 0.0392310802440331\n",
       "484. 0.0393536392854195\n",
       "485. 0.0490214531502574\n",
       "486. 0.0396366452377635\n",
       "487. 0.0396650289448398\n",
       "488. 0.0657939687931545\n",
       "489. 0.0765758454701296\n",
       "490. 0.0611540814230824\n",
       "491. 0.197972627878753\n",
       "492. 0.0435260095063634\n",
       "493. 0.0396650289448398\n",
       "494. 0.0765758454701296\n",
       "495. 0.0392310802440331\n",
       "496. 0.0502434078176246\n",
       "497. 0.0392310802440331\n",
       "498. 0.0538687944265217\n",
       "499. 0.0701340179492015\n",
       "500. 0.0505422648624419\n",
       "501. 0.0505422648624419\n",
       "502. 0.0552492736542768\n",
       "503. 0.0505422648624419\n",
       "504. 0.0392310802440331\n",
       "505. 0.0502434078176246\n",
       "506. 0.312322443993547\n",
       "507. 0.0402895636381069\n",
       "508. 0.0705376363419421\n",
       "509. 0.0544272976968682\n",
       "510. 0.279810622634911\n",
       "511. 0.0435260095063634\n",
       "512. 0.0396650289448398\n",
       "513. 0.863778078605876\n",
       "514. 0.0653810456920552\n",
       "515. 0.0590500539589063\n",
       "516. 0.0835203679657271\n",
       "517. 0.0590500539589063\n",
       "518. 0.417594488922819\n",
       "519. 0.0643366036373718\n",
       "520. 0.0475228526033046\n",
       "521. 0.0475228526033046\n",
       "522. 0.0505422648624419\n",
       "523. 0.0721575750736133\n",
       "524. 0.0464270858827943\n",
       "525. 0.0460036020211568\n",
       "526. 0.0505422648624419\n",
       "527. 0.0490962990063064\n",
       "528. 0.34785931541269\n",
       "529. 0.21666774342788\n",
       "530. 0.0392310802440331\n",
       "531. 0.0392310802440331\n",
       "532. 0.0590500539589063\n",
       "533. 0.0470288916896563\n",
       "534. 0.165601552319954\n",
       "535. 0.0470075575525019\n",
       "536. 0.244569129829729\n",
       "537. 0.0695160138076883\n",
       "538. 0.0929694896320363\n",
       "539. 0.0392310802440331\n",
       "540. 0.0542637800793991\n",
       "541. 0.0653810456920552\n",
       "542. 0.0505422648624419\n",
       "543. 0.0551708376756284\n",
       "544. 0.0392310802440331\n",
       "545. 0.0560397955266855\n",
       "546. 0.0470288916896563\n",
       "547. 0.274565303006101\n",
       "548. 0.0490962990063064\n",
       "549. 0.0470075575525019\n",
       "550. 0.0475228526033046\n",
       "551. 0.0611540814230824\n",
       "552. 0.884938987337465\n",
       "553. 0.0502434078176246\n",
       "554. 0.0497069746627195\n",
       "555. 0.691769676544765\n",
       "556. 0.0611540814230824\n",
       "557. 0.0544272976968682\n",
       "558. 0.250503227106907\n",
       "559. 0.106414006924995\n",
       "560. 0.0513187824044823\n",
       "561. 0.0721575750736133\n",
       "562. 0.0490962990063064\n",
       "563. 0.114856405438865\n",
       "564. 0.27361065837508\n",
       "565. 0.0402895636381069\n",
       "566. 0.379354997019281\n",
       "567. 0.0552492736542768\n",
       "568. 0.0611540814230824\n",
       "569. 0.0470288916896563\n",
       "570. 0.0490962990063064\n",
       "571. 0.305754482222158\n",
       "572. 0.0392310802440331\n",
       "573. 0.311617450825154\n",
       "574. 0.0460036020211568\n",
       "575. 0.279810622634911\n",
       "576. 0.0542637800793991\n",
       "577. 0.0929694896320363\n",
       "578. 0.0653810456920552\n",
       "579. 0.0396366452377635\n",
       "580. 0.0490962990063064\n",
       "581. 0.0695160138076883\n",
       "582. 0.0544272976968682\n",
       "583. 0.0435260095063634\n",
       "584. 0.688175318821066\n",
       "585. 0.0505422648624419\n",
       "586. 0.0929694896320363\n",
       "587. 0.0590500539589063\n",
       "588. 0.0590500539589063\n",
       "589. 0.0435260095063634\n",
       "590. 0.0392310802440331\n",
       "591. 0.0402895636381069\n",
       "592. 0.0611540814230824\n",
       "593. 0.0435260095063634\n",
       "594. 0.0460036020211568\n",
       "595. 0.0765758454701296\n",
       "596. 0.0513187824044823\n",
       "597. 0.0611540814230824\n",
       "598. 0.0551708376756284\n",
       "599. 0.0470075575525019\n",
       "600. 0.0393536392854195\n",
       "601. 0.0657939687931545\n",
       "602. 0.0502434078176246\n",
       "603. 0.0705376363419421\n",
       "604. 0.256076268019483\n",
       "605. 0.0392310802440331\n",
       "606. 0.0490962990063064\n",
       "607. 0.0394402944942955\n",
       "608. 0.0765758454701296\n",
       "609. 0.0435260095063634\n",
       "610. 0.811462237690797\n",
       "611. 0.0470075575525019\n",
       "612. 0.191843848732917\n",
       "613. 0.690114515233374\n",
       "614. 0.0962106361767415\n",
       "615. 0.0490962990063064\n",
       "616. 0.0437803287299971\n",
       "617. 0.284387025183037\n",
       "618. 0.598790655327105\n",
       "619. 0.0392310802440331\n",
       "620. 0.0470288916896563\n",
       "621. 0.0590500539589063\n",
       "622. 0.0392310802440331\n",
       "623. 0.0460036020211568\n",
       "624. 0.0392310802440331\n",
       "625. 0.0394402944942955\n",
       "626. 0.379979925545675\n",
       "627. 0.0505422648624419\n",
       "628. 0.0721575750736133\n",
       "629. 0.0434150169222341\n",
       "630. 0.0551708376756284\n",
       "631. 0.0470288916896563\n",
       "632. 0.0392310802440331\n",
       "633. 0.0705376363419421\n",
       "634. 0.0835203679657271\n",
       "635. 0.622941137331631\n",
       "636. 0.0497069746627195\n",
       "637. 0.0393536392854195\n",
       "638. 0.0505422648624419\n",
       "639. 0.0552492736542768\n",
       "640. 0.189232757039775\n",
       "641. 0.0470288916896563\n",
       "642. 0.0392310802440331\n",
       "643. 0.0470075575525019\n",
       "644. 0.0470288916896563\n",
       "645. 0.0392310802440331\n",
       "646. 0.0611540814230824\n",
       "647. 0.0544272976968682\n",
       "648. 0.0394402944942955\n",
       "649. 0.0765758454701296\n",
       "650. 0.0470075575525019\n",
       "651. 0.165601552319954\n",
       "652. 0.0396366452377635\n",
       "653. 0.0705376363419421\n",
       "654. 0.0721575750736133\n",
       "655. 0.0392310802440331\n",
       "656. 0.0502434078176246\n",
       "657. 0.0490962990063064\n",
       "658. 0.0392310802440331\n",
       "659. 0.0544272976968682\n",
       "660. 0.0490962990063064\n",
       "661. 0.0705376363419421\n",
       "662. 0.0437803287299971\n",
       "663. 0.0962106361767415\n",
       "664. 0.0611540814230824\n",
       "665. 0.0435260095063634\n",
       "666. 0.0490214531502574\n",
       "667. 0.0538687944265217\n",
       "668. 0.0538687944265217\n",
       "669. 0.0505422648624419\n",
       "670. 0.229403410942524\n",
       "671. 0.0502434078176246\n",
       "672. 0.0567028254012986\n",
       "673. 0.0835203679657271\n",
       "674. 0.0392310802440331\n",
       "675. 0.0467794145372378\n",
       "676. 0.0695160138076883\n",
       "677. 0.0393536392854195\n",
       "678. 0.0470288916896563\n",
       "679. 0.0460036020211568\n",
       "680. 0.0470288916896563\n",
       "681. 0.0538687944265217\n",
       "682. 0.0611540814230824\n",
       "683. 0.0611540814230824\n",
       "684. 0.319789800174937\n",
       "685. 0.274032647713637\n",
       "686. 0.0392310802440331\n",
       "687. 0.0544272976968682\n",
       "688. 0.309353138467764\n",
       "689. 0.0392310802440331\n",
       "690. 0.235926066878306\n",
       "691. 0.0538687944265217\n",
       "692. 0.0695160138076883\n",
       "693. 0.0437803287299971\n",
       "694. 0.0590500539589063\n",
       "695. 0.0396366452377635\n",
       "696. 0.0490962990063064\n",
       "697. 0.0611540814230824\n",
       "698. 0.0962106361767415\n",
       "699. 0.784384923120806\n",
       "700. 0.0435260095063634\n",
       "701. 0.0396650289448398\n",
       "702. 0.237500129498932\n",
       "703. 0.0502434078176246\n",
       "704. 0.114856405438865\n",
       "705. 0.0392310802440331\n",
       "706. 0.0544272976968682\n",
       "707. 0.0552492736542768\n",
       "708. 0.253743103386435\n",
       "709. 0.0490214531502574\n",
       "710. 0.0835203679657271\n",
       "711. 0.0835203679657271\n",
       "712. 0.0560397955266855\n",
       "713. 0.04370054580617\n",
       "714. 0.0502434078176246\n",
       "715. 0.0611540814230824\n",
       "716. 0.0502434078176246\n",
       "717. 0.0396366452377635\n",
       "718. 0.106414006924995\n",
       "719. 0.0551708376756284\n",
       "720. 0.235926066878306\n",
       "721. 0.0490962990063064\n",
       "722. 0.0393536392854195\n",
       "723. 0.0929694896320363\n",
       "724. 0.0538687944265217\n",
       "725. 0.0392310802440331\n",
       "726. 0.0490962990063064\n",
       "727. 0.802037086883042\n",
       "728. 0.0552492736542768\n",
       "729. 0.0392310802440331\n",
       "730. 0.197972627878753\n",
       "731. 0.0434150169222341\n",
       "732. 0.0505422648624419\n",
       "733. 0.0880917555294811\n",
       "734. 0.0502434078176246\n",
       "735. 0.0643366036373718\n",
       "736. 0.0590500539589063\n",
       "737. 0.0393536392854195\n",
       "738. 0.0392310802440331\n",
       "739. 0.0701340179492015\n",
       "740. 0.339494934326037\n",
       "741. 0.761863088622674\n",
       "742. 0.0552492736542768\n",
       "743. 0.0878686885357587\n",
       "744. 0.80661033239096\n",
       "745. 0.0393536392854195\n",
       "746. 0.0611540814230824\n",
       "747. 0.0695160138076883\n",
       "748. 0.063312536431413\n",
       "749. 0.0657939687931545\n",
       "750. 0.0505422648624419\n",
       "751. 0.251549885166514\n",
       "752. 0.0513187824044823\n",
       "753. 0.0590500539589063\n",
       "754. 0.0546790356122431\n",
       "755. 0.0393536392854195\n",
       "756. 0.0705376363419421\n",
       "757. 0.0394402944942955\n",
       "758. 0.0505422648624419\n",
       "759. 0.0653810456920552\n",
       "760. 0.279810622634911\n",
       "761. 0.0590500539589063\n",
       "762. 0.0396650289448398\n",
       "763. 0.04370054580617\n",
       "764. 0.260792897962035\n",
       "765. 0.114856405438865\n",
       "766. 0.209603598808645\n",
       "767. 0.34785931541269\n",
       "768. 0.252121559285981\n",
       "769. 0.0437803287299971\n",
       "770. 0.0505422648624419\n",
       "771. 0.0490962990063064\n",
       "772. 0.312322443993547\n",
       "773. 0.0611540814230824\n",
       "774. 0.0467794145372378\n",
       "775. 0.04370054580617\n",
       "776. 0.0880917555294811\n",
       "777. 0.0878686885357587\n",
       "778. 0.0464270858827943\n",
       "779. 0.0643366036373718\n",
       "780. 0.293367608396109\n",
       "781. 0.0502434078176246\n",
       "782. 0.0392310802440331\n",
       "783. 0.114856405438865\n",
       "784. 0.0546790356122431\n",
       "785. 0.191263037518618\n",
       "786. 0.265626858976541\n",
       "787. 0.0502434078176246\n",
       "788. 0.0546790356122431\n",
       "789. 0.0464270858827943\n",
       "790. 0.0546790356122431\n",
       "791. 0.0560397955266855\n",
       "792. 0.0393536392854195\n",
       "793. 0.0560397955266855\n",
       "794. 0.0392310802440331\n",
       "795. 0.0434150169222341\n",
       "796. 0.678254135311586\n",
       "797. 0.737992319524266\n",
       "798. 0.0962106361767415\n",
       "799. 0.0552492736542768\n",
       "800. 0.0643366036373718\n",
       "801. 0.439398623216433\n",
       "802. 0.237500129498932\n",
       "803. 0.0393536392854195\n",
       "804. 0.0470075575525019\n",
       "805. 0.766848590215638\n",
       "806. 0.0611540814230824\n",
       "807. 0.0470288916896563\n",
       "808. 0.0505422648624419\n",
       "809. 0.0434150169222341\n",
       "810. 0.0653810456920552\n",
       "811. 0.0544272976968682\n",
       "812. 0.0835203679657271\n",
       "813. 0.0505422648624419\n",
       "814. 0.0402895636381069\n",
       "815. 0.0878686885357587\n",
       "816. 0.0490962990063064\n",
       "817. 0.0544272976968682\n",
       "818. 0.0490962990063064\n",
       "819. 0.0765758454701296\n",
       "820. 0.461866473513337\n",
       "821. 0.0611540814230824\n",
       "822. 0.0880917555294811\n",
       "823. 0.04370054580617\n",
       "824. 0.0544272976968682\n",
       "825. 0.0475228526033046\n",
       "826. 0.0929694896320363\n",
       "827. 0.601932800760852\n",
       "828. 0.0560397955266855\n",
       "829. 0.051325292414123\n",
       "830. 0.0590500539589063\n",
       "831. 0.0880917555294811\n",
       "832. 0.0695160138076883\n",
       "833. 0.395701573579991\n",
       "834. 0.0590500539589063\n",
       "835. 0.382676812147653\n",
       "836. 0.0701340179492015\n",
       "837. 0.0392310802440331\n",
       "838. 0.0490214531502574\n",
       "839. 0.279810622634911\n",
       "840. 0.0590500539589063\n",
       "841. 0.0657939687931545\n",
       "842. 0.0502434078176246\n",
       "843. 0.0490962990063064\n",
       "844. 0.0653810456920552\n",
       "845. 0.0701340179492015\n",
       "846. 0.0611540814230824\n",
       "847. 0.344657162779725\n",
       "848. 0.161398727448971\n",
       "849. 0.0657939687931545\n",
       "850. 0.0396366452377635\n",
       "851. 0.432939205946586\n",
       "852. 0.187173649288501\n",
       "853. 0.312322443993547\n",
       "854. 0.0392310802440331\n",
       "855. 0.106414006924995\n",
       "856. 0.0653810456920552\n",
       "857. 0.0396366452377635\n",
       "858. 0.0611540814230824\n",
       "859. 0.792636349614848\n",
       "860. 0.04370054580617\n",
       "861. 0.0695160138076883\n",
       "862. 0.0502434078176246\n",
       "863. 0.251617582557877\n",
       "864. 0.0705376363419421\n",
       "865. 0.0392310802440331\n",
       "866. 0.0962106361767415\n",
       "867. 0.0392310802440331\n",
       "868. 0.253957190767119\n",
       "869. 0.231631097262436\n",
       "870. 0.0701340179492015\n",
       "871. 0.106414006924995\n",
       "872. 0.0392310802440331\n",
       "873. 0.0560397955266855\n",
       "874. 0.0505422648624419\n",
       "875. 0.0402895636381069\n",
       "876. 0.0392310802440331\n",
       "877. 0.0470075575525019\n",
       "878. 0.0396366452377635\n",
       "879. 0.0393536392854195\n",
       "880. 0.0470288916896563\n",
       "881. 0.189232757039775\n",
       "882. 0.0393536392854195\n",
       "883. 0.0590500539589063\n",
       "884. 0.0611540814230824\n",
       "885. 0.0653810456920552\n",
       "886. 0.0393536392854195\n",
       "887. 0.0611540814230824\n",
       "888. 0.0590500539589063\n",
       "889. 0.114856405438865\n",
       "890. 0.0611540814230824\n",
       "891. 0.0393536392854195\n",
       "892. 0.114856405438865\n",
       "893. 0.0611540814230824\n",
       "894. 0.0392310802440331\n",
       "895. 0.0396366452377635\n",
       "896. 0.0470075575525019\n",
       "897. 0.0546790356122431\n",
       "898. 0.0402895636381069\n",
       "899. 0.0392310802440331\n",
       "900. 0.0490214531502574\n",
       "901. 0.0705376363419421\n",
       "902. 0.209895197355668\n",
       "903. 0.0470075575525019\n",
       "904. 0.0560397955266855\n",
       "905. 0.04370054580617\n",
       "906. 0.0705376363419421\n",
       "907. 0.235926066878306\n",
       "908. 0.237500129498932\n",
       "909. 0.0590500539589063\n",
       "910. 0.347531056255353\n",
       "911. 0.12378719553553\n",
       "912. 0.0929694896320363\n",
       "913. 0.0467794145372378\n",
       "914. 0.483745589366804\n",
       "915. 0.0392310802440331\n",
       "916. 0.0490962990063064\n",
       "917. 0.0394402944942955\n",
       "918. 0.0490214531502574\n",
       "919. 0.416097304372128\n",
       "920. 0.0392310802440331\n",
       "921. 0.165601552319954\n",
       "922. 0.395701573579991\n",
       "923. 0.0513187824044823\n",
       "924. 0.0402895636381069\n",
       "925. 0.0880917555294811\n",
       "926. 0.0643366036373718\n",
       "927. 0.0460036020211568\n",
       "928. 0.0590500539589063\n",
       "929. 0.0470288916896563\n",
       "930. 0.0402895636381069\n",
       "931. 0.0470288916896563\n",
       "932. 0.0643366036373718\n",
       "933. 0.0880917555294811\n",
       "934. 0.0643366036373718\n",
       "935. 0.106414006924995\n",
       "936. 0.0546790356122431\n",
       "937. 0.0962106361767415\n",
       "938. 0.0475228526033046\n",
       "939. 0.0502434078176246\n",
       "940. 0.0490214531502574\n",
       "941. 0.0544272976968682\n",
       "942. 0.0393536392854195\n",
       "943. 0.598790655327105\n",
       "944. 0.0835203679657271\n",
       "945. 0.371024294944453\n",
       "946. 0.0490214531502574\n",
       "947. 0.341454682864037\n",
       "948. 0.0695160138076883\n",
       "949. 0.0590500539589063\n",
       "950. 0.0460036020211568\n",
       "951. 0.395701573579991\n",
       "952. 0.0962106361767415\n",
       "953. 0.0393536392854195\n",
       "954. 0.0643366036373718\n",
       "955. 0.0611540814230824\n",
       "956. 0.0590500539589063\n",
       "957. 0.0396366452377635\n",
       "958. 0.114856405438865\n",
       "959. 0.0611540814230824\n",
       "960. 0.6328550668449\n",
       "961. 0.0538687944265217\n",
       "962. 0.765534738762068\n",
       "963. 0.255792264796675\n",
       "964. 0.236846188140466\n",
       "965. 0.0394402944942955\n",
       "966. 0.0402895636381069\n",
       "967. 0.0544272976968682\n",
       "968. 0.0538687944265217\n",
       "969. 0.0402895636381069\n",
       "970. 0.0490214531502574\n",
       "971. 0.400516813923643\n",
       "972. 0.0590500539589063\n",
       "973. 0.0878686885357587\n",
       "974. 0.395701573579991\n",
       "975. 0.0505422648624419\n",
       "976. 0.0701340179492015\n",
       "977. 0.615521663397242\n",
       "978. 0.0460036020211568\n",
       "979. 0.375493676268522\n",
       "980. 0.0467794145372378\n",
       "981. 0.0546790356122431\n",
       "982. 0.0962106361767415\n",
       "983. 0.0470075575525019\n",
       "984. 0.0705376363419421\n",
       "985. 0.0502434078176246\n",
       "986. 0.156640602669229\n",
       "987. 0.0701340179492015\n",
       "988. 0.0567028254012986\n",
       "989. 0.0695160138076883\n",
       "990. 0.0835203679657271\n",
       "991. 0.0490962990063064\n",
       "992. 0.0835203679657271\n",
       "993. 0.0929694896320363\n",
       "994. 0.0657939687931545\n",
       "995. 0.0551708376756284\n",
       "996. 0.0490962990063064\n",
       "997. 0.0392310802440331\n",
       "998. 0.0392310802440331\n",
       "999. 0.0490962990063064\n",
       "1000. 0.0502434078176246\n",
       "1001. 0.0396366452377635\n",
       "1002. 0.0929694896320363\n",
       "1003. 0.04370054580617\n",
       "1004. 0.0552492736542768\n",
       "1005. 0.106414006924995\n",
       "1006. 0.337551731815556\n",
       "1007. 0.0502434078176246\n",
       "1008. 0.114856405438865\n",
       "1009. 0.0929694896320363\n",
       "1010. 0.0470075575525019\n",
       "1011. 0.664358678509347\n",
       "1012. 0.165601552319954\n",
       "1013. 0.375299959140913\n",
       "1014. 0.0470075575525019\n",
       "1015. 0.0393536392854195\n",
       "1016. 0.412994068873526\n",
       "1017. 0.21666774342788\n",
       "1018. 0.051325292414123\n",
       "1019. 0.0392310802440331\n",
       "1020. 0.0505422648624419\n",
       "1021. 0.0505422648624419\n",
       "1022. 0.0392310802440331\n",
       "1023. 0.0929694896320363\n",
       "1024. 0.189232757039775\n",
       "1025. 0.0392310802440331\n",
       "1026. 0.0396366452377635\n",
       "1027. 0.0402895636381069\n",
       "1028. 0.0546790356122431\n",
       "1029. 0.416097304372128\n",
       "1030. 0.0460036020211568\n",
       "1031. 0.0394402944942955\n",
       "1032. 0.0402895636381069\n",
       "1033. 0.415458248473933\n",
       "1034. 0.0434150169222341\n",
       "1035. 0.0880917555294811\n",
       "1036. 0.0546790356122431\n",
       "1037. 0.0392310802440331\n",
       "1038. 0.0611540814230824\n",
       "1039. 0.0705376363419421\n",
       "1040. 0.0560397955266855\n",
       "1041. 0.0396650289448398\n",
       "1042. 0.0560397955266855\n",
       "1043. 0.0505422648624419\n",
       "1044. 0.0560397955266855\n",
       "1045. 0.0929694896320363\n",
       "1046. 0.0643366036373718\n",
       "1047. 0.0611540814230824\n",
       "1048. 0.051325292414123\n",
       "1049. 0.0497069746627195\n",
       "1050. 0.0590500539589063\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   [1] 0.05905005 0.05386879 0.07215758 0.03923108 0.09296949 0.06115408\n",
       "   [7] 0.28683842 0.08809176 0.07013402 0.06579397 0.04702889 0.04909630\n",
       "  [13] 0.04677941 0.04909630 0.07657585 0.04909630 0.04970697 0.05024341\n",
       "  [19] 0.11485641 0.10641401 0.05670283 0.05024341 0.05386879 0.09296949\n",
       "  [25] 0.30993658 0.09621064 0.12378720 0.05467904 0.05132529 0.04341502\n",
       "  [31] 0.31978980 0.04752285 0.06951601 0.24269355 0.03944029 0.15664060\n",
       "  [37] 0.06433660 0.03923108 0.07215758 0.06115408 0.04902145 0.04700756\n",
       "  [43] 0.05054226 0.06538105 0.05524927 0.05386879 0.03966503 0.05024341\n",
       "  [49] 0.04902145 0.04909630 0.05386879 0.07053764 0.08809176 0.04702889\n",
       "  [55] 0.04600360 0.04700756 0.31896561 0.06538105 0.69268249 0.03923108\n",
       "  [61] 0.03966503 0.30162335 0.03923108 0.05386879 0.05024341 0.06115408\n",
       "  [67] 0.06115408 0.07215758 0.04600360 0.06538105 0.06115408 0.24269355\n",
       "  [73] 0.06579397 0.04702889 0.03944029 0.03923108 0.03935364 0.05603980\n",
       "  [79] 0.03923108 0.05517084 0.04642709 0.06115408 0.04600360 0.64790409\n",
       "  [85] 0.26079290 0.04028956 0.07013402 0.06115408 0.04341502 0.15664060\n",
       "  [91] 0.03963665 0.07657585 0.25161758 0.04970697 0.10641401 0.03923108\n",
       "  [97] 0.05603980 0.06115408 0.06538105 0.04702889 0.03923108 0.04028956\n",
       " [103] 0.05905005 0.04702889 0.03923108 0.06115408 0.34785932 0.04902145\n",
       " [109] 0.11485641 0.03923108 0.06115408 0.07657585 0.25871284 0.05386879\n",
       " [115] 0.05386879 0.73447716 0.36003708 0.05603980 0.06538105 0.27981062\n",
       " [121] 0.27002865 0.04700756 0.27002865 0.09296949 0.04700756 0.04902145\n",
       " [127] 0.03935364 0.06433660 0.04028956 0.18923276 0.03935364 0.08809176\n",
       " [133] 0.05603980 0.04702889 0.03923108 0.03923108 0.09296949 0.16560155\n",
       " [139] 0.06115408 0.03935364 0.05524927 0.09621064 0.51979672 0.07053764\n",
       " [145] 0.05054226 0.05524927 0.04970697 0.04702889 0.07013402 0.08809176\n",
       " [151] 0.03935364 0.08352037 0.54418897 0.58880659 0.09621064 0.07053764\n",
       " [157] 0.07013402 0.09296949 0.09447248 0.06115408 0.11485641 0.44302036\n",
       " [163] 0.09296949 0.03923108 0.07053764 0.06115408 0.04909630 0.05054226\n",
       " [169] 0.04028956 0.06579397 0.06115408 0.03944029 0.33269731 0.04370055\n",
       " [175] 0.05517084 0.05524927 0.04702889 0.05442730 0.65611351 0.39570157\n",
       " [181] 0.03963665 0.11485641 0.05024341 0.07657585 0.23684619 0.06951601\n",
       " [187] 0.08352037 0.03935364 0.07215758 0.06579397 0.06115408 0.06579397\n",
       " [193] 0.03963665 0.05524927 0.19816856 0.04677941 0.07053764 0.05603980\n",
       " [199] 0.11485641 0.27002865 0.04909630 0.06579397 0.06538105 0.04677941\n",
       " [205] 0.05524927 0.05054226 0.06951601 0.03923108 0.03923108 0.04341502\n",
       " [211] 0.05467904 0.06115408 0.04902145 0.06951601 0.09621064 0.03923108\n",
       " [217] 0.07013402 0.04600360 0.11485641 0.06115408 0.07013402 0.11041364\n",
       " [223] 0.05524927 0.05054226 0.06579397 0.09296949 0.06579397 0.05524927\n",
       " [229] 0.03944029 0.05517084 0.23532939 0.18923276 0.10641401 0.08809176\n",
       " [235] 0.05426378 0.09296949 0.05467904 0.81277070 0.42674838 0.07215758\n",
       " [241] 0.03963665 0.54417557 0.07013402 0.04700756 0.15664060 0.08352037\n",
       " [247] 0.33755173 0.06115408 0.06538105 0.05054226 0.03923108 0.04970697\n",
       " [253] 0.06433660 0.04677941 0.31538555 0.10641401 0.03963665 0.03923108\n",
       " [259] 0.09621064 0.03966503 0.04909630 0.04702889 0.05024341 0.07013402\n",
       " [265] 0.18923276 0.03944029 0.03935364 0.04909630 0.10641401 0.05524927\n",
       " [271] 0.03935364 0.21666774 0.05132529 0.05905005 0.03963665 0.24269355\n",
       " [277] 0.05517084 0.39570157 0.06115408 0.21141354 0.07013402 0.05024341\n",
       " [283] 0.41243168 0.05524927 0.06579397 0.03923108 0.04677941 0.05054226\n",
       " [289] 0.70148402 0.04902145 0.27403265 0.05524927 0.11485641 0.06538105\n",
       " [295] 0.76790234 0.09621064 0.03923108 0.09621064 0.66173937 0.04902145\n",
       " [301] 0.28680816 0.09621064 0.03923108 0.05132529 0.20989520 0.05054226\n",
       " [307] 0.27403265 0.05024341 0.04378033 0.06579397 0.07657585 0.66703051\n",
       " [313] 0.37529996 0.56705678 0.80302335 0.04702889 0.05524927 0.05386879\n",
       " [319] 0.08352037 0.04600360 0.05905005 0.05905005 0.03935364 0.04600360\n",
       " [325] 0.03944029 0.06115408 0.05603980 0.09296949 0.04902145 0.03923108\n",
       " [331] 0.19648704 0.03963665 0.05905005 0.05467904 0.03923108 0.05670283\n",
       " [337] 0.04370055 0.03923108 0.05442730 0.04352601 0.09296949 0.05024341\n",
       " [343] 0.08809176 0.07657585 0.03944029 0.34948353 0.03923108 0.74158236\n",
       " [349] 0.31232244 0.04909630 0.03966503 0.09621064 0.03963665 0.05054226\n",
       " [355] 0.05386879 0.09296949 0.07013402 0.04702889 0.11485641 0.03923108\n",
       " [361] 0.09621064 0.06115408 0.05905005 0.03923108 0.08352037 0.64020554\n",
       " [367] 0.06538105 0.11485641 0.04341502 0.05054226 0.43293921 0.04028956\n",
       " [373] 0.05054226 0.04700756 0.57405188 0.39570157 0.07657585 0.71315937\n",
       " [379] 0.04909630 0.06115408 0.31978980 0.10641401 0.05054226 0.05386879\n",
       " [385] 0.05386879 0.06115408 0.04909630 0.04352601 0.08352037 0.36462881\n",
       " [391] 0.31352787 0.06951601 0.04028956 0.53463062 0.49881652 0.43293921\n",
       " [397] 0.63961404 0.03935364 0.30750844 0.04909630 0.03935364 0.04700756\n",
       " [403] 0.03966503 0.03923108 0.07053764 0.05905005 0.08809176 0.07215758\n",
       " [409] 0.04028956 0.05524927 0.21603425 0.04700756 0.04642709 0.04700756\n",
       " [415] 0.06538105 0.07013402 0.04970697 0.05905005 0.04909630 0.03923108\n",
       " [421] 0.10641401 0.06115408 0.05524927 0.05603980 0.04702889 0.06115408\n",
       " [427] 0.08809176 0.04677941 0.05024341 0.08352037 0.04370055 0.09296949\n",
       " [433] 0.04028956 0.05054226 0.07013402 0.05054226 0.06951601 0.05524927\n",
       " [439] 0.06115408 0.07657585 0.43224496 0.04677941 0.44950656 0.03935364\n",
       " [445] 0.05054226 0.67825414 0.24425432 0.07053764 0.20989520 0.05905005\n",
       " [451] 0.68992423 0.04600360 0.03923108 0.06433660 0.04600360 0.07657585\n",
       " [457] 0.03923108 0.05024341 0.07013402 0.04702889 0.10641401 0.05905005\n",
       " [463] 0.05131878 0.06579397 0.04902145 0.04909630 0.09621064 0.90027224\n",
       " [469] 0.06115408 0.04378033 0.03966503 0.05024341 0.05386879 0.04909630\n",
       " [475] 0.03963665 0.05517084 0.06579397 0.05905005 0.06538105 0.04677941\n",
       " [481] 0.03923108 0.03944029 0.03923108 0.03935364 0.04902145 0.03963665\n",
       " [487] 0.03966503 0.06579397 0.07657585 0.06115408 0.19797263 0.04352601\n",
       " [493] 0.03966503 0.07657585 0.03923108 0.05024341 0.03923108 0.05386879\n",
       " [499] 0.07013402 0.05054226 0.05054226 0.05524927 0.05054226 0.03923108\n",
       " [505] 0.05024341 0.31232244 0.04028956 0.07053764 0.05442730 0.27981062\n",
       " [511] 0.04352601 0.03966503 0.86377808 0.06538105 0.05905005 0.08352037\n",
       " [517] 0.05905005 0.41759449 0.06433660 0.04752285 0.04752285 0.05054226\n",
       " [523] 0.07215758 0.04642709 0.04600360 0.05054226 0.04909630 0.34785932\n",
       " [529] 0.21666774 0.03923108 0.03923108 0.05905005 0.04702889 0.16560155\n",
       " [535] 0.04700756 0.24456913 0.06951601 0.09296949 0.03923108 0.05426378\n",
       " [541] 0.06538105 0.05054226 0.05517084 0.03923108 0.05603980 0.04702889\n",
       " [547] 0.27456530 0.04909630 0.04700756 0.04752285 0.06115408 0.88493899\n",
       " [553] 0.05024341 0.04970697 0.69176968 0.06115408 0.05442730 0.25050323\n",
       " [559] 0.10641401 0.05131878 0.07215758 0.04909630 0.11485641 0.27361066\n",
       " [565] 0.04028956 0.37935500 0.05524927 0.06115408 0.04702889 0.04909630\n",
       " [571] 0.30575448 0.03923108 0.31161745 0.04600360 0.27981062 0.05426378\n",
       " [577] 0.09296949 0.06538105 0.03963665 0.04909630 0.06951601 0.05442730\n",
       " [583] 0.04352601 0.68817532 0.05054226 0.09296949 0.05905005 0.05905005\n",
       " [589] 0.04352601 0.03923108 0.04028956 0.06115408 0.04352601 0.04600360\n",
       " [595] 0.07657585 0.05131878 0.06115408 0.05517084 0.04700756 0.03935364\n",
       " [601] 0.06579397 0.05024341 0.07053764 0.25607627 0.03923108 0.04909630\n",
       " [607] 0.03944029 0.07657585 0.04352601 0.81146224 0.04700756 0.19184385\n",
       " [613] 0.69011452 0.09621064 0.04909630 0.04378033 0.28438703 0.59879066\n",
       " [619] 0.03923108 0.04702889 0.05905005 0.03923108 0.04600360 0.03923108\n",
       " [625] 0.03944029 0.37997993 0.05054226 0.07215758 0.04341502 0.05517084\n",
       " [631] 0.04702889 0.03923108 0.07053764 0.08352037 0.62294114 0.04970697\n",
       " [637] 0.03935364 0.05054226 0.05524927 0.18923276 0.04702889 0.03923108\n",
       " [643] 0.04700756 0.04702889 0.03923108 0.06115408 0.05442730 0.03944029\n",
       " [649] 0.07657585 0.04700756 0.16560155 0.03963665 0.07053764 0.07215758\n",
       " [655] 0.03923108 0.05024341 0.04909630 0.03923108 0.05442730 0.04909630\n",
       " [661] 0.07053764 0.04378033 0.09621064 0.06115408 0.04352601 0.04902145\n",
       " [667] 0.05386879 0.05386879 0.05054226 0.22940341 0.05024341 0.05670283\n",
       " [673] 0.08352037 0.03923108 0.04677941 0.06951601 0.03935364 0.04702889\n",
       " [679] 0.04600360 0.04702889 0.05386879 0.06115408 0.06115408 0.31978980\n",
       " [685] 0.27403265 0.03923108 0.05442730 0.30935314 0.03923108 0.23592607\n",
       " [691] 0.05386879 0.06951601 0.04378033 0.05905005 0.03963665 0.04909630\n",
       " [697] 0.06115408 0.09621064 0.78438492 0.04352601 0.03966503 0.23750013\n",
       " [703] 0.05024341 0.11485641 0.03923108 0.05442730 0.05524927 0.25374310\n",
       " [709] 0.04902145 0.08352037 0.08352037 0.05603980 0.04370055 0.05024341\n",
       " [715] 0.06115408 0.05024341 0.03963665 0.10641401 0.05517084 0.23592607\n",
       " [721] 0.04909630 0.03935364 0.09296949 0.05386879 0.03923108 0.04909630\n",
       " [727] 0.80203709 0.05524927 0.03923108 0.19797263 0.04341502 0.05054226\n",
       " [733] 0.08809176 0.05024341 0.06433660 0.05905005 0.03935364 0.03923108\n",
       " [739] 0.07013402 0.33949493 0.76186309 0.05524927 0.08786869 0.80661033\n",
       " [745] 0.03935364 0.06115408 0.06951601 0.06331254 0.06579397 0.05054226\n",
       " [751] 0.25154989 0.05131878 0.05905005 0.05467904 0.03935364 0.07053764\n",
       " [757] 0.03944029 0.05054226 0.06538105 0.27981062 0.05905005 0.03966503\n",
       " [763] 0.04370055 0.26079290 0.11485641 0.20960360 0.34785932 0.25212156\n",
       " [769] 0.04378033 0.05054226 0.04909630 0.31232244 0.06115408 0.04677941\n",
       " [775] 0.04370055 0.08809176 0.08786869 0.04642709 0.06433660 0.29336761\n",
       " [781] 0.05024341 0.03923108 0.11485641 0.05467904 0.19126304 0.26562686\n",
       " [787] 0.05024341 0.05467904 0.04642709 0.05467904 0.05603980 0.03935364\n",
       " [793] 0.05603980 0.03923108 0.04341502 0.67825414 0.73799232 0.09621064\n",
       " [799] 0.05524927 0.06433660 0.43939862 0.23750013 0.03935364 0.04700756\n",
       " [805] 0.76684859 0.06115408 0.04702889 0.05054226 0.04341502 0.06538105\n",
       " [811] 0.05442730 0.08352037 0.05054226 0.04028956 0.08786869 0.04909630\n",
       " [817] 0.05442730 0.04909630 0.07657585 0.46186647 0.06115408 0.08809176\n",
       " [823] 0.04370055 0.05442730 0.04752285 0.09296949 0.60193280 0.05603980\n",
       " [829] 0.05132529 0.05905005 0.08809176 0.06951601 0.39570157 0.05905005\n",
       " [835] 0.38267681 0.07013402 0.03923108 0.04902145 0.27981062 0.05905005\n",
       " [841] 0.06579397 0.05024341 0.04909630 0.06538105 0.07013402 0.06115408\n",
       " [847] 0.34465716 0.16139873 0.06579397 0.03963665 0.43293921 0.18717365\n",
       " [853] 0.31232244 0.03923108 0.10641401 0.06538105 0.03963665 0.06115408\n",
       " [859] 0.79263635 0.04370055 0.06951601 0.05024341 0.25161758 0.07053764\n",
       " [865] 0.03923108 0.09621064 0.03923108 0.25395719 0.23163110 0.07013402\n",
       " [871] 0.10641401 0.03923108 0.05603980 0.05054226 0.04028956 0.03923108\n",
       " [877] 0.04700756 0.03963665 0.03935364 0.04702889 0.18923276 0.03935364\n",
       " [883] 0.05905005 0.06115408 0.06538105 0.03935364 0.06115408 0.05905005\n",
       " [889] 0.11485641 0.06115408 0.03935364 0.11485641 0.06115408 0.03923108\n",
       " [895] 0.03963665 0.04700756 0.05467904 0.04028956 0.03923108 0.04902145\n",
       " [901] 0.07053764 0.20989520 0.04700756 0.05603980 0.04370055 0.07053764\n",
       " [907] 0.23592607 0.23750013 0.05905005 0.34753106 0.12378720 0.09296949\n",
       " [913] 0.04677941 0.48374559 0.03923108 0.04909630 0.03944029 0.04902145\n",
       " [919] 0.41609730 0.03923108 0.16560155 0.39570157 0.05131878 0.04028956\n",
       " [925] 0.08809176 0.06433660 0.04600360 0.05905005 0.04702889 0.04028956\n",
       " [931] 0.04702889 0.06433660 0.08809176 0.06433660 0.10641401 0.05467904\n",
       " [937] 0.09621064 0.04752285 0.05024341 0.04902145 0.05442730 0.03935364\n",
       " [943] 0.59879066 0.08352037 0.37102429 0.04902145 0.34145468 0.06951601\n",
       " [949] 0.05905005 0.04600360 0.39570157 0.09621064 0.03935364 0.06433660\n",
       " [955] 0.06115408 0.05905005 0.03963665 0.11485641 0.06115408 0.63285507\n",
       " [961] 0.05386879 0.76553474 0.25579226 0.23684619 0.03944029 0.04028956\n",
       " [967] 0.05442730 0.05386879 0.04028956 0.04902145 0.40051681 0.05905005\n",
       " [973] 0.08786869 0.39570157 0.05054226 0.07013402 0.61552166 0.04600360\n",
       " [979] 0.37549368 0.04677941 0.05467904 0.09621064 0.04700756 0.07053764\n",
       " [985] 0.05024341 0.15664060 0.07013402 0.05670283 0.06951601 0.08352037\n",
       " [991] 0.04909630 0.08352037 0.09296949 0.06579397 0.05517084 0.04909630\n",
       " [997] 0.03923108 0.03923108 0.04909630 0.05024341 0.03963665 0.09296949\n",
       "[1003] 0.04370055 0.05524927 0.10641401 0.33755173 0.05024341 0.11485641\n",
       "[1009] 0.09296949 0.04700756 0.66435868 0.16560155 0.37529996 0.04700756\n",
       "[1015] 0.03935364 0.41299407 0.21666774 0.05132529 0.03923108 0.05054226\n",
       "[1021] 0.05054226 0.03923108 0.09296949 0.18923276 0.03923108 0.03963665\n",
       "[1027] 0.04028956 0.05467904 0.41609730 0.04600360 0.03944029 0.04028956\n",
       "[1033] 0.41545825 0.04341502 0.08809176 0.05467904 0.03923108 0.06115408\n",
       "[1039] 0.07053764 0.05603980 0.03966503 0.05603980 0.05054226 0.05603980\n",
       "[1045] 0.09296949 0.06433660 0.06115408 0.05132529 0.04970697 0.05905005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model on validation set \n",
    "gb.pred = predict(gb ,valid_processed[, -1], n.trees = 1500, type='response')\n",
    "\n",
    "# if probabibility is > 0.5 consider as subscribe\n",
    "gb.pred2 <- ifelse(gb.pred > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction   0   1\n",
      "         0 912  20\n",
      "         1  92  26\n",
      "                                          \n",
      "               Accuracy : 0.8933          \n",
      "                 95% CI : (0.8731, 0.9114)\n",
      "    No Information Rate : 0.9562          \n",
      "    P-Value [Acc > NIR] : 1               \n",
      "                                          \n",
      "                  Kappa : 0.2711          \n",
      "                                          \n",
      " Mcnemar's Test P-Value : 1.961e-11       \n",
      "                                          \n",
      "            Sensitivity : 0.9084          \n",
      "            Specificity : 0.5652          \n",
      "         Pos Pred Value : 0.9785          \n",
      "         Neg Pred Value : 0.2203          \n",
      "             Prevalence : 0.9562          \n",
      "         Detection Rate : 0.8686          \n",
      "   Detection Prevalence : 0.8876          \n",
      "      Balanced Accuracy : 0.7368          \n",
      "                                          \n",
      "       'Positive' Class : 0               \n",
      "                                          \n"
     ]
    }
   ],
   "source": [
    "# look at the confusion matrix - 89.3% accuracy\n",
    "cm = confusionMatrix(as.factor(valid_processed$subscribe), as.factor(gb.pred2))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.9409499 </td><td>0.05905005</td></tr>\n",
       "\t<tr><td>0.9461312 </td><td>0.05386879</td></tr>\n",
       "\t<tr><td>0.9278424 </td><td>0.07215758</td></tr>\n",
       "\t<tr><td>0.9607689 </td><td>0.03923108</td></tr>\n",
       "\t<tr><td>0.9070305 </td><td>0.09296949</td></tr>\n",
       "\t<tr><td>0.9388459 </td><td>0.06115408</td></tr>\n",
       "\t<tr><td>0.7131616 </td><td>0.28683842</td></tr>\n",
       "\t<tr><td>0.9119082 </td><td>0.08809176</td></tr>\n",
       "\t<tr><td>0.9298660 </td><td>0.07013402</td></tr>\n",
       "\t<tr><td>0.9342060 </td><td>0.06579397</td></tr>\n",
       "\t<tr><td>0.9529711 </td><td>0.04702889</td></tr>\n",
       "\t<tr><td>0.9509037 </td><td>0.04909630</td></tr>\n",
       "\t<tr><td>0.9532206 </td><td>0.04677941</td></tr>\n",
       "\t<tr><td>0.9509037 </td><td>0.04909630</td></tr>\n",
       "\t<tr><td>0.9234242 </td><td>0.07657585</td></tr>\n",
       "\t<tr><td>0.9509037 </td><td>0.04909630</td></tr>\n",
       "\t<tr><td>0.9502930 </td><td>0.04970697</td></tr>\n",
       "\t<tr><td>0.9497566 </td><td>0.05024341</td></tr>\n",
       "\t<tr><td>0.8851436 </td><td>0.11485641</td></tr>\n",
       "\t<tr><td>0.8935860 </td><td>0.10641401</td></tr>\n",
       "\t<tr><td>0.9432972 </td><td>0.05670283</td></tr>\n",
       "\t<tr><td>0.9497566 </td><td>0.05024341</td></tr>\n",
       "\t<tr><td>0.9461312 </td><td>0.05386879</td></tr>\n",
       "\t<tr><td>0.9070305 </td><td>0.09296949</td></tr>\n",
       "\t<tr><td>0.6900634 </td><td>0.30993658</td></tr>\n",
       "\t<tr><td>0.9037894 </td><td>0.09621064</td></tr>\n",
       "\t<tr><td>0.8762128 </td><td>0.12378720</td></tr>\n",
       "\t<tr><td>0.9453210 </td><td>0.05467904</td></tr>\n",
       "\t<tr><td>0.9486747 </td><td>0.05132529</td></tr>\n",
       "\t<tr><td>0.9565850 </td><td>0.04341502</td></tr>\n",
       "\t<tr><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>0.9494577 </td><td>0.05054226</td></tr>\n",
       "\t<tr><td>0.9607689 </td><td>0.03923108</td></tr>\n",
       "\t<tr><td>0.9070305 </td><td>0.09296949</td></tr>\n",
       "\t<tr><td>0.8107672 </td><td>0.18923276</td></tr>\n",
       "\t<tr><td>0.9607689 </td><td>0.03923108</td></tr>\n",
       "\t<tr><td>0.9603634 </td><td>0.03963665</td></tr>\n",
       "\t<tr><td>0.9597104 </td><td>0.04028956</td></tr>\n",
       "\t<tr><td>0.9453210 </td><td>0.05467904</td></tr>\n",
       "\t<tr><td>0.5839027 </td><td>0.41609730</td></tr>\n",
       "\t<tr><td>0.9539964 </td><td>0.04600360</td></tr>\n",
       "\t<tr><td>0.9605597 </td><td>0.03944029</td></tr>\n",
       "\t<tr><td>0.9597104 </td><td>0.04028956</td></tr>\n",
       "\t<tr><td>0.5845418 </td><td>0.41545825</td></tr>\n",
       "\t<tr><td>0.9565850 </td><td>0.04341502</td></tr>\n",
       "\t<tr><td>0.9119082 </td><td>0.08809176</td></tr>\n",
       "\t<tr><td>0.9453210 </td><td>0.05467904</td></tr>\n",
       "\t<tr><td>0.9607689 </td><td>0.03923108</td></tr>\n",
       "\t<tr><td>0.9388459 </td><td>0.06115408</td></tr>\n",
       "\t<tr><td>0.9294624 </td><td>0.07053764</td></tr>\n",
       "\t<tr><td>0.9439602 </td><td>0.05603980</td></tr>\n",
       "\t<tr><td>0.9603350 </td><td>0.03966503</td></tr>\n",
       "\t<tr><td>0.9439602 </td><td>0.05603980</td></tr>\n",
       "\t<tr><td>0.9494577 </td><td>0.05054226</td></tr>\n",
       "\t<tr><td>0.9439602 </td><td>0.05603980</td></tr>\n",
       "\t<tr><td>0.9070305 </td><td>0.09296949</td></tr>\n",
       "\t<tr><td>0.9356634 </td><td>0.06433660</td></tr>\n",
       "\t<tr><td>0.9388459 </td><td>0.06115408</td></tr>\n",
       "\t<tr><td>0.9486747 </td><td>0.05132529</td></tr>\n",
       "\t<tr><td>0.9502930 </td><td>0.04970697</td></tr>\n",
       "\t<tr><td>0.9409499 </td><td>0.05905005</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " 0 & 1\\\\\n",
       "\\hline\n",
       "\t 0.9409499  & 0.05905005\\\\\n",
       "\t 0.9461312  & 0.05386879\\\\\n",
       "\t 0.9278424  & 0.07215758\\\\\n",
       "\t 0.9607689  & 0.03923108\\\\\n",
       "\t 0.9070305  & 0.09296949\\\\\n",
       "\t 0.9388459  & 0.06115408\\\\\n",
       "\t 0.7131616  & 0.28683842\\\\\n",
       "\t 0.9119082  & 0.08809176\\\\\n",
       "\t 0.9298660  & 0.07013402\\\\\n",
       "\t 0.9342060  & 0.06579397\\\\\n",
       "\t 0.9529711  & 0.04702889\\\\\n",
       "\t 0.9509037  & 0.04909630\\\\\n",
       "\t 0.9532206  & 0.04677941\\\\\n",
       "\t 0.9509037  & 0.04909630\\\\\n",
       "\t 0.9234242  & 0.07657585\\\\\n",
       "\t 0.9509037  & 0.04909630\\\\\n",
       "\t 0.9502930  & 0.04970697\\\\\n",
       "\t 0.9497566  & 0.05024341\\\\\n",
       "\t 0.8851436  & 0.11485641\\\\\n",
       "\t 0.8935860  & 0.10641401\\\\\n",
       "\t 0.9432972  & 0.05670283\\\\\n",
       "\t 0.9497566  & 0.05024341\\\\\n",
       "\t 0.9461312  & 0.05386879\\\\\n",
       "\t 0.9070305  & 0.09296949\\\\\n",
       "\t 0.6900634  & 0.30993658\\\\\n",
       "\t 0.9037894  & 0.09621064\\\\\n",
       "\t 0.8762128  & 0.12378720\\\\\n",
       "\t 0.9453210  & 0.05467904\\\\\n",
       "\t 0.9486747  & 0.05132529\\\\\n",
       "\t 0.9565850  & 0.04341502\\\\\n",
       "\t ... & ...\\\\\n",
       "\t 0.9494577  & 0.05054226\\\\\n",
       "\t 0.9607689  & 0.03923108\\\\\n",
       "\t 0.9070305  & 0.09296949\\\\\n",
       "\t 0.8107672  & 0.18923276\\\\\n",
       "\t 0.9607689  & 0.03923108\\\\\n",
       "\t 0.9603634  & 0.03963665\\\\\n",
       "\t 0.9597104  & 0.04028956\\\\\n",
       "\t 0.9453210  & 0.05467904\\\\\n",
       "\t 0.5839027  & 0.41609730\\\\\n",
       "\t 0.9539964  & 0.04600360\\\\\n",
       "\t 0.9605597  & 0.03944029\\\\\n",
       "\t 0.9597104  & 0.04028956\\\\\n",
       "\t 0.5845418  & 0.41545825\\\\\n",
       "\t 0.9565850  & 0.04341502\\\\\n",
       "\t 0.9119082  & 0.08809176\\\\\n",
       "\t 0.9453210  & 0.05467904\\\\\n",
       "\t 0.9607689  & 0.03923108\\\\\n",
       "\t 0.9388459  & 0.06115408\\\\\n",
       "\t 0.9294624  & 0.07053764\\\\\n",
       "\t 0.9439602  & 0.05603980\\\\\n",
       "\t 0.9603350  & 0.03966503\\\\\n",
       "\t 0.9439602  & 0.05603980\\\\\n",
       "\t 0.9494577  & 0.05054226\\\\\n",
       "\t 0.9439602  & 0.05603980\\\\\n",
       "\t 0.9070305  & 0.09296949\\\\\n",
       "\t 0.9356634  & 0.06433660\\\\\n",
       "\t 0.9388459  & 0.06115408\\\\\n",
       "\t 0.9486747  & 0.05132529\\\\\n",
       "\t 0.9502930  & 0.04970697\\\\\n",
       "\t 0.9409499  & 0.05905005\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 1 |\n",
       "|---|---|\n",
       "| 0.9409499  | 0.05905005 |\n",
       "| 0.9461312  | 0.05386879 |\n",
       "| 0.9278424  | 0.07215758 |\n",
       "| 0.9607689  | 0.03923108 |\n",
       "| 0.9070305  | 0.09296949 |\n",
       "| 0.9388459  | 0.06115408 |\n",
       "| 0.7131616  | 0.28683842 |\n",
       "| 0.9119082  | 0.08809176 |\n",
       "| 0.9298660  | 0.07013402 |\n",
       "| 0.9342060  | 0.06579397 |\n",
       "| 0.9529711  | 0.04702889 |\n",
       "| 0.9509037  | 0.04909630 |\n",
       "| 0.9532206  | 0.04677941 |\n",
       "| 0.9509037  | 0.04909630 |\n",
       "| 0.9234242  | 0.07657585 |\n",
       "| 0.9509037  | 0.04909630 |\n",
       "| 0.9502930  | 0.04970697 |\n",
       "| 0.9497566  | 0.05024341 |\n",
       "| 0.8851436  | 0.11485641 |\n",
       "| 0.8935860  | 0.10641401 |\n",
       "| 0.9432972  | 0.05670283 |\n",
       "| 0.9497566  | 0.05024341 |\n",
       "| 0.9461312  | 0.05386879 |\n",
       "| 0.9070305  | 0.09296949 |\n",
       "| 0.6900634  | 0.30993658 |\n",
       "| 0.9037894  | 0.09621064 |\n",
       "| 0.8762128  | 0.12378720 |\n",
       "| 0.9453210  | 0.05467904 |\n",
       "| 0.9486747  | 0.05132529 |\n",
       "| 0.9565850  | 0.04341502 |\n",
       "| ... | ... |\n",
       "| 0.9494577  | 0.05054226 |\n",
       "| 0.9607689  | 0.03923108 |\n",
       "| 0.9070305  | 0.09296949 |\n",
       "| 0.8107672  | 0.18923276 |\n",
       "| 0.9607689  | 0.03923108 |\n",
       "| 0.9603634  | 0.03963665 |\n",
       "| 0.9597104  | 0.04028956 |\n",
       "| 0.9453210  | 0.05467904 |\n",
       "| 0.5839027  | 0.41609730 |\n",
       "| 0.9539964  | 0.04600360 |\n",
       "| 0.9605597  | 0.03944029 |\n",
       "| 0.9597104  | 0.04028956 |\n",
       "| 0.5845418  | 0.41545825 |\n",
       "| 0.9565850  | 0.04341502 |\n",
       "| 0.9119082  | 0.08809176 |\n",
       "| 0.9453210  | 0.05467904 |\n",
       "| 0.9607689  | 0.03923108 |\n",
       "| 0.9388459  | 0.06115408 |\n",
       "| 0.9294624  | 0.07053764 |\n",
       "| 0.9439602  | 0.05603980 |\n",
       "| 0.9603350  | 0.03966503 |\n",
       "| 0.9439602  | 0.05603980 |\n",
       "| 0.9494577  | 0.05054226 |\n",
       "| 0.9439602  | 0.05603980 |\n",
       "| 0.9070305  | 0.09296949 |\n",
       "| 0.9356634  | 0.06433660 |\n",
       "| 0.9388459  | 0.06115408 |\n",
       "| 0.9486747  | 0.05132529 |\n",
       "| 0.9502930  | 0.04970697 |\n",
       "| 0.9409499  | 0.05905005 |\n",
       "\n"
      ],
      "text/plain": [
       "     0         1         \n",
       "1    0.9409499 0.05905005\n",
       "2    0.9461312 0.05386879\n",
       "3    0.9278424 0.07215758\n",
       "4    0.9607689 0.03923108\n",
       "5    0.9070305 0.09296949\n",
       "6    0.9388459 0.06115408\n",
       "7    0.7131616 0.28683842\n",
       "8    0.9119082 0.08809176\n",
       "9    0.9298660 0.07013402\n",
       "10   0.9342060 0.06579397\n",
       "11   0.9529711 0.04702889\n",
       "12   0.9509037 0.04909630\n",
       "13   0.9532206 0.04677941\n",
       "14   0.9509037 0.04909630\n",
       "15   0.9234242 0.07657585\n",
       "16   0.9509037 0.04909630\n",
       "17   0.9502930 0.04970697\n",
       "18   0.9497566 0.05024341\n",
       "19   0.8851436 0.11485641\n",
       "20   0.8935860 0.10641401\n",
       "21   0.9432972 0.05670283\n",
       "22   0.9497566 0.05024341\n",
       "23   0.9461312 0.05386879\n",
       "24   0.9070305 0.09296949\n",
       "25   0.6900634 0.30993658\n",
       "26   0.9037894 0.09621064\n",
       "27   0.8762128 0.12378720\n",
       "28   0.9453210 0.05467904\n",
       "29   0.9486747 0.05132529\n",
       "30   0.9565850 0.04341502\n",
       "...  ...       ...       \n",
       "1021 0.9494577 0.05054226\n",
       "1022 0.9607689 0.03923108\n",
       "1023 0.9070305 0.09296949\n",
       "1024 0.8107672 0.18923276\n",
       "1025 0.9607689 0.03923108\n",
       "1026 0.9603634 0.03963665\n",
       "1027 0.9597104 0.04028956\n",
       "1028 0.9453210 0.05467904\n",
       "1029 0.5839027 0.41609730\n",
       "1030 0.9539964 0.04600360\n",
       "1031 0.9605597 0.03944029\n",
       "1032 0.9597104 0.04028956\n",
       "1033 0.5845418 0.41545825\n",
       "1034 0.9565850 0.04341502\n",
       "1035 0.9119082 0.08809176\n",
       "1036 0.9453210 0.05467904\n",
       "1037 0.9607689 0.03923108\n",
       "1038 0.9388459 0.06115408\n",
       "1039 0.9294624 0.07053764\n",
       "1040 0.9439602 0.05603980\n",
       "1041 0.9603350 0.03966503\n",
       "1042 0.9439602 0.05603980\n",
       "1043 0.9494577 0.05054226\n",
       "1044 0.9439602 0.05603980\n",
       "1045 0.9070305 0.09296949\n",
       "1046 0.9356634 0.06433660\n",
       "1047 0.9388459 0.06115408\n",
       "1048 0.9486747 0.05132529\n",
       "1049 0.9502930 0.04970697\n",
       "1050 0.9409499 0.05905005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert output to a form that has 2 columns - probability for 0 and 1\n",
    "gb_df <- data.frame(gb.pred)\n",
    "gb_df$one <- gb_df$gb.pred\n",
    "gb_df$zero <- 1 - gb_df$gb.pred\n",
    "gb_df <- gb_df[-1]\n",
    "gb_df[, '0'] <- gb_df[, 'zero'] \n",
    "gb_df[, '1'] <- gb_df[, 1]\n",
    "gb_df <- gb_df[-1]\n",
    "gb_df <- gb_df[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8013839\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8013839\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nIQBZE0IAsvYfjf6oVRezU78AAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  import ROCR package for ROC curve plotting - AUC is 80.1% without resampling\n",
    "library(ROCR)\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_gb_roc_curve <- gb_df\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(valid_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_gb_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.gb.valid <- performance(pred, measure = \"auc\")\n",
    " print(auc.gb.valid@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.893333333333333"
      ],
      "text/latex": [
       "0.893333333333333"
      ],
      "text/markdown": [
       "0.893333333333333"
      ],
      "text/plain": [
       "[1] 0.8933333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.220338983050847"
      ],
      "text/latex": [
       "0.220338983050847"
      ],
      "text/markdown": [
       "0.220338983050847"
      ],
      "text/plain": [
       "[1] 0.220339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - 89.3% accuracy without resampling\n",
    "gb_acc_valid <- accuracy(valid_processed$subscribe, gb.pred2)\n",
    "gb_acc_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. Gradient Boosting Model -  WITH RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"package 'DMwR' is in use and will not be installed\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2284 1713 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resample the data in the train set using SMOTE - makes the classes more balanced \n",
    "# undersamples majority class (0) and oversamples minority class (1)\n",
    "\n",
    "set.seed(1)\n",
    "train_processed$subscribe <- as.factor(train_processed$subscribe)\n",
    "up_train <- SMOTE(subscribe ~ ., data  = train_processed[, -1])                         \n",
    "table(up_train$subscribe) \n",
    "\n",
    "# need to convert the target variable to character for the model to run without giving en error\n",
    "up_train$subscribe <- as.character(up_train$subscribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gbm(formula = subscribe ~ ., distribution = \"bernoulli\", data = up_train[, \n",
       "    -1], n.trees = 1000, interaction.depth = 4, shrinkage = 0.01)\n",
       "A gradient boosted model with bernoulli loss function.\n",
       "1000 iterations were performed.\n",
       "There were 49 predictors of which 25 had non-zero influence."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train model on training set - same parameters as the last model are used \n",
    "gb.up = gbm(subscribe ~ . , data = up_train[, -1], distribution = \"bernoulli\", n.trees = 1000, shrinkage = 0.01, interaction.depth = 4)\n",
    "gb.up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>var</th><th scope=col>rel.inf</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>euribor3m</th><td>euribor3m                         </td><td>36.452869285                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed</th><td>nr_employed                       </td><td>15.290372449                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_freq_bin_incidence</th><td>nr_employed_freq_bin_incidence    </td><td>11.761027233                      </td></tr>\n",
       "\t<tr><th scope=row>month_binned_nov_aug_jun_jul_may</th><td>month_binned_nov_aug_jun_jul_may  </td><td> 7.523606880                      </td></tr>\n",
       "\t<tr><th scope=row>pdays_999</th><td>pdays_999                         </td><td> 6.490335034                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_binned___Inf_5076_2_</th><td>nr_employed_binned___Inf_5076_2_  </td><td> 4.959156697                      </td></tr>\n",
       "\t<tr><th scope=row>month_incidence</th><td>month_incidence                   </td><td> 3.302986355                      </td></tr>\n",
       "\t<tr><th scope=row>woe_nr_employed_binned</th><td>woe_nr_employed_binned            </td><td> 2.806409601                      </td></tr>\n",
       "\t<tr><th scope=row>woe_cons_conf_idx_binned</th><td>woe_cons_conf_idx_binned          </td><td> 2.577373624                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_freq_bin_incidence</th><td>euribor3m_freq_bin_incidence      </td><td> 1.961869090                      </td></tr>\n",
       "\t<tr><th scope=row>woe_month_binned</th><td>woe_month_binned                  </td><td> 1.744645670                      </td></tr>\n",
       "\t<tr><th scope=row>cons_conf_idx_width_bin_incidence</th><td>cons_conf_idx_width_bin_incidence </td><td> 1.329647316                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_width_bin_incidence</th><td>nr_employed_width_bin_incidence   </td><td> 0.888188150                      </td></tr>\n",
       "\t<tr><th scope=row>woe_cons_price_idx_binned</th><td>woe_cons_price_idx_binned         </td><td> 0.845617967                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate</th><td>emp_var_rate                      </td><td> 0.547807461                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_freq_bin_incidence</th><td>emp_var_rate_freq_bin_incidence   </td><td> 0.493471992                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_width_bin_incidence</th><td>euribor3m_width_bin_incidence     </td><td> 0.448488310                      </td></tr>\n",
       "\t<tr><th scope=row>emp_varrate_positive</th><td>emp_varrate_positive              </td><td> 0.153401864                      </td></tr>\n",
       "\t<tr><th scope=row>woe_emp_var_rate_binned</th><td>woe_emp_var_rate_binned           </td><td> 0.130542124                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_width_bin_incidence</th><td>emp_var_rate_width_bin_incidence  </td><td> 0.075738771                      </td></tr>\n",
       "\t<tr><th scope=row>cons_conf_idx_width_bin_woe</th><td>cons_conf_idx_width_bin_woe       </td><td> 0.071933581                      </td></tr>\n",
       "\t<tr><th scope=row>month_woe</th><td>month_woe                         </td><td> 0.064984722                      </td></tr>\n",
       "\t<tr><th scope=row>woe_euribor3m_binned</th><td>woe_euribor3m_binned              </td><td> 0.048263124                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_width_bin__0_634_1_5162_</th><td>euribor3m_width_bin__0_634_1_5162_</td><td> 0.024002018                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_binned__4_076_Inf_</th><td>euribor3m_binned__4_076_Inf_      </td><td> 0.007260684                      </td></tr>\n",
       "\t<tr><th scope=row>nremply_ge_mean</th><td>nremply_ge_mean                   </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>pdays_ge_mean</th><td>pdays_ge_mean                     </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>emp_varrate_ge_mean</th><td>emp_varrate_ge_mean               </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_binned___0_1_Inf_</th><td>emp_var_rate_binned___0_1_Inf_    </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_binned___Inf_1_262_</th><td>euribor3m_binned___Inf_1_262_     </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_binned__5099_1_Inf_</th><td>nr_employed_binned__5099_1_Inf_   </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>month_binned_incidence</th><td>month_binned_incidence            </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_binned_incidence</th><td>emp_var_rate_binned_incidence     </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>cons_price_idx_binned_incidence</th><td>cons_price_idx_binned_incidence   </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>cons_conf_idx_binned_incidence</th><td>cons_conf_idx_binned_incidence    </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_binned_incidence</th><td>euribor3m_binned_incidence        </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_binned_incidence</th><td>nr_employed_binned_incidence      </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>month_binned_woe</th><td>month_binned_woe                  </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_binned_woe</th><td>emp_var_rate_binned_woe           </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>cons_price_idx_binned_woe</th><td>cons_price_idx_binned_woe         </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>cons_conf_idx_binned_woe</th><td>cons_conf_idx_binned_woe          </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_binned_woe</th><td>euribor3m_binned_woe              </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_binned_woe</th><td>nr_employed_binned_woe            </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_freq_bin_woe</th><td>emp_var_rate_freq_bin_woe         </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_freq_bin_woe</th><td>euribor3m_freq_bin_woe            </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_freq_bin_woe</th><td>nr_employed_freq_bin_woe          </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>emp_var_rate_width_bin_woe</th><td>emp_var_rate_width_bin_woe        </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>euribor3m_width_bin_woe</th><td>euribor3m_width_bin_woe           </td><td> 0.000000000                      </td></tr>\n",
       "\t<tr><th scope=row>nr_employed_width_bin_woe</th><td>nr_employed_width_bin_woe         </td><td> 0.000000000                      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & var & rel.inf\\\\\n",
       "\\hline\n",
       "\teuribor3m & euribor3m                          & 36.452869285                      \\\\\n",
       "\tnr\\_employed & nr\\_employed                        & 15.290372449                        \\\\\n",
       "\tnr\\_employed\\_freq\\_bin\\_incidence & nr\\_employed\\_freq\\_bin\\_incidence     & 11.761027233                              \\\\\n",
       "\tmonth\\_binned\\_nov\\_aug\\_jun\\_jul\\_may & month\\_binned\\_nov\\_aug\\_jun\\_jul\\_may   &  7.523606880                                  \\\\\n",
       "\tpdays\\_999 & pdays\\_999                          &  6.490335034                        \\\\\n",
       "\tnr\\_employed\\_binned\\_\\_\\_Inf\\_5076\\_2\\_ & nr\\_employed\\_binned\\_\\_\\_Inf\\_5076\\_2\\_   &  4.959156697                                      \\\\\n",
       "\tmonth\\_incidence & month\\_incidence                    &  3.302986355                        \\\\\n",
       "\twoe\\_nr\\_employed\\_binned & woe\\_nr\\_employed\\_binned             &  2.806409601                            \\\\\n",
       "\twoe\\_cons\\_conf\\_idx\\_binned & woe\\_cons\\_conf\\_idx\\_binned           &  2.577373624                              \\\\\n",
       "\teuribor3m\\_freq\\_bin\\_incidence & euribor3m\\_freq\\_bin\\_incidence       &  1.961869090                            \\\\\n",
       "\twoe\\_month\\_binned & woe\\_month\\_binned                   &  1.744645670                          \\\\\n",
       "\tcons\\_conf\\_idx\\_width\\_bin\\_incidence & cons\\_conf\\_idx\\_width\\_bin\\_incidence  &  1.329647316                                \\\\\n",
       "\tnr\\_employed\\_width\\_bin\\_incidence & nr\\_employed\\_width\\_bin\\_incidence    &  0.888188150                              \\\\\n",
       "\twoe\\_cons\\_price\\_idx\\_binned & woe\\_cons\\_price\\_idx\\_binned          &  0.845617967                              \\\\\n",
       "\temp\\_var\\_rate & emp\\_var\\_rate                       &  0.547807461                          \\\\\n",
       "\temp\\_var\\_rate\\_freq\\_bin\\_incidence & emp\\_var\\_rate\\_freq\\_bin\\_incidence    &  0.493471992                                \\\\\n",
       "\teuribor3m\\_width\\_bin\\_incidence & euribor3m\\_width\\_bin\\_incidence      &  0.448488310                            \\\\\n",
       "\temp\\_varrate\\_positive & emp\\_varrate\\_positive               &  0.153401864                          \\\\\n",
       "\twoe\\_emp\\_var\\_rate\\_binned & woe\\_emp\\_var\\_rate\\_binned            &  0.130542124                              \\\\\n",
       "\temp\\_var\\_rate\\_width\\_bin\\_incidence & emp\\_var\\_rate\\_width\\_bin\\_incidence   &  0.075738771                                \\\\\n",
       "\tcons\\_conf\\_idx\\_width\\_bin\\_woe & cons\\_conf\\_idx\\_width\\_bin\\_woe        &  0.071933581                                \\\\\n",
       "\tmonth\\_woe & month\\_woe                          &  0.064984722                        \\\\\n",
       "\twoe\\_euribor3m\\_binned & woe\\_euribor3m\\_binned               &  0.048263124                          \\\\\n",
       "\teuribor3m\\_width\\_bin\\_\\_0\\_634\\_1\\_5162\\_ & euribor3m\\_width\\_bin\\_\\_0\\_634\\_1\\_5162\\_ &  0.024002018                                      \\\\\n",
       "\teuribor3m\\_binned\\_\\_4\\_076\\_Inf\\_ & euribor3m\\_binned\\_\\_4\\_076\\_Inf\\_       &  0.007260684                                  \\\\\n",
       "\tnremply\\_ge\\_mean & nremply\\_ge\\_mean                    &  0.000000000                          \\\\\n",
       "\tpdays\\_ge\\_mean & pdays\\_ge\\_mean                      &  0.000000000                          \\\\\n",
       "\temp\\_varrate\\_ge\\_mean & emp\\_varrate\\_ge\\_mean                &  0.000000000                            \\\\\n",
       "\temp\\_var\\_rate\\_binned\\_\\_\\_0\\_1\\_Inf\\_ & emp\\_var\\_rate\\_binned\\_\\_\\_0\\_1\\_Inf\\_     &  0.000000000                                        \\\\\n",
       "\teuribor3m\\_binned\\_\\_\\_Inf\\_1\\_262\\_ & euribor3m\\_binned\\_\\_\\_Inf\\_1\\_262\\_      &  0.000000000                                    \\\\\n",
       "\tnr\\_employed\\_binned\\_\\_5099\\_1\\_Inf\\_ & nr\\_employed\\_binned\\_\\_5099\\_1\\_Inf\\_    &  0.000000000                                    \\\\\n",
       "\tmonth\\_binned\\_incidence & month\\_binned\\_incidence             &  0.000000000                          \\\\\n",
       "\temp\\_var\\_rate\\_binned\\_incidence & emp\\_var\\_rate\\_binned\\_incidence      &  0.000000000                              \\\\\n",
       "\tcons\\_price\\_idx\\_binned\\_incidence & cons\\_price\\_idx\\_binned\\_incidence    &  0.000000000                              \\\\\n",
       "\tcons\\_conf\\_idx\\_binned\\_incidence & cons\\_conf\\_idx\\_binned\\_incidence     &  0.000000000                              \\\\\n",
       "\teuribor3m\\_binned\\_incidence & euribor3m\\_binned\\_incidence         &  0.000000000                          \\\\\n",
       "\tnr\\_employed\\_binned\\_incidence & nr\\_employed\\_binned\\_incidence       &  0.000000000                            \\\\\n",
       "\tmonth\\_binned\\_woe & month\\_binned\\_woe                   &  0.000000000                          \\\\\n",
       "\temp\\_var\\_rate\\_binned\\_woe & emp\\_var\\_rate\\_binned\\_woe            &  0.000000000                              \\\\\n",
       "\tcons\\_price\\_idx\\_binned\\_woe & cons\\_price\\_idx\\_binned\\_woe          &  0.000000000                              \\\\\n",
       "\tcons\\_conf\\_idx\\_binned\\_woe & cons\\_conf\\_idx\\_binned\\_woe           &  0.000000000                              \\\\\n",
       "\teuribor3m\\_binned\\_woe & euribor3m\\_binned\\_woe               &  0.000000000                          \\\\\n",
       "\tnr\\_employed\\_binned\\_woe & nr\\_employed\\_binned\\_woe             &  0.000000000                            \\\\\n",
       "\temp\\_var\\_rate\\_freq\\_bin\\_woe & emp\\_var\\_rate\\_freq\\_bin\\_woe          &  0.000000000                                \\\\\n",
       "\teuribor3m\\_freq\\_bin\\_woe & euribor3m\\_freq\\_bin\\_woe             &  0.000000000                            \\\\\n",
       "\tnr\\_employed\\_freq\\_bin\\_woe & nr\\_employed\\_freq\\_bin\\_woe           &  0.000000000                              \\\\\n",
       "\temp\\_var\\_rate\\_width\\_bin\\_woe & emp\\_var\\_rate\\_width\\_bin\\_woe         &  0.000000000                                \\\\\n",
       "\teuribor3m\\_width\\_bin\\_woe & euribor3m\\_width\\_bin\\_woe            &  0.000000000                            \\\\\n",
       "\tnr\\_employed\\_width\\_bin\\_woe & nr\\_employed\\_width\\_bin\\_woe          &  0.000000000                              \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | var | rel.inf |\n",
       "|---|---|---|\n",
       "| euribor3m | euribor3m                          | 36.452869285                       |\n",
       "| nr_employed | nr_employed                        | 15.290372449                       |\n",
       "| nr_employed_freq_bin_incidence | nr_employed_freq_bin_incidence     | 11.761027233                       |\n",
       "| month_binned_nov_aug_jun_jul_may | month_binned_nov_aug_jun_jul_may   |  7.523606880                       |\n",
       "| pdays_999 | pdays_999                          |  6.490335034                       |\n",
       "| nr_employed_binned___Inf_5076_2_ | nr_employed_binned___Inf_5076_2_   |  4.959156697                       |\n",
       "| month_incidence | month_incidence                    |  3.302986355                       |\n",
       "| woe_nr_employed_binned | woe_nr_employed_binned             |  2.806409601                       |\n",
       "| woe_cons_conf_idx_binned | woe_cons_conf_idx_binned           |  2.577373624                       |\n",
       "| euribor3m_freq_bin_incidence | euribor3m_freq_bin_incidence       |  1.961869090                       |\n",
       "| woe_month_binned | woe_month_binned                   |  1.744645670                       |\n",
       "| cons_conf_idx_width_bin_incidence | cons_conf_idx_width_bin_incidence  |  1.329647316                       |\n",
       "| nr_employed_width_bin_incidence | nr_employed_width_bin_incidence    |  0.888188150                       |\n",
       "| woe_cons_price_idx_binned | woe_cons_price_idx_binned          |  0.845617967                       |\n",
       "| emp_var_rate | emp_var_rate                       |  0.547807461                       |\n",
       "| emp_var_rate_freq_bin_incidence | emp_var_rate_freq_bin_incidence    |  0.493471992                       |\n",
       "| euribor3m_width_bin_incidence | euribor3m_width_bin_incidence      |  0.448488310                       |\n",
       "| emp_varrate_positive | emp_varrate_positive               |  0.153401864                       |\n",
       "| woe_emp_var_rate_binned | woe_emp_var_rate_binned            |  0.130542124                       |\n",
       "| emp_var_rate_width_bin_incidence | emp_var_rate_width_bin_incidence   |  0.075738771                       |\n",
       "| cons_conf_idx_width_bin_woe | cons_conf_idx_width_bin_woe        |  0.071933581                       |\n",
       "| month_woe | month_woe                          |  0.064984722                       |\n",
       "| woe_euribor3m_binned | woe_euribor3m_binned               |  0.048263124                       |\n",
       "| euribor3m_width_bin__0_634_1_5162_ | euribor3m_width_bin__0_634_1_5162_ |  0.024002018                       |\n",
       "| euribor3m_binned__4_076_Inf_ | euribor3m_binned__4_076_Inf_       |  0.007260684                       |\n",
       "| nremply_ge_mean | nremply_ge_mean                    |  0.000000000                       |\n",
       "| pdays_ge_mean | pdays_ge_mean                      |  0.000000000                       |\n",
       "| emp_varrate_ge_mean | emp_varrate_ge_mean                |  0.000000000                       |\n",
       "| emp_var_rate_binned___0_1_Inf_ | emp_var_rate_binned___0_1_Inf_     |  0.000000000                       |\n",
       "| euribor3m_binned___Inf_1_262_ | euribor3m_binned___Inf_1_262_      |  0.000000000                       |\n",
       "| nr_employed_binned__5099_1_Inf_ | nr_employed_binned__5099_1_Inf_    |  0.000000000                       |\n",
       "| month_binned_incidence | month_binned_incidence             |  0.000000000                       |\n",
       "| emp_var_rate_binned_incidence | emp_var_rate_binned_incidence      |  0.000000000                       |\n",
       "| cons_price_idx_binned_incidence | cons_price_idx_binned_incidence    |  0.000000000                       |\n",
       "| cons_conf_idx_binned_incidence | cons_conf_idx_binned_incidence     |  0.000000000                       |\n",
       "| euribor3m_binned_incidence | euribor3m_binned_incidence         |  0.000000000                       |\n",
       "| nr_employed_binned_incidence | nr_employed_binned_incidence       |  0.000000000                       |\n",
       "| month_binned_woe | month_binned_woe                   |  0.000000000                       |\n",
       "| emp_var_rate_binned_woe | emp_var_rate_binned_woe            |  0.000000000                       |\n",
       "| cons_price_idx_binned_woe | cons_price_idx_binned_woe          |  0.000000000                       |\n",
       "| cons_conf_idx_binned_woe | cons_conf_idx_binned_woe           |  0.000000000                       |\n",
       "| euribor3m_binned_woe | euribor3m_binned_woe               |  0.000000000                       |\n",
       "| nr_employed_binned_woe | nr_employed_binned_woe             |  0.000000000                       |\n",
       "| emp_var_rate_freq_bin_woe | emp_var_rate_freq_bin_woe          |  0.000000000                       |\n",
       "| euribor3m_freq_bin_woe | euribor3m_freq_bin_woe             |  0.000000000                       |\n",
       "| nr_employed_freq_bin_woe | nr_employed_freq_bin_woe           |  0.000000000                       |\n",
       "| emp_var_rate_width_bin_woe | emp_var_rate_width_bin_woe         |  0.000000000                       |\n",
       "| euribor3m_width_bin_woe | euribor3m_width_bin_woe            |  0.000000000                       |\n",
       "| nr_employed_width_bin_woe | nr_employed_width_bin_woe          |  0.000000000                       |\n",
       "\n"
      ],
      "text/plain": [
       "                                   var                               \n",
       "euribor3m                          euribor3m                         \n",
       "nr_employed                        nr_employed                       \n",
       "nr_employed_freq_bin_incidence     nr_employed_freq_bin_incidence    \n",
       "month_binned_nov_aug_jun_jul_may   month_binned_nov_aug_jun_jul_may  \n",
       "pdays_999                          pdays_999                         \n",
       "nr_employed_binned___Inf_5076_2_   nr_employed_binned___Inf_5076_2_  \n",
       "month_incidence                    month_incidence                   \n",
       "woe_nr_employed_binned             woe_nr_employed_binned            \n",
       "woe_cons_conf_idx_binned           woe_cons_conf_idx_binned          \n",
       "euribor3m_freq_bin_incidence       euribor3m_freq_bin_incidence      \n",
       "woe_month_binned                   woe_month_binned                  \n",
       "cons_conf_idx_width_bin_incidence  cons_conf_idx_width_bin_incidence \n",
       "nr_employed_width_bin_incidence    nr_employed_width_bin_incidence   \n",
       "woe_cons_price_idx_binned          woe_cons_price_idx_binned         \n",
       "emp_var_rate                       emp_var_rate                      \n",
       "emp_var_rate_freq_bin_incidence    emp_var_rate_freq_bin_incidence   \n",
       "euribor3m_width_bin_incidence      euribor3m_width_bin_incidence     \n",
       "emp_varrate_positive               emp_varrate_positive              \n",
       "woe_emp_var_rate_binned            woe_emp_var_rate_binned           \n",
       "emp_var_rate_width_bin_incidence   emp_var_rate_width_bin_incidence  \n",
       "cons_conf_idx_width_bin_woe        cons_conf_idx_width_bin_woe       \n",
       "month_woe                          month_woe                         \n",
       "woe_euribor3m_binned               woe_euribor3m_binned              \n",
       "euribor3m_width_bin__0_634_1_5162_ euribor3m_width_bin__0_634_1_5162_\n",
       "euribor3m_binned__4_076_Inf_       euribor3m_binned__4_076_Inf_      \n",
       "nremply_ge_mean                    nremply_ge_mean                   \n",
       "pdays_ge_mean                      pdays_ge_mean                     \n",
       "emp_varrate_ge_mean                emp_varrate_ge_mean               \n",
       "emp_var_rate_binned___0_1_Inf_     emp_var_rate_binned___0_1_Inf_    \n",
       "euribor3m_binned___Inf_1_262_      euribor3m_binned___Inf_1_262_     \n",
       "nr_employed_binned__5099_1_Inf_    nr_employed_binned__5099_1_Inf_   \n",
       "month_binned_incidence             month_binned_incidence            \n",
       "emp_var_rate_binned_incidence      emp_var_rate_binned_incidence     \n",
       "cons_price_idx_binned_incidence    cons_price_idx_binned_incidence   \n",
       "cons_conf_idx_binned_incidence     cons_conf_idx_binned_incidence    \n",
       "euribor3m_binned_incidence         euribor3m_binned_incidence        \n",
       "nr_employed_binned_incidence       nr_employed_binned_incidence      \n",
       "month_binned_woe                   month_binned_woe                  \n",
       "emp_var_rate_binned_woe            emp_var_rate_binned_woe           \n",
       "cons_price_idx_binned_woe          cons_price_idx_binned_woe         \n",
       "cons_conf_idx_binned_woe           cons_conf_idx_binned_woe          \n",
       "euribor3m_binned_woe               euribor3m_binned_woe              \n",
       "nr_employed_binned_woe             nr_employed_binned_woe            \n",
       "emp_var_rate_freq_bin_woe          emp_var_rate_freq_bin_woe         \n",
       "euribor3m_freq_bin_woe             euribor3m_freq_bin_woe            \n",
       "nr_employed_freq_bin_woe           nr_employed_freq_bin_woe          \n",
       "emp_var_rate_width_bin_woe         emp_var_rate_width_bin_woe        \n",
       "euribor3m_width_bin_woe            euribor3m_width_bin_woe           \n",
       "nr_employed_width_bin_woe          nr_employed_width_bin_woe         \n",
       "                                   rel.inf     \n",
       "euribor3m                          36.452869285\n",
       "nr_employed                        15.290372449\n",
       "nr_employed_freq_bin_incidence     11.761027233\n",
       "month_binned_nov_aug_jun_jul_may    7.523606880\n",
       "pdays_999                           6.490335034\n",
       "nr_employed_binned___Inf_5076_2_    4.959156697\n",
       "month_incidence                     3.302986355\n",
       "woe_nr_employed_binned              2.806409601\n",
       "woe_cons_conf_idx_binned            2.577373624\n",
       "euribor3m_freq_bin_incidence        1.961869090\n",
       "woe_month_binned                    1.744645670\n",
       "cons_conf_idx_width_bin_incidence   1.329647316\n",
       "nr_employed_width_bin_incidence     0.888188150\n",
       "woe_cons_price_idx_binned           0.845617967\n",
       "emp_var_rate                        0.547807461\n",
       "emp_var_rate_freq_bin_incidence     0.493471992\n",
       "euribor3m_width_bin_incidence       0.448488310\n",
       "emp_varrate_positive                0.153401864\n",
       "woe_emp_var_rate_binned             0.130542124\n",
       "emp_var_rate_width_bin_incidence    0.075738771\n",
       "cons_conf_idx_width_bin_woe         0.071933581\n",
       "month_woe                           0.064984722\n",
       "woe_euribor3m_binned                0.048263124\n",
       "euribor3m_width_bin__0_634_1_5162_  0.024002018\n",
       "euribor3m_binned__4_076_Inf_        0.007260684\n",
       "nremply_ge_mean                     0.000000000\n",
       "pdays_ge_mean                       0.000000000\n",
       "emp_varrate_ge_mean                 0.000000000\n",
       "emp_var_rate_binned___0_1_Inf_      0.000000000\n",
       "euribor3m_binned___Inf_1_262_       0.000000000\n",
       "nr_employed_binned__5099_1_Inf_     0.000000000\n",
       "month_binned_incidence              0.000000000\n",
       "emp_var_rate_binned_incidence       0.000000000\n",
       "cons_price_idx_binned_incidence     0.000000000\n",
       "cons_conf_idx_binned_incidence      0.000000000\n",
       "euribor3m_binned_incidence          0.000000000\n",
       "nr_employed_binned_incidence        0.000000000\n",
       "month_binned_woe                    0.000000000\n",
       "emp_var_rate_binned_woe             0.000000000\n",
       "cons_price_idx_binned_woe           0.000000000\n",
       "cons_conf_idx_binned_woe            0.000000000\n",
       "euribor3m_binned_woe                0.000000000\n",
       "nr_employed_binned_woe              0.000000000\n",
       "emp_var_rate_freq_bin_woe           0.000000000\n",
       "euribor3m_freq_bin_woe              0.000000000\n",
       "nr_employed_freq_bin_woe            0.000000000\n",
       "emp_var_rate_width_bin_woe          0.000000000\n",
       "euribor3m_width_bin_woe             0.000000000\n",
       "nr_employed_width_bin_woe           0.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAAdVBMVEUAAAAAAP8ABf8AC/8A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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary of model\n",
    "summary(gb.up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.629729342407615</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.251401814083053</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.685492872211998</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.413155642355208</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.230015133308653</li>\n",
       "\t<li>0.149311776056979</li>\n",
       "\t<li>0.70256399842942</li>\n",
       "\t<li>0.236841734752239</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.657973547317766</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.412054766860731</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.736493374008182</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.924096300671246</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.675755458948237</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.657973547317766</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.240353293038969</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.203330909258629</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.913290066543919</li>\n",
       "\t<li>0.699592690020604</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.149311776056979</li>\n",
       "\t<li>0.412054766860731</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.811330994456108</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.249773115529272</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.709268592795317</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.779723158594629</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.960498080989255</li>\n",
       "\t<li>0.753246088119491</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.714357073288815</li>\n",
       "\t<li>0.715950193902842</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.715008852754436</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.606557206851563</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.416943484633065</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.845976066260931</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.782569537536321</li>\n",
       "\t<li>0.940853580992516</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.367118554889384</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.814314949879732</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.693267394360043</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.931459957212675</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.704652946865888</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.614110725388833</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.715008852754436</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.149311776056979</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.421238903567062</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.552091073563732</li>\n",
       "\t<li>0.606557206851563</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.202749944924359</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.91683465800382</li>\n",
       "\t<li>0.803025247849141</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.9209234696595</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.412054766860731</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.777602361611969</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.729978659916996</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.606557206851563</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.558525683572257</li>\n",
       "\t<li>0.230015133308653</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.657973547317766</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.712874566525974</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.950252387736305</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.954198481759065</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.657935033196083</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.944689949014361</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.859963950434059</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.664844639939796</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.230015133308653</li>\n",
       "\t<li>0.656077437684926</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.657935033196083</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.147292724551831</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.878869774290919</li>\n",
       "\t<li>0.750339927809653</li>\n",
       "\t<li>0.93105873450367</li>\n",
       "\t<li>0.928802502530711</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.566343625065339</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.251401814083053</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.730182559406963</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.933141738162316</li>\n",
       "\t<li>0.655509694400969</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.240353293038969</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.914773813915076</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.149311776056979</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.790770115018419</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.908177886493446</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.912503833609426</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.70256399842942</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.80381357347248</li>\n",
       "\t<li>0.730038098223732</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.787022343695971</li>\n",
       "\t<li>0.842079187385065</li>\n",
       "\t<li>0.790770115018419</li>\n",
       "\t<li>0.917768905462808</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.650640750276653</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.567542321311521</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.203330909258629</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.725728476276896</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.756028365846785</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.85103456004097</li>\n",
       "\t<li>0.821985454965777</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.656077437684926</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.955801194818472</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.209432144668635</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.938933529976895</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.147292724551831</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.554570583863829</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.655509694400969</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.714357073288815</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.941681878560522</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.928041185179601</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.236841734752239</li>\n",
       "\t<li>0.236841734752239</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.203330909258629</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.709268592795317</li>\n",
       "\t<li>0.558525683572257</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.416943484633065</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.657809502534609</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.202749944924359</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.796818466016312</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.199762298390942</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.957624827436696</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.92407947924288</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.613737509900783</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.209432144668635</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.676706659750958</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.81634072814827</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.703687994899811</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.685492872211998</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.714357073288815</li>\n",
       "\t<li>0.202749944924359</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.852809727024064</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.209432144668635</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.671738774264812</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.939090369148877</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.564131146315923</li>\n",
       "\t<li>0.938347884684307</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.147292724551831</li>\n",
       "\t<li>0.737458296827584</li>\n",
       "\t<li>0.823729245194469</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.724467558892919</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.149311776056979</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.939111714515002</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.606557206851563</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.240353293038969</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.416943484633065</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.359060575243397</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.147292724551831</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.435043056409538</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.251401814083053</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.240353293038969</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.70256399842942</li>\n",
       "\t<li>0.657935033196083</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.656350183438676</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.637515591662838</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.147292724551831</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.939111714515002</li>\n",
       "\t<li>0.10475296761192</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.615727255887486</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.705021816724597</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.637515591662838</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.941271032830213</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.554570583863829</li>\n",
       "\t<li>0.363196653152763</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.758725171773406</li>\n",
       "\t<li>0.924923059740632</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.390400698485063</li>\n",
       "\t<li>0.941681878560522</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.539410720642678</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.664102727371852</li>\n",
       "\t<li>0.209432144668635</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.714357073288815</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.699592690020604</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.538321528331251</li>\n",
       "\t<li>0.709268592795317</li>\n",
       "\t<li>0.779723158594629</li>\n",
       "\t<li>0.147292724551831</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.655509694400969</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.390400698485063</li>\n",
       "\t<li>0.203330909258629</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.721279692169841</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.571548361530728</li>\n",
       "\t<li>0.698854372053202</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.203330909258629</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.363196653152763</li>\n",
       "\t<li>0.85103456004097</li>\n",
       "\t<li>0.926235770365555</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.815129602869136</li>\n",
       "\t<li>0.615727255887486</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.894040947373294</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.363196653152763</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.390400698485063</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.363026896923872</li>\n",
       "\t<li>0.780499613516611</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.199762298390942</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.945681963224875</li>\n",
       "\t<li>0.249773115529272</li>\n",
       "\t<li>0.230015133308653</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.700214753008697</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.714357073288815</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.718074038532234</li>\n",
       "\t<li>0.455081350824798</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.790770115018419</li>\n",
       "\t<li>0.610484581643423</li>\n",
       "\t<li>0.655509694400969</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.950821926150528</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.811330994456108</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.651091072536366</li>\n",
       "\t<li>0.793866095554564</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.240353293038969</li>\n",
       "\t<li>0.606557206851563</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.327854321846187</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.656077437684926</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.249773115529272</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.637515591662838</li>\n",
       "\t<li>0.615727255887486</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.932643821866116</li>\n",
       "\t<li>0.413155642355208</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.79455841375669</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.823448749511182</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.416943484633065</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.209432144668635</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.240353293038969</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.259267708251366</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.236841734752239</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.823729245194469</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.74312346153102</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.777602361611969</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.932643821866116</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.897508681809954</li>\n",
       "\t<li>0.869671792043324</li>\n",
       "\t<li>0.704652946865888</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.186453258970893</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.104254243190589</li>\n",
       "\t<li>0.817727888142566</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "\t<li>0.390400698485063</li>\n",
       "\t<li>0.781177512592929</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.801885365453711</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.76794109004424</li>\n",
       "\t<li>0.192716448089242</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.360429537846714</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.412054766860731</li>\n",
       "\t<li>0.244559378366155</li>\n",
       "\t<li>0.251401814083053</li>\n",
       "\t<li>0.233478129473165</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.280577158017499</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.325031396968285</li>\n",
       "\t<li>0.258083158152784</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.255541759146525</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.195864614975529</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "\t<li>0.404535559299887</li>\n",
       "\t<li>0.777602361611969</li>\n",
       "\t<li>0.263653433600722</li>\n",
       "\t<li>0.443304248792827</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.939090369148877</li>\n",
       "\t<li>0.416943484633065</li>\n",
       "\t<li>0.750339927809653</li>\n",
       "\t<li>0.210817495117819</li>\n",
       "\t<li>0.136505262308892</li>\n",
       "\t<li>0.783277908522697</li>\n",
       "\t<li>0.558525683572257</li>\n",
       "\t<li>0.230015133308653</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.606557206851563</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.184386581346285</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.823448749511182</li>\n",
       "\t<li>0.150920423077129</li>\n",
       "\t<li>0.154579449930328</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.795011033525534</li>\n",
       "\t<li>0.149311776056979</li>\n",
       "\t<li>0.387083142830042</li>\n",
       "\t<li>0.267489102209345</li>\n",
       "\t<li>0.140410700472605</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.236601256400567</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.157269436337511</li>\n",
       "\t<li>0.250390859994071</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.249773115529272</li>\n",
       "\t<li>0.36834944746659</li>\n",
       "\t<li>0.23511511895634</li>\n",
       "\t<li>0.303540168381316</li>\n",
       "\t<li>0.230015133308653</li>\n",
       "\t<li>0.296053680884441</li>\n",
       "\t<li>0.287940398909027</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.287940398909027\n",
       "\\item 0.186453258970893\n",
       "\\item 0.359060575243397\n",
       "\\item 0.140410700472605\n",
       "\\item 0.36834944746659\n",
       "\\item 0.303540168381316\n",
       "\\item 0.629729342407615\n",
       "\\item 0.387083142830042\n",
       "\\item 0.244559378366155\n",
       "\\item 0.325031396968285\n",
       "\\item 0.259267708251366\n",
       "\\item 0.255541759146525\n",
       "\\item 0.192716448089242\n",
       "\\item 0.255541759146525\n",
       "\\item 0.363026896923872\n",
       "\\item 0.255541759146525\n",
       "\\item 0.296053680884441\n",
       "\\item 0.263653433600722\n",
       "\\item 0.443304248792827\n",
       "\\item 0.404535559299887\n",
       "\\item 0.251401814083053\n",
       "\\item 0.263653433600722\n",
       "\\item 0.186453258970893\n",
       "\\item 0.36834944746659\n",
       "\\item 0.685492872211998\n",
       "\\item 0.360429537846714\n",
       "\\item 0.413155642355208\n",
       "\\item 0.267489102209345\n",
       "\\item 0.230015133308653\n",
       "\\item 0.149311776056979\n",
       "\\item 0.70256399842942\n",
       "\\item 0.236841734752239\n",
       "\\item 0.233478129473165\n",
       "\\item 0.657973547317766\n",
       "\\item 0.154579449930328\n",
       "\\item 0.412054766860731\n",
       "\\item 0.23511511895634\n",
       "\\item 0.140410700472605\n",
       "\\item 0.359060575243397\n",
       "\\item 0.303540168381316\n",
       "\\item 0.104254243190589\n",
       "\\item 0.210817495117819\n",
       "\\item 0.212316661412966\n",
       "\\item 0.327854321846187\n",
       "\\item 0.270957006790474\n",
       "\\item 0.186453258970893\n",
       "\\item 0.157269436337511\n",
       "\\item 0.263653433600722\n",
       "\\item 0.104254243190589\n",
       "\\item 0.255541759146525\n",
       "\\item 0.186453258970893\n",
       "\\item 0.236601256400567\n",
       "\\item 0.387083142830042\n",
       "\\item 0.259267708251366\n",
       "\\item 0.150920423077129\n",
       "\\item 0.210817495117819\n",
       "\\item 0.736493374008182\n",
       "\\item 0.327854321846187\n",
       "\\item 0.924096300671246\n",
       "\\item 0.140410700472605\n",
       "\\item 0.157269436337511\n",
       "\\item 0.675755458948237\n",
       "\\item 0.140410700472605\n",
       "\\item 0.186453258970893\n",
       "\\item 0.263653433600722\n",
       "\\item 0.303540168381316\n",
       "\\item 0.303540168381316\n",
       "\\item 0.359060575243397\n",
       "\\item 0.150920423077129\n",
       "\\item 0.327854321846187\n",
       "\\item 0.303540168381316\n",
       "\\item 0.657973547317766\n",
       "\\item 0.325031396968285\n",
       "\\item 0.240353293038969\n",
       "\\item 0.154579449930328\n",
       "\\item 0.140410700472605\n",
       "\\item 0.136505262308892\n",
       "\\item 0.250390859994071\n",
       "\\item 0.140410700472605\n",
       "\\item 0.258083158152784\n",
       "\\item 0.203330909258629\n",
       "\\item 0.303540168381316\n",
       "\\item 0.150920423077129\n",
       "\\item 0.913290066543919\n",
       "\\item 0.699592690020604\n",
       "\\item 0.260149782037432\n",
       "\\item 0.244559378366155\n",
       "\\item 0.303540168381316\n",
       "\\item 0.149311776056979\n",
       "\\item 0.412054766860731\n",
       "\\item 0.184386581346285\n",
       "\\item 0.363026896923872\n",
       "\\item 0.811330994456108\n",
       "\\item 0.296053680884441\n",
       "\\item 0.404535559299887\n",
       "\\item 0.140410700472605\n",
       "\\item 0.249773115529272\n",
       "\\item 0.303540168381316\n",
       "\\item 0.327854321846187\n",
       "\\item 0.259267708251366\n",
       "\\item 0.140410700472605\n",
       "\\item 0.260149782037432\n",
       "\\item 0.287940398909027\n",
       "\\item 0.259267708251366\n",
       "\\item 0.140410700472605\n",
       "\\item 0.303540168381316\n",
       "\\item 0.709268592795317\n",
       "\\item 0.104254243190589\n",
       "\\item 0.443304248792827\n",
       "\\item 0.140410700472605\n",
       "\\item 0.303540168381316\n",
       "\\item 0.363026896923872\n",
       "\\item 0.779723158594629\n",
       "\\item 0.186453258970893\n",
       "\\item 0.186453258970893\n",
       "\\item 0.960498080989255\n",
       "\\item 0.753246088119491\n",
       "\\item 0.250390859994071\n",
       "\\item 0.327854321846187\n",
       "\\item 0.714357073288815\n",
       "\\item 0.715950193902842\n",
       "\\item 0.210817495117819\n",
       "\\item 0.715008852754436\n",
       "\\item 0.36834944746659\n",
       "\\item 0.210817495117819\n",
       "\\item 0.104254243190589\n",
       "\\item 0.136505262308892\n",
       "\\item 0.23511511895634\n",
       "\\item 0.260149782037432\n",
       "\\item 0.606557206851563\n",
       "\\item 0.136505262308892\n",
       "\\item 0.387083142830042\n",
       "\\item 0.250390859994071\n",
       "\\item 0.259267708251366\n",
       "\\item 0.140410700472605\n",
       "\\item 0.140410700472605\n",
       "\\item 0.36834944746659\n",
       "\\item 0.416943484633065\n",
       "\\item 0.303540168381316\n",
       "\\item 0.136505262308892\n",
       "\\item 0.270957006790474\n",
       "\\item 0.360429537846714\n",
       "\\item 0.845976066260931\n",
       "\\item 0.236601256400567\n",
       "\\item 0.212316661412966\n",
       "\\item 0.270957006790474\n",
       "\\item 0.296053680884441\n",
       "\\item 0.259267708251366\n",
       "\\item 0.244559378366155\n",
       "\\item 0.387083142830042\n",
       "\\item 0.136505262308892\n",
       "\\item 0.280577158017499\n",
       "\\item 0.782569537536321\n",
       "\\item 0.940853580992516\n",
       "\\item 0.360429537846714\n",
       "\\item 0.236601256400567\n",
       "\\item 0.244559378366155\n",
       "\\item 0.36834944746659\n",
       "\\item 0.367118554889384\n",
       "\\item 0.303540168381316\n",
       "\\item 0.443304248792827\n",
       "\\item 0.814314949879732\n",
       "\\item 0.36834944746659\n",
       "\\item 0.140410700472605\n",
       "\\item 0.236601256400567\n",
       "\\item 0.303540168381316\n",
       "\\item 0.255541759146525\n",
       "\\item 0.212316661412966\n",
       "\\item 0.260149782037432\n",
       "\\item 0.325031396968285\n",
       "\\item 0.303540168381316\n",
       "\\item 0.154579449930328\n",
       "\\item 0.693267394360043\n",
       "\\item 0.195864614975529\n",
       "\\item 0.258083158152784\n",
       "\\item 0.270957006790474\n",
       "\\item 0.259267708251366\n",
       "\\item 0.179464398041015\n",
       "\\item 0.931459957212675\n",
       "\\item 0.781177512592929\n",
       "\\item 0.184386581346285\n",
       "\\item 0.443304248792827\n",
       "\\item 0.263653433600722\n",
       "\\item 0.363026896923872\n",
       "\\item 0.704652946865888\n",
       "\\item 0.233478129473165\n",
       "\\item 0.280577158017499\n",
       "\\item 0.136505262308892\n",
       "\\item 0.359060575243397\n",
       "\\item 0.325031396968285\n",
       "\\item 0.303540168381316\n",
       "\\item 0.325031396968285\n",
       "\\item 0.184386581346285\n",
       "\\item 0.270957006790474\n",
       "\\item 0.614110725388833\n",
       "\\item 0.192716448089242\n",
       "\\item 0.236601256400567\n",
       "\\item 0.250390859994071\n",
       "\\item 0.443304248792827\n",
       "\\item 0.715008852754436\n",
       "\\item 0.255541759146525\n",
       "\\item 0.325031396968285\n",
       "\\item 0.327854321846187\n",
       "\\item 0.192716448089242\n",
       "\\item 0.270957006790474\n",
       "\\item 0.212316661412966\n",
       "\\item 0.233478129473165\n",
       "\\item 0.140410700472605\n",
       "\\item 0.140410700472605\n",
       "\\item 0.149311776056979\n",
       "\\item 0.267489102209345\n",
       "\\item 0.303540168381316\n",
       "\\item 0.104254243190589\n",
       "\\item 0.233478129473165\n",
       "\\item 0.360429537846714\n",
       "\\item 0.140410700472605\n",
       "\\item 0.244559378366155\n",
       "\\item 0.150920423077129\n",
       "\\item 0.443304248792827\n",
       "\\item 0.303540168381316\n",
       "\\item 0.244559378366155\n",
       "\\item 0.421238903567062\n",
       "\\item 0.270957006790474\n",
       "\\item 0.212316661412966\n",
       "\\item 0.325031396968285\n",
       "\\item 0.36834944746659\n",
       "\\item 0.325031396968285\n",
       "\\item 0.270957006790474\n",
       "\\item 0.154579449930328\n",
       "\\item 0.258083158152784\n",
       "\\item 0.552091073563732\n",
       "\\item 0.606557206851563\n",
       "\\item 0.404535559299887\n",
       "\\item 0.387083142830042\n",
       "\\item 0.202749944924359\n",
       "\\item 0.36834944746659\n",
       "\\item 0.267489102209345\n",
       "\\item 0.91683465800382\n",
       "\\item 0.803025247849141\n",
       "\\item 0.359060575243397\n",
       "\\item 0.184386581346285\n",
       "\\item 0.9209234696595\n",
       "\\item 0.244559378366155\n",
       "\\item 0.210817495117819\n",
       "\\item 0.412054766860731\n",
       "\\item 0.280577158017499\n",
       "\\item 0.777602361611969\n",
       "\\item 0.303540168381316\n",
       "\\item 0.327854321846187\n",
       "\\item 0.212316661412966\n",
       "\\item 0.140410700472605\n",
       "\\item 0.296053680884441\n",
       "\\item 0.23511511895634\n",
       "\\item 0.192716448089242\n",
       "\\item 0.729978659916996\n",
       "\\item 0.404535559299887\n",
       "\\item 0.184386581346285\n",
       "\\item 0.140410700472605\n",
       "\\item 0.360429537846714\n",
       "\\item 0.157269436337511\n",
       "\\item 0.255541759146525\n",
       "\\item 0.259267708251366\n",
       "\\item 0.263653433600722\n",
       "\\item 0.244559378366155\n",
       "\\item 0.606557206851563\n",
       "\\item 0.154579449930328\n",
       "\\item 0.136505262308892\n",
       "\\item 0.255541759146525\n",
       "\\item 0.404535559299887\n",
       "\\item 0.270957006790474\n",
       "\\item 0.136505262308892\n",
       "\\item 0.558525683572257\n",
       "\\item 0.230015133308653\n",
       "\\item 0.287940398909027\n",
       "\\item 0.184386581346285\n",
       "\\item 0.657973547317766\n",
       "\\item 0.258083158152784\n",
       "\\item 0.781177512592929\n",
       "\\item 0.303540168381316\n",
       "\\item 0.712874566525974\n",
       "\\item 0.244559378366155\n",
       "\\item 0.263653433600722\n",
       "\\item 0.950252387736305\n",
       "\\item 0.270957006790474\n",
       "\\item 0.325031396968285\n",
       "\\item 0.140410700472605\n",
       "\\item 0.192716448089242\n",
       "\\item 0.212316661412966\n",
       "\\item 0.954198481759065\n",
       "\\item 0.104254243190589\n",
       "\\item 0.657935033196083\n",
       "\\item 0.270957006790474\n",
       "\\item 0.443304248792827\n",
       "\\item 0.327854321846187\n",
       "\\item 0.944689949014361\n",
       "\\item 0.360429537846714\n",
       "\\item 0.140410700472605\n",
       "\\item 0.360429537846714\n",
       "\\item 0.859963950434059\n",
       "\\item 0.104254243190589\n",
       "\\item 0.664844639939796\n",
       "\\item 0.360429537846714\n",
       "\\item 0.140410700472605\n",
       "\\item 0.230015133308653\n",
       "\\item 0.656077437684926\n",
       "\\item 0.212316661412966\n",
       "\\item 0.657935033196083\n",
       "\\item 0.263653433600722\n",
       "\\item 0.147292724551831\n",
       "\\item 0.325031396968285\n",
       "\\item 0.363026896923872\n",
       "\\item 0.878869774290919\n",
       "\\item 0.750339927809653\n",
       "\\item 0.93105873450367\n",
       "\\item 0.928802502530711\n",
       "\\item 0.259267708251366\n",
       "\\item 0.270957006790474\n",
       "\\item 0.186453258970893\n",
       "\\item 0.280577158017499\n",
       "\\item 0.150920423077129\n",
       "\\item 0.287940398909027\n",
       "\\item 0.287940398909027\n",
       "\\item 0.136505262308892\n",
       "\\item 0.150920423077129\n",
       "\\item 0.154579449930328\n",
       "\\item 0.303540168381316\n",
       "\\item 0.250390859994071\n",
       "\\item 0.36834944746659\n",
       "\\item 0.104254243190589\n",
       "\\item 0.140410700472605\n",
       "\\item 0.566343625065339\n",
       "\\item 0.184386581346285\n",
       "\\item 0.287940398909027\n",
       "\\item 0.267489102209345\n",
       "\\item 0.140410700472605\n",
       "\\item 0.251401814083053\n",
       "\\item 0.195864614975529\n",
       "\\item 0.140410700472605\n",
       "\\item 0.179464398041015\n",
       "\\item 0.10475296761192\n",
       "\\item 0.36834944746659\n",
       "\\item 0.263653433600722\n",
       "\\item 0.387083142830042\n",
       "\\item 0.363026896923872\n",
       "\\item 0.154579449930328\n",
       "\\item 0.730182559406963\n",
       "\\item 0.140410700472605\n",
       "\\item 0.933141738162316\n",
       "\\item 0.655509694400969\n",
       "\\item 0.255541759146525\n",
       "\\item 0.157269436337511\n",
       "\\item 0.360429537846714\n",
       "\\item 0.184386581346285\n",
       "\\item 0.212316661412966\n",
       "\\item 0.186453258970893\n",
       "\\item 0.36834944746659\n",
       "\\item 0.244559378366155\n",
       "\\item 0.240353293038969\n",
       "\\item 0.443304248792827\n",
       "\\item 0.140410700472605\n",
       "\\item 0.360429537846714\n",
       "\\item 0.303540168381316\n",
       "\\item 0.287940398909027\n",
       "\\item 0.140410700472605\n",
       "\\item 0.280577158017499\n",
       "\\item 0.914773813915076\n",
       "\\item 0.327854321846187\n",
       "\\item 0.443304248792827\n",
       "\\item 0.149311776056979\n",
       "\\item 0.212316661412966\n",
       "\\item 0.790770115018419\n",
       "\\item 0.260149782037432\n",
       "\\item 0.212316661412966\n",
       "\\item 0.210817495117819\n",
       "\\item 0.908177886493446\n",
       "\\item 0.781177512592929\n",
       "\\item 0.363026896923872\n",
       "\\item 0.912503833609426\n",
       "\\item 0.255541759146525\n",
       "\\item 0.303540168381316\n",
       "\\item 0.70256399842942\n",
       "\\item 0.404535559299887\n",
       "\\item 0.212316661412966\n",
       "\\item 0.186453258970893\n",
       "\\item 0.186453258970893\n",
       "\\item 0.303540168381316\n",
       "\\item 0.255541759146525\n",
       "\\item 0.10475296761192\n",
       "\\item 0.280577158017499\n",
       "\\item 0.80381357347248\n",
       "\\item 0.730038098223732\n",
       "\\item 0.233478129473165\n",
       "\\item 0.260149782037432\n",
       "\\item 0.787022343695971\n",
       "\\item 0.842079187385065\n",
       "\\item 0.790770115018419\n",
       "\\item 0.917768905462808\n",
       "\\item 0.136505262308892\n",
       "\\item 0.650640750276653\n",
       "\\item 0.255541759146525\n",
       "\\item 0.136505262308892\n",
       "\\item 0.210817495117819\n",
       "\\item 0.157269436337511\n",
       "\\item 0.140410700472605\n",
       "\\item 0.236601256400567\n",
       "\\item 0.287940398909027\n",
       "\\item 0.387083142830042\n",
       "\\item 0.359060575243397\n",
       "\\item 0.260149782037432\n",
       "\\item 0.270957006790474\n",
       "\\item 0.567542321311521\n",
       "\\item 0.210817495117819\n",
       "\\item 0.203330909258629\n",
       "\\item 0.210817495117819\n",
       "\\item 0.327854321846187\n",
       "\\item 0.244559378366155\n",
       "\\item 0.296053680884441\n",
       "\\item 0.287940398909027\n",
       "\\item 0.255541759146525\n",
       "\\item 0.140410700472605\n",
       "\\item 0.404535559299887\n",
       "\\item 0.303540168381316\n",
       "\\item 0.270957006790474\n",
       "\\item 0.250390859994071\n",
       "\\item 0.259267708251366\n",
       "\\item 0.303540168381316\n",
       "\\item 0.387083142830042\n",
       "\\item 0.192716448089242\n",
       "\\item 0.263653433600722\n",
       "\\item 0.280577158017499\n",
       "\\item 0.195864614975529\n",
       "\\item 0.36834944746659\n",
       "\\item 0.260149782037432\n",
       "\\item 0.212316661412966\n",
       "\\item 0.244559378366155\n",
       "\\item 0.212316661412966\n",
       "\\item 0.233478129473165\n",
       "\\item 0.270957006790474\n",
       "\\item 0.303540168381316\n",
       "\\item 0.363026896923872\n",
       "\\item 0.725728476276896\n",
       "\\item 0.192716448089242\n",
       "\\item 0.756028365846785\n",
       "\\item 0.136505262308892\n",
       "\\item 0.212316661412966\n",
       "\\item 0.85103456004097\n",
       "\\item 0.821985454965777\n",
       "\\item 0.236601256400567\n",
       "\\item 0.656077437684926\n",
       "\\item 0.287940398909027\n",
       "\\item 0.955801194818472\n",
       "\\item 0.150920423077129\n",
       "\\item 0.140410700472605\n",
       "\\item 0.23511511895634\n",
       "\\item 0.150920423077129\n",
       "\\item 0.363026896923872\n",
       "\\item 0.140410700472605\n",
       "\\item 0.263653433600722\n",
       "\\item 0.244559378366155\n",
       "\\item 0.259267708251366\n",
       "\\item 0.404535559299887\n",
       "\\item 0.287940398909027\n",
       "\\item 0.209432144668635\n",
       "\\item 0.325031396968285\n",
       "\\item 0.104254243190589\n",
       "\\item 0.255541759146525\n",
       "\\item 0.360429537846714\n",
       "\\item 0.938933529976895\n",
       "\\item 0.303540168381316\n",
       "\\item 0.147292724551831\n",
       "\\item 0.157269436337511\n",
       "\\item 0.263653433600722\n",
       "\\item 0.186453258970893\n",
       "\\item 0.255541759146525\n",
       "\\item 0.184386581346285\n",
       "\\item 0.258083158152784\n",
       "\\item 0.325031396968285\n",
       "\\item 0.287940398909027\n",
       "\\item 0.327854321846187\n",
       "\\item 0.192716448089242\n",
       "\\item 0.140410700472605\n",
       "\\item 0.154579449930328\n",
       "\\item 0.140410700472605\n",
       "\\item 0.136505262308892\n",
       "\\item 0.104254243190589\n",
       "\\item 0.184386581346285\n",
       "\\item 0.157269436337511\n",
       "\\item 0.325031396968285\n",
       "\\item 0.363026896923872\n",
       "\\item 0.303540168381316\n",
       "\\item 0.554570583863829\n",
       "\\item 0.10475296761192\n",
       "\\item 0.157269436337511\n",
       "\\item 0.363026896923872\n",
       "\\item 0.140410700472605\n",
       "\\item 0.263653433600722\n",
       "\\item 0.140410700472605\n",
       "\\item 0.186453258970893\n",
       "\\item 0.244559378366155\n",
       "\\item 0.212316661412966\n",
       "\\item 0.212316661412966\n",
       "\\item 0.270957006790474\n",
       "\\item 0.212316661412966\n",
       "\\item 0.140410700472605\n",
       "\\item 0.263653433600722\n",
       "\\item 0.655509694400969\n",
       "\\item 0.260149782037432\n",
       "\\item 0.236601256400567\n",
       "\\item 0.179464398041015\n",
       "\\item 0.714357073288815\n",
       "\\item 0.10475296761192\n",
       "\\item 0.157269436337511\n",
       "\\item 0.941681878560522\n",
       "\\item 0.327854321846187\n",
       "\\item 0.287940398909027\n",
       "\\item 0.280577158017499\n",
       "\\item 0.287940398909027\n",
       "\\item 0.928041185179601\n",
       "\\item 0.23511511895634\n",
       "\\item 0.236841734752239\n",
       "\\item 0.236841734752239\n",
       "\\item 0.212316661412966\n",
       "\\item 0.359060575243397\n",
       "\\item 0.203330909258629\n",
       "\\item 0.150920423077129\n",
       "\\item 0.212316661412966\n",
       "\\item 0.255541759146525\n",
       "\\item 0.709268592795317\n",
       "\\item 0.558525683572257\n",
       "\\item 0.140410700472605\n",
       "\\item 0.140410700472605\n",
       "\\item 0.287940398909027\n",
       "\\item 0.259267708251366\n",
       "\\item 0.416943484633065\n",
       "\\item 0.210817495117819\n",
       "\\item 0.657809502534609\n",
       "\\item 0.233478129473165\n",
       "\\item 0.36834944746659\n",
       "\\item 0.140410700472605\n",
       "\\item 0.202749944924359\n",
       "\\item 0.327854321846187\n",
       "\\item 0.212316661412966\n",
       "\\item 0.258083158152784\n",
       "\\item 0.140410700472605\n",
       "\\item 0.250390859994071\n",
       "\\item 0.259267708251366\n",
       "\\item 0.796818466016312\n",
       "\\item 0.255541759146525\n",
       "\\item 0.210817495117819\n",
       "\\item 0.199762298390942\n",
       "\\item 0.303540168381316\n",
       "\\item 0.957624827436696\n",
       "\\item 0.263653433600722\n",
       "\\item 0.296053680884441\n",
       "\\item 0.92407947924288\n",
       "\\item 0.303540168381316\n",
       "\\item 0.179464398041015\n",
       "\\item 0.613737509900783\n",
       "\\item 0.404535559299887\n",
       "\\item 0.209432144668635\n",
       "\\item 0.359060575243397\n",
       "\\item 0.255541759146525\n",
       "\\item 0.443304248792827\n",
       "\\item 0.676706659750958\n",
       "\\item 0.260149782037432\n",
       "\\item 0.81634072814827\n",
       "\\item 0.270957006790474\n",
       "\\item 0.303540168381316\n",
       "\\item 0.259267708251366\n",
       "\\item 0.255541759146525\n",
       "\\item 0.703687994899811\n",
       "\\item 0.140410700472605\n",
       "\\item 0.685492872211998\n",
       "\\item 0.150920423077129\n",
       "\\item 0.714357073288815\n",
       "\\item 0.202749944924359\n",
       "\\item 0.36834944746659\n",
       "\\item 0.327854321846187\n",
       "\\item 0.184386581346285\n",
       "\\item 0.255541759146525\n",
       "\\item 0.233478129473165\n",
       "\\item 0.179464398041015\n",
       "\\item 0.10475296761192\n",
       "\\item 0.852809727024064\n",
       "\\item 0.212316661412966\n",
       "\\item 0.36834944746659\n",
       "\\item 0.287940398909027\n",
       "\\item 0.287940398909027\n",
       "\\item 0.10475296761192\n",
       "\\item 0.140410700472605\n",
       "\\item 0.260149782037432\n",
       "\\item 0.303540168381316\n",
       "\\item 0.10475296761192\n",
       "\\item 0.150920423077129\n",
       "\\item 0.363026896923872\n",
       "\\item 0.209432144668635\n",
       "\\item 0.303540168381316\n",
       "\\item 0.258083158152784\n",
       "\\item 0.210817495117819\n",
       "\\item 0.136505262308892\n",
       "\\item 0.325031396968285\n",
       "\\item 0.263653433600722\n",
       "\\item 0.236601256400567\n",
       "\\item 0.671738774264812\n",
       "\\item 0.140410700472605\n",
       "\\item 0.255541759146525\n",
       "\\item 0.154579449930328\n",
       "\\item 0.363026896923872\n",
       "\\item 0.10475296761192\n",
       "\\item 0.939090369148877\n",
       "\\item 0.210817495117819\n",
       "\\item 0.564131146315923\n",
       "\\item 0.938347884684307\n",
       "\\item 0.360429537846714\n",
       "\\item 0.255541759146525\n",
       "\\item 0.147292724551831\n",
       "\\item 0.737458296827584\n",
       "\\item 0.823729245194469\n",
       "\\item 0.140410700472605\n",
       "\\item 0.259267708251366\n",
       "\\item 0.287940398909027\n",
       "\\item 0.140410700472605\n",
       "\\item 0.150920423077129\n",
       "\\item 0.140410700472605\n",
       "\\item 0.154579449930328\n",
       "\\item 0.724467558892919\n",
       "\\item 0.212316661412966\n",
       "\\item 0.359060575243397\n",
       "\\item 0.149311776056979\n",
       "\\item 0.258083158152784\n",
       "\\item 0.259267708251366\n",
       "\\item 0.140410700472605\n",
       "\\item 0.236601256400567\n",
       "\\item 0.280577158017499\n",
       "\\item 0.939111714515002\n",
       "\\item 0.296053680884441\n",
       "\\item 0.136505262308892\n",
       "\\item 0.212316661412966\n",
       "\\item 0.270957006790474\n",
       "\\item 0.606557206851563\n",
       "\\item 0.259267708251366\n",
       "\\item 0.140410700472605\n",
       "\\item 0.210817495117819\n",
       "\\item 0.240353293038969\n",
       "\\item 0.140410700472605\n",
       "\\item 0.303540168381316\n",
       "\\item 0.179464398041015\n",
       "\\item 0.154579449930328\n",
       "\\item 0.363026896923872\n",
       "\\item 0.210817495117819\n",
       "\\item 0.416943484633065\n",
       "\\item 0.184386581346285\n",
       "\\item 0.236601256400567\n",
       "\\item 0.359060575243397\n",
       "\\item 0.140410700472605\n",
       "\\item 0.263653433600722\n",
       "\\item 0.255541759146525\n",
       "\\item 0.140410700472605\n",
       "\\item 0.179464398041015\n",
       "\\item 0.255541759146525\n",
       "\\item 0.236601256400567\n",
       "\\item 0.147292724551831\n",
       "\\item 0.360429537846714\n",
       "\\item 0.303540168381316\n",
       "\\item 0.10475296761192\n",
       "\\item 0.104254243190589\n",
       "\\item 0.186453258970893\n",
       "\\item 0.186453258970893\n",
       "\\item 0.212316661412966\n",
       "\\item 0.435043056409538\n",
       "\\item 0.263653433600722\n",
       "\\item 0.251401814083053\n",
       "\\item 0.280577158017499\n",
       "\\item 0.140410700472605\n",
       "\\item 0.192716448089242\n",
       "\\item 0.233478129473165\n",
       "\\item 0.136505262308892\n",
       "\\item 0.259267708251366\n",
       "\\item 0.150920423077129\n",
       "\\item 0.240353293038969\n",
       "\\item 0.186453258970893\n",
       "\\item 0.303540168381316\n",
       "\\item 0.303540168381316\n",
       "\\item 0.70256399842942\n",
       "\\item 0.657935033196083\n",
       "\\item 0.140410700472605\n",
       "\\item 0.179464398041015\n",
       "\\item 0.656350183438676\n",
       "\\item 0.140410700472605\n",
       "\\item 0.637515591662838\n",
       "\\item 0.186453258970893\n",
       "\\item 0.233478129473165\n",
       "\\item 0.147292724551831\n",
       "\\item 0.287940398909027\n",
       "\\item 0.184386581346285\n",
       "\\item 0.255541759146525\n",
       "\\item 0.303540168381316\n",
       "\\item 0.360429537846714\n",
       "\\item 0.939111714515002\n",
       "\\item 0.10475296761192\n",
       "\\item 0.157269436337511\n",
       "\\item 0.615727255887486\n",
       "\\item 0.263653433600722\n",
       "\\item 0.443304248792827\n",
       "\\item 0.140410700472605\n",
       "\\item 0.179464398041015\n",
       "\\item 0.270957006790474\n",
       "\\item 0.705021816724597\n",
       "\\item 0.104254243190589\n",
       "\\item 0.280577158017499\n",
       "\\item 0.280577158017499\n",
       "\\item 0.250390859994071\n",
       "\\item 0.195864614975529\n",
       "\\item 0.263653433600722\n",
       "\\item 0.303540168381316\n",
       "\\item 0.263653433600722\n",
       "\\item 0.184386581346285\n",
       "\\item 0.404535559299887\n",
       "\\item 0.258083158152784\n",
       "\\item 0.637515591662838\n",
       "\\item 0.255541759146525\n",
       "\\item 0.136505262308892\n",
       "\\item 0.36834944746659\n",
       "\\item 0.186453258970893\n",
       "\\item 0.140410700472605\n",
       "\\item 0.255541759146525\n",
       "\\item 0.941271032830213\n",
       "\\item 0.270957006790474\n",
       "\\item 0.140410700472605\n",
       "\\item 0.554570583863829\n",
       "\\item 0.363196653152763\n",
       "\\item 0.212316661412966\n",
       "\\item 0.387083142830042\n",
       "\\item 0.263653433600722\n",
       "\\item 0.23511511895634\n",
       "\\item 0.287940398909027\n",
       "\\item 0.136505262308892\n",
       "\\item 0.140410700472605\n",
       "\\item 0.244559378366155\n",
       "\\item 0.758725171773406\n",
       "\\item 0.924923059740632\n",
       "\\item 0.270957006790474\n",
       "\\item 0.390400698485063\n",
       "\\item 0.941681878560522\n",
       "\\item 0.136505262308892\n",
       "\\item 0.303540168381316\n",
       "\\item 0.233478129473165\n",
       "\\item 0.539410720642678\n",
       "\\item 0.325031396968285\n",
       "\\item 0.212316661412966\n",
       "\\item 0.664102727371852\n",
       "\\item 0.209432144668635\n",
       "\\item 0.287940398909027\n",
       "\\item 0.267489102209345\n",
       "\\item 0.136505262308892\n",
       "\\item 0.236601256400567\n",
       "\\item 0.154579449930328\n",
       "\\item 0.212316661412966\n",
       "\\item 0.327854321846187\n",
       "\\item 0.714357073288815\n",
       "\\item 0.287940398909027\n",
       "\\item 0.157269436337511\n",
       "\\item 0.195864614975529\n",
       "\\item 0.699592690020604\n",
       "\\item 0.443304248792827\n",
       "\\item 0.538321528331251\n",
       "\\item 0.709268592795317\n",
       "\\item 0.779723158594629\n",
       "\\item 0.147292724551831\n",
       "\\item 0.212316661412966\n",
       "\\item 0.255541759146525\n",
       "\\item 0.655509694400969\n",
       "\\item 0.303540168381316\n",
       "\\item 0.192716448089242\n",
       "\\item 0.195864614975529\n",
       "\\item 0.387083142830042\n",
       "\\item 0.390400698485063\n",
       "\\item 0.203330909258629\n",
       "\\item 0.23511511895634\n",
       "\\item 0.721279692169841\n",
       "\\item 0.263653433600722\n",
       "\\item 0.140410700472605\n",
       "\\item 0.443304248792827\n",
       "\\item 0.267489102209345\n",
       "\\item 0.571548361530728\n",
       "\\item 0.698854372053202\n",
       "\\item 0.263653433600722\n",
       "\\item 0.267489102209345\n",
       "\\item 0.203330909258629\n",
       "\\item 0.267489102209345\n",
       "\\item 0.250390859994071\n",
       "\\item 0.136505262308892\n",
       "\\item 0.250390859994071\n",
       "\\item 0.140410700472605\n",
       "\\item 0.363196653152763\n",
       "\\item 0.85103456004097\n",
       "\\item 0.926235770365555\n",
       "\\item 0.360429537846714\n",
       "\\item 0.270957006790474\n",
       "\\item 0.23511511895634\n",
       "\\item 0.815129602869136\n",
       "\\item 0.615727255887486\n",
       "\\item 0.136505262308892\n",
       "\\item 0.210817495117819\n",
       "\\item 0.894040947373294\n",
       "\\item 0.303540168381316\n",
       "\\item 0.259267708251366\n",
       "\\item 0.212316661412966\n",
       "\\item 0.363196653152763\n",
       "\\item 0.327854321846187\n",
       "\\item 0.179464398041015\n",
       "\\item 0.280577158017499\n",
       "\\item 0.212316661412966\n",
       "\\item 0.260149782037432\n",
       "\\item 0.390400698485063\n",
       "\\item 0.255541759146525\n",
       "\\item 0.179464398041015\n",
       "\\item 0.255541759146525\n",
       "\\item 0.363026896923872\n",
       "\\item 0.780499613516611\n",
       "\\item 0.303540168381316\n",
       "\\item 0.387083142830042\n",
       "\\item 0.195864614975529\n",
       "\\item 0.179464398041015\n",
       "\\item 0.199762298390942\n",
       "\\item 0.36834944746659\n",
       "\\item 0.945681963224875\n",
       "\\item 0.249773115529272\n",
       "\\item 0.230015133308653\n",
       "\\item 0.287940398909027\n",
       "\\item 0.387083142830042\n",
       "\\item 0.233478129473165\n",
       "\\item 0.781177512592929\n",
       "\\item 0.287940398909027\n",
       "\\item 0.700214753008697\n",
       "\\item 0.244559378366155\n",
       "\\item 0.140410700472605\n",
       "\\item 0.104254243190589\n",
       "\\item 0.714357073288815\n",
       "\\item 0.287940398909027\n",
       "\\item 0.325031396968285\n",
       "\\item 0.263653433600722\n",
       "\\item 0.255541759146525\n",
       "\\item 0.327854321846187\n",
       "\\item 0.244559378366155\n",
       "\\item 0.303540168381316\n",
       "\\item 0.718074038532234\n",
       "\\item 0.455081350824798\n",
       "\\item 0.325031396968285\n",
       "\\item 0.184386581346285\n",
       "\\item 0.790770115018419\n",
       "\\item 0.610484581643423\n",
       "\\item 0.655509694400969\n",
       "\\item 0.140410700472605\n",
       "\\item 0.404535559299887\n",
       "\\item 0.327854321846187\n",
       "\\item 0.184386581346285\n",
       "\\item 0.303540168381316\n",
       "\\item 0.950821926150528\n",
       "\\item 0.195864614975529\n",
       "\\item 0.233478129473165\n",
       "\\item 0.263653433600722\n",
       "\\item 0.811330994456108\n",
       "\\item 0.236601256400567\n",
       "\\item 0.140410700472605\n",
       "\\item 0.360429537846714\n",
       "\\item 0.140410700472605\n",
       "\\item 0.651091072536366\n",
       "\\item 0.793866095554564\n",
       "\\item 0.244559378366155\n",
       "\\item 0.404535559299887\n",
       "\\item 0.140410700472605\n",
       "\\item 0.250390859994071\n",
       "\\item 0.212316661412966\n",
       "\\item 0.260149782037432\n",
       "\\item 0.140410700472605\n",
       "\\item 0.210817495117819\n",
       "\\item 0.184386581346285\n",
       "\\item 0.136505262308892\n",
       "\\item 0.240353293038969\n",
       "\\item 0.606557206851563\n",
       "\\item 0.136505262308892\n",
       "\\item 0.287940398909027\n",
       "\\item 0.303540168381316\n",
       "\\item 0.327854321846187\n",
       "\\item 0.136505262308892\n",
       "\\item 0.303540168381316\n",
       "\\item 0.287940398909027\n",
       "\\item 0.443304248792827\n",
       "\\item 0.303540168381316\n",
       "\\item 0.136505262308892\n",
       "\\item 0.443304248792827\n",
       "\\item 0.303540168381316\n",
       "\\item 0.140410700472605\n",
       "\\item 0.184386581346285\n",
       "\\item 0.210817495117819\n",
       "\\item 0.267489102209345\n",
       "\\item 0.260149782037432\n",
       "\\item 0.140410700472605\n",
       "\\item 0.104254243190589\n",
       "\\item 0.236601256400567\n",
       "\\item 0.656077437684926\n",
       "\\item 0.210817495117819\n",
       "\\item 0.249773115529272\n",
       "\\item 0.195864614975529\n",
       "\\item 0.236601256400567\n",
       "\\item 0.637515591662838\n",
       "\\item 0.615727255887486\n",
       "\\item 0.287940398909027\n",
       "\\item 0.932643821866116\n",
       "\\item 0.413155642355208\n",
       "\\item 0.36834944746659\n",
       "\\item 0.192716448089242\n",
       "\\item 0.79455841375669\n",
       "\\item 0.140410700472605\n",
       "\\item 0.255541759146525\n",
       "\\item 0.154579449930328\n",
       "\\item 0.104254243190589\n",
       "\\item 0.823448749511182\n",
       "\\item 0.140410700472605\n",
       "\\item 0.416943484633065\n",
       "\\item 0.781177512592929\n",
       "\\item 0.209432144668635\n",
       "\\item 0.260149782037432\n",
       "\\item 0.387083142830042\n",
       "\\item 0.23511511895634\n",
       "\\item 0.150920423077129\n",
       "\\item 0.287940398909027\n",
       "\\item 0.240353293038969\n",
       "\\item 0.260149782037432\n",
       "\\item 0.259267708251366\n",
       "\\item 0.23511511895634\n",
       "\\item 0.387083142830042\n",
       "\\item 0.23511511895634\n",
       "\\item 0.404535559299887\n",
       "\\item 0.267489102209345\n",
       "\\item 0.360429537846714\n",
       "\\item 0.236841734752239\n",
       "\\item 0.263653433600722\n",
       "\\item 0.104254243190589\n",
       "\\item 0.179464398041015\n",
       "\\item 0.136505262308892\n",
       "\\item 0.823729245194469\n",
       "\\item 0.280577158017499\n",
       "\\item 0.74312346153102\n",
       "\\item 0.104254243190589\n",
       "\\item 0.777602361611969\n",
       "\\item 0.233478129473165\n",
       "\\item 0.287940398909027\n",
       "\\item 0.150920423077129\n",
       "\\item 0.781177512592929\n",
       "\\item 0.360429537846714\n",
       "\\item 0.136505262308892\n",
       "\\item 0.23511511895634\n",
       "\\item 0.303540168381316\n",
       "\\item 0.287940398909027\n",
       "\\item 0.184386581346285\n",
       "\\item 0.443304248792827\n",
       "\\item 0.303540168381316\n",
       "\\item 0.932643821866116\n",
       "\\item 0.186453258970893\n",
       "\\item 0.897508681809954\n",
       "\\item 0.869671792043324\n",
       "\\item 0.704652946865888\n",
       "\\item 0.154579449930328\n",
       "\\item 0.260149782037432\n",
       "\\item 0.179464398041015\n",
       "\\item 0.186453258970893\n",
       "\\item 0.260149782037432\n",
       "\\item 0.104254243190589\n",
       "\\item 0.817727888142566\n",
       "\\item 0.287940398909027\n",
       "\\item 0.390400698485063\n",
       "\\item 0.781177512592929\n",
       "\\item 0.212316661412966\n",
       "\\item 0.244559378366155\n",
       "\\item 0.801885365453711\n",
       "\\item 0.150920423077129\n",
       "\\item 0.76794109004424\n",
       "\\item 0.192716448089242\n",
       "\\item 0.267489102209345\n",
       "\\item 0.360429537846714\n",
       "\\item 0.210817495117819\n",
       "\\item 0.236601256400567\n",
       "\\item 0.263653433600722\n",
       "\\item 0.412054766860731\n",
       "\\item 0.244559378366155\n",
       "\\item 0.251401814083053\n",
       "\\item 0.233478129473165\n",
       "\\item 0.280577158017499\n",
       "\\item 0.255541759146525\n",
       "\\item 0.280577158017499\n",
       "\\item 0.36834944746659\n",
       "\\item 0.325031396968285\n",
       "\\item 0.258083158152784\n",
       "\\item 0.255541759146525\n",
       "\\item 0.140410700472605\n",
       "\\item 0.140410700472605\n",
       "\\item 0.255541759146525\n",
       "\\item 0.263653433600722\n",
       "\\item 0.184386581346285\n",
       "\\item 0.36834944746659\n",
       "\\item 0.195864614975529\n",
       "\\item 0.270957006790474\n",
       "\\item 0.404535559299887\n",
       "\\item 0.777602361611969\n",
       "\\item 0.263653433600722\n",
       "\\item 0.443304248792827\n",
       "\\item 0.36834944746659\n",
       "\\item 0.210817495117819\n",
       "\\item 0.939090369148877\n",
       "\\item 0.416943484633065\n",
       "\\item 0.750339927809653\n",
       "\\item 0.210817495117819\n",
       "\\item 0.136505262308892\n",
       "\\item 0.783277908522697\n",
       "\\item 0.558525683572257\n",
       "\\item 0.230015133308653\n",
       "\\item 0.140410700472605\n",
       "\\item 0.212316661412966\n",
       "\\item 0.212316661412966\n",
       "\\item 0.140410700472605\n",
       "\\item 0.36834944746659\n",
       "\\item 0.606557206851563\n",
       "\\item 0.140410700472605\n",
       "\\item 0.184386581346285\n",
       "\\item 0.260149782037432\n",
       "\\item 0.267489102209345\n",
       "\\item 0.823448749511182\n",
       "\\item 0.150920423077129\n",
       "\\item 0.154579449930328\n",
       "\\item 0.260149782037432\n",
       "\\item 0.795011033525534\n",
       "\\item 0.149311776056979\n",
       "\\item 0.387083142830042\n",
       "\\item 0.267489102209345\n",
       "\\item 0.140410700472605\n",
       "\\item 0.303540168381316\n",
       "\\item 0.236601256400567\n",
       "\\item 0.250390859994071\n",
       "\\item 0.157269436337511\n",
       "\\item 0.250390859994071\n",
       "\\item 0.212316661412966\n",
       "\\item 0.249773115529272\n",
       "\\item 0.36834944746659\n",
       "\\item 0.23511511895634\n",
       "\\item 0.303540168381316\n",
       "\\item 0.230015133308653\n",
       "\\item 0.296053680884441\n",
       "\\item 0.287940398909027\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.287940398909027\n",
       "2. 0.186453258970893\n",
       "3. 0.359060575243397\n",
       "4. 0.140410700472605\n",
       "5. 0.36834944746659\n",
       "6. 0.303540168381316\n",
       "7. 0.629729342407615\n",
       "8. 0.387083142830042\n",
       "9. 0.244559378366155\n",
       "10. 0.325031396968285\n",
       "11. 0.259267708251366\n",
       "12. 0.255541759146525\n",
       "13. 0.192716448089242\n",
       "14. 0.255541759146525\n",
       "15. 0.363026896923872\n",
       "16. 0.255541759146525\n",
       "17. 0.296053680884441\n",
       "18. 0.263653433600722\n",
       "19. 0.443304248792827\n",
       "20. 0.404535559299887\n",
       "21. 0.251401814083053\n",
       "22. 0.263653433600722\n",
       "23. 0.186453258970893\n",
       "24. 0.36834944746659\n",
       "25. 0.685492872211998\n",
       "26. 0.360429537846714\n",
       "27. 0.413155642355208\n",
       "28. 0.267489102209345\n",
       "29. 0.230015133308653\n",
       "30. 0.149311776056979\n",
       "31. 0.70256399842942\n",
       "32. 0.236841734752239\n",
       "33. 0.233478129473165\n",
       "34. 0.657973547317766\n",
       "35. 0.154579449930328\n",
       "36. 0.412054766860731\n",
       "37. 0.23511511895634\n",
       "38. 0.140410700472605\n",
       "39. 0.359060575243397\n",
       "40. 0.303540168381316\n",
       "41. 0.104254243190589\n",
       "42. 0.210817495117819\n",
       "43. 0.212316661412966\n",
       "44. 0.327854321846187\n",
       "45. 0.270957006790474\n",
       "46. 0.186453258970893\n",
       "47. 0.157269436337511\n",
       "48. 0.263653433600722\n",
       "49. 0.104254243190589\n",
       "50. 0.255541759146525\n",
       "51. 0.186453258970893\n",
       "52. 0.236601256400567\n",
       "53. 0.387083142830042\n",
       "54. 0.259267708251366\n",
       "55. 0.150920423077129\n",
       "56. 0.210817495117819\n",
       "57. 0.736493374008182\n",
       "58. 0.327854321846187\n",
       "59. 0.924096300671246\n",
       "60. 0.140410700472605\n",
       "61. 0.157269436337511\n",
       "62. 0.675755458948237\n",
       "63. 0.140410700472605\n",
       "64. 0.186453258970893\n",
       "65. 0.263653433600722\n",
       "66. 0.303540168381316\n",
       "67. 0.303540168381316\n",
       "68. 0.359060575243397\n",
       "69. 0.150920423077129\n",
       "70. 0.327854321846187\n",
       "71. 0.303540168381316\n",
       "72. 0.657973547317766\n",
       "73. 0.325031396968285\n",
       "74. 0.240353293038969\n",
       "75. 0.154579449930328\n",
       "76. 0.140410700472605\n",
       "77. 0.136505262308892\n",
       "78. 0.250390859994071\n",
       "79. 0.140410700472605\n",
       "80. 0.258083158152784\n",
       "81. 0.203330909258629\n",
       "82. 0.303540168381316\n",
       "83. 0.150920423077129\n",
       "84. 0.913290066543919\n",
       "85. 0.699592690020604\n",
       "86. 0.260149782037432\n",
       "87. 0.244559378366155\n",
       "88. 0.303540168381316\n",
       "89. 0.149311776056979\n",
       "90. 0.412054766860731\n",
       "91. 0.184386581346285\n",
       "92. 0.363026896923872\n",
       "93. 0.811330994456108\n",
       "94. 0.296053680884441\n",
       "95. 0.404535559299887\n",
       "96. 0.140410700472605\n",
       "97. 0.249773115529272\n",
       "98. 0.303540168381316\n",
       "99. 0.327854321846187\n",
       "100. 0.259267708251366\n",
       "101. 0.140410700472605\n",
       "102. 0.260149782037432\n",
       "103. 0.287940398909027\n",
       "104. 0.259267708251366\n",
       "105. 0.140410700472605\n",
       "106. 0.303540168381316\n",
       "107. 0.709268592795317\n",
       "108. 0.104254243190589\n",
       "109. 0.443304248792827\n",
       "110. 0.140410700472605\n",
       "111. 0.303540168381316\n",
       "112. 0.363026896923872\n",
       "113. 0.779723158594629\n",
       "114. 0.186453258970893\n",
       "115. 0.186453258970893\n",
       "116. 0.960498080989255\n",
       "117. 0.753246088119491\n",
       "118. 0.250390859994071\n",
       "119. 0.327854321846187\n",
       "120. 0.714357073288815\n",
       "121. 0.715950193902842\n",
       "122. 0.210817495117819\n",
       "123. 0.715008852754436\n",
       "124. 0.36834944746659\n",
       "125. 0.210817495117819\n",
       "126. 0.104254243190589\n",
       "127. 0.136505262308892\n",
       "128. 0.23511511895634\n",
       "129. 0.260149782037432\n",
       "130. 0.606557206851563\n",
       "131. 0.136505262308892\n",
       "132. 0.387083142830042\n",
       "133. 0.250390859994071\n",
       "134. 0.259267708251366\n",
       "135. 0.140410700472605\n",
       "136. 0.140410700472605\n",
       "137. 0.36834944746659\n",
       "138. 0.416943484633065\n",
       "139. 0.303540168381316\n",
       "140. 0.136505262308892\n",
       "141. 0.270957006790474\n",
       "142. 0.360429537846714\n",
       "143. 0.845976066260931\n",
       "144. 0.236601256400567\n",
       "145. 0.212316661412966\n",
       "146. 0.270957006790474\n",
       "147. 0.296053680884441\n",
       "148. 0.259267708251366\n",
       "149. 0.244559378366155\n",
       "150. 0.387083142830042\n",
       "151. 0.136505262308892\n",
       "152. 0.280577158017499\n",
       "153. 0.782569537536321\n",
       "154. 0.940853580992516\n",
       "155. 0.360429537846714\n",
       "156. 0.236601256400567\n",
       "157. 0.244559378366155\n",
       "158. 0.36834944746659\n",
       "159. 0.367118554889384\n",
       "160. 0.303540168381316\n",
       "161. 0.443304248792827\n",
       "162. 0.814314949879732\n",
       "163. 0.36834944746659\n",
       "164. 0.140410700472605\n",
       "165. 0.236601256400567\n",
       "166. 0.303540168381316\n",
       "167. 0.255541759146525\n",
       "168. 0.212316661412966\n",
       "169. 0.260149782037432\n",
       "170. 0.325031396968285\n",
       "171. 0.303540168381316\n",
       "172. 0.154579449930328\n",
       "173. 0.693267394360043\n",
       "174. 0.195864614975529\n",
       "175. 0.258083158152784\n",
       "176. 0.270957006790474\n",
       "177. 0.259267708251366\n",
       "178. 0.179464398041015\n",
       "179. 0.931459957212675\n",
       "180. 0.781177512592929\n",
       "181. 0.184386581346285\n",
       "182. 0.443304248792827\n",
       "183. 0.263653433600722\n",
       "184. 0.363026896923872\n",
       "185. 0.704652946865888\n",
       "186. 0.233478129473165\n",
       "187. 0.280577158017499\n",
       "188. 0.136505262308892\n",
       "189. 0.359060575243397\n",
       "190. 0.325031396968285\n",
       "191. 0.303540168381316\n",
       "192. 0.325031396968285\n",
       "193. 0.184386581346285\n",
       "194. 0.270957006790474\n",
       "195. 0.614110725388833\n",
       "196. 0.192716448089242\n",
       "197. 0.236601256400567\n",
       "198. 0.250390859994071\n",
       "199. 0.443304248792827\n",
       "200. 0.715008852754436\n",
       "201. 0.255541759146525\n",
       "202. 0.325031396968285\n",
       "203. 0.327854321846187\n",
       "204. 0.192716448089242\n",
       "205. 0.270957006790474\n",
       "206. 0.212316661412966\n",
       "207. 0.233478129473165\n",
       "208. 0.140410700472605\n",
       "209. 0.140410700472605\n",
       "210. 0.149311776056979\n",
       "211. 0.267489102209345\n",
       "212. 0.303540168381316\n",
       "213. 0.104254243190589\n",
       "214. 0.233478129473165\n",
       "215. 0.360429537846714\n",
       "216. 0.140410700472605\n",
       "217. 0.244559378366155\n",
       "218. 0.150920423077129\n",
       "219. 0.443304248792827\n",
       "220. 0.303540168381316\n",
       "221. 0.244559378366155\n",
       "222. 0.421238903567062\n",
       "223. 0.270957006790474\n",
       "224. 0.212316661412966\n",
       "225. 0.325031396968285\n",
       "226. 0.36834944746659\n",
       "227. 0.325031396968285\n",
       "228. 0.270957006790474\n",
       "229. 0.154579449930328\n",
       "230. 0.258083158152784\n",
       "231. 0.552091073563732\n",
       "232. 0.606557206851563\n",
       "233. 0.404535559299887\n",
       "234. 0.387083142830042\n",
       "235. 0.202749944924359\n",
       "236. 0.36834944746659\n",
       "237. 0.267489102209345\n",
       "238. 0.91683465800382\n",
       "239. 0.803025247849141\n",
       "240. 0.359060575243397\n",
       "241. 0.184386581346285\n",
       "242. 0.9209234696595\n",
       "243. 0.244559378366155\n",
       "244. 0.210817495117819\n",
       "245. 0.412054766860731\n",
       "246. 0.280577158017499\n",
       "247. 0.777602361611969\n",
       "248. 0.303540168381316\n",
       "249. 0.327854321846187\n",
       "250. 0.212316661412966\n",
       "251. 0.140410700472605\n",
       "252. 0.296053680884441\n",
       "253. 0.23511511895634\n",
       "254. 0.192716448089242\n",
       "255. 0.729978659916996\n",
       "256. 0.404535559299887\n",
       "257. 0.184386581346285\n",
       "258. 0.140410700472605\n",
       "259. 0.360429537846714\n",
       "260. 0.157269436337511\n",
       "261. 0.255541759146525\n",
       "262. 0.259267708251366\n",
       "263. 0.263653433600722\n",
       "264. 0.244559378366155\n",
       "265. 0.606557206851563\n",
       "266. 0.154579449930328\n",
       "267. 0.136505262308892\n",
       "268. 0.255541759146525\n",
       "269. 0.404535559299887\n",
       "270. 0.270957006790474\n",
       "271. 0.136505262308892\n",
       "272. 0.558525683572257\n",
       "273. 0.230015133308653\n",
       "274. 0.287940398909027\n",
       "275. 0.184386581346285\n",
       "276. 0.657973547317766\n",
       "277. 0.258083158152784\n",
       "278. 0.781177512592929\n",
       "279. 0.303540168381316\n",
       "280. 0.712874566525974\n",
       "281. 0.244559378366155\n",
       "282. 0.263653433600722\n",
       "283. 0.950252387736305\n",
       "284. 0.270957006790474\n",
       "285. 0.325031396968285\n",
       "286. 0.140410700472605\n",
       "287. 0.192716448089242\n",
       "288. 0.212316661412966\n",
       "289. 0.954198481759065\n",
       "290. 0.104254243190589\n",
       "291. 0.657935033196083\n",
       "292. 0.270957006790474\n",
       "293. 0.443304248792827\n",
       "294. 0.327854321846187\n",
       "295. 0.944689949014361\n",
       "296. 0.360429537846714\n",
       "297. 0.140410700472605\n",
       "298. 0.360429537846714\n",
       "299. 0.859963950434059\n",
       "300. 0.104254243190589\n",
       "301. 0.664844639939796\n",
       "302. 0.360429537846714\n",
       "303. 0.140410700472605\n",
       "304. 0.230015133308653\n",
       "305. 0.656077437684926\n",
       "306. 0.212316661412966\n",
       "307. 0.657935033196083\n",
       "308. 0.263653433600722\n",
       "309. 0.147292724551831\n",
       "310. 0.325031396968285\n",
       "311. 0.363026896923872\n",
       "312. 0.878869774290919\n",
       "313. 0.750339927809653\n",
       "314. 0.93105873450367\n",
       "315. 0.928802502530711\n",
       "316. 0.259267708251366\n",
       "317. 0.270957006790474\n",
       "318. 0.186453258970893\n",
       "319. 0.280577158017499\n",
       "320. 0.150920423077129\n",
       "321. 0.287940398909027\n",
       "322. 0.287940398909027\n",
       "323. 0.136505262308892\n",
       "324. 0.150920423077129\n",
       "325. 0.154579449930328\n",
       "326. 0.303540168381316\n",
       "327. 0.250390859994071\n",
       "328. 0.36834944746659\n",
       "329. 0.104254243190589\n",
       "330. 0.140410700472605\n",
       "331. 0.566343625065339\n",
       "332. 0.184386581346285\n",
       "333. 0.287940398909027\n",
       "334. 0.267489102209345\n",
       "335. 0.140410700472605\n",
       "336. 0.251401814083053\n",
       "337. 0.195864614975529\n",
       "338. 0.140410700472605\n",
       "339. 0.179464398041015\n",
       "340. 0.10475296761192\n",
       "341. 0.36834944746659\n",
       "342. 0.263653433600722\n",
       "343. 0.387083142830042\n",
       "344. 0.363026896923872\n",
       "345. 0.154579449930328\n",
       "346. 0.730182559406963\n",
       "347. 0.140410700472605\n",
       "348. 0.933141738162316\n",
       "349. 0.655509694400969\n",
       "350. 0.255541759146525\n",
       "351. 0.157269436337511\n",
       "352. 0.360429537846714\n",
       "353. 0.184386581346285\n",
       "354. 0.212316661412966\n",
       "355. 0.186453258970893\n",
       "356. 0.36834944746659\n",
       "357. 0.244559378366155\n",
       "358. 0.240353293038969\n",
       "359. 0.443304248792827\n",
       "360. 0.140410700472605\n",
       "361. 0.360429537846714\n",
       "362. 0.303540168381316\n",
       "363. 0.287940398909027\n",
       "364. 0.140410700472605\n",
       "365. 0.280577158017499\n",
       "366. 0.914773813915076\n",
       "367. 0.327854321846187\n",
       "368. 0.443304248792827\n",
       "369. 0.149311776056979\n",
       "370. 0.212316661412966\n",
       "371. 0.790770115018419\n",
       "372. 0.260149782037432\n",
       "373. 0.212316661412966\n",
       "374. 0.210817495117819\n",
       "375. 0.908177886493446\n",
       "376. 0.781177512592929\n",
       "377. 0.363026896923872\n",
       "378. 0.912503833609426\n",
       "379. 0.255541759146525\n",
       "380. 0.303540168381316\n",
       "381. 0.70256399842942\n",
       "382. 0.404535559299887\n",
       "383. 0.212316661412966\n",
       "384. 0.186453258970893\n",
       "385. 0.186453258970893\n",
       "386. 0.303540168381316\n",
       "387. 0.255541759146525\n",
       "388. 0.10475296761192\n",
       "389. 0.280577158017499\n",
       "390. 0.80381357347248\n",
       "391. 0.730038098223732\n",
       "392. 0.233478129473165\n",
       "393. 0.260149782037432\n",
       "394. 0.787022343695971\n",
       "395. 0.842079187385065\n",
       "396. 0.790770115018419\n",
       "397. 0.917768905462808\n",
       "398. 0.136505262308892\n",
       "399. 0.650640750276653\n",
       "400. 0.255541759146525\n",
       "401. 0.136505262308892\n",
       "402. 0.210817495117819\n",
       "403. 0.157269436337511\n",
       "404. 0.140410700472605\n",
       "405. 0.236601256400567\n",
       "406. 0.287940398909027\n",
       "407. 0.387083142830042\n",
       "408. 0.359060575243397\n",
       "409. 0.260149782037432\n",
       "410. 0.270957006790474\n",
       "411. 0.567542321311521\n",
       "412. 0.210817495117819\n",
       "413. 0.203330909258629\n",
       "414. 0.210817495117819\n",
       "415. 0.327854321846187\n",
       "416. 0.244559378366155\n",
       "417. 0.296053680884441\n",
       "418. 0.287940398909027\n",
       "419. 0.255541759146525\n",
       "420. 0.140410700472605\n",
       "421. 0.404535559299887\n",
       "422. 0.303540168381316\n",
       "423. 0.270957006790474\n",
       "424. 0.250390859994071\n",
       "425. 0.259267708251366\n",
       "426. 0.303540168381316\n",
       "427. 0.387083142830042\n",
       "428. 0.192716448089242\n",
       "429. 0.263653433600722\n",
       "430. 0.280577158017499\n",
       "431. 0.195864614975529\n",
       "432. 0.36834944746659\n",
       "433. 0.260149782037432\n",
       "434. 0.212316661412966\n",
       "435. 0.244559378366155\n",
       "436. 0.212316661412966\n",
       "437. 0.233478129473165\n",
       "438. 0.270957006790474\n",
       "439. 0.303540168381316\n",
       "440. 0.363026896923872\n",
       "441. 0.725728476276896\n",
       "442. 0.192716448089242\n",
       "443. 0.756028365846785\n",
       "444. 0.136505262308892\n",
       "445. 0.212316661412966\n",
       "446. 0.85103456004097\n",
       "447. 0.821985454965777\n",
       "448. 0.236601256400567\n",
       "449. 0.656077437684926\n",
       "450. 0.287940398909027\n",
       "451. 0.955801194818472\n",
       "452. 0.150920423077129\n",
       "453. 0.140410700472605\n",
       "454. 0.23511511895634\n",
       "455. 0.150920423077129\n",
       "456. 0.363026896923872\n",
       "457. 0.140410700472605\n",
       "458. 0.263653433600722\n",
       "459. 0.244559378366155\n",
       "460. 0.259267708251366\n",
       "461. 0.404535559299887\n",
       "462. 0.287940398909027\n",
       "463. 0.209432144668635\n",
       "464. 0.325031396968285\n",
       "465. 0.104254243190589\n",
       "466. 0.255541759146525\n",
       "467. 0.360429537846714\n",
       "468. 0.938933529976895\n",
       "469. 0.303540168381316\n",
       "470. 0.147292724551831\n",
       "471. 0.157269436337511\n",
       "472. 0.263653433600722\n",
       "473. 0.186453258970893\n",
       "474. 0.255541759146525\n",
       "475. 0.184386581346285\n",
       "476. 0.258083158152784\n",
       "477. 0.325031396968285\n",
       "478. 0.287940398909027\n",
       "479. 0.327854321846187\n",
       "480. 0.192716448089242\n",
       "481. 0.140410700472605\n",
       "482. 0.154579449930328\n",
       "483. 0.140410700472605\n",
       "484. 0.136505262308892\n",
       "485. 0.104254243190589\n",
       "486. 0.184386581346285\n",
       "487. 0.157269436337511\n",
       "488. 0.325031396968285\n",
       "489. 0.363026896923872\n",
       "490. 0.303540168381316\n",
       "491. 0.554570583863829\n",
       "492. 0.10475296761192\n",
       "493. 0.157269436337511\n",
       "494. 0.363026896923872\n",
       "495. 0.140410700472605\n",
       "496. 0.263653433600722\n",
       "497. 0.140410700472605\n",
       "498. 0.186453258970893\n",
       "499. 0.244559378366155\n",
       "500. 0.212316661412966\n",
       "501. 0.212316661412966\n",
       "502. 0.270957006790474\n",
       "503. 0.212316661412966\n",
       "504. 0.140410700472605\n",
       "505. 0.263653433600722\n",
       "506. 0.655509694400969\n",
       "507. 0.260149782037432\n",
       "508. 0.236601256400567\n",
       "509. 0.179464398041015\n",
       "510. 0.714357073288815\n",
       "511. 0.10475296761192\n",
       "512. 0.157269436337511\n",
       "513. 0.941681878560522\n",
       "514. 0.327854321846187\n",
       "515. 0.287940398909027\n",
       "516. 0.280577158017499\n",
       "517. 0.287940398909027\n",
       "518. 0.928041185179601\n",
       "519. 0.23511511895634\n",
       "520. 0.236841734752239\n",
       "521. 0.236841734752239\n",
       "522. 0.212316661412966\n",
       "523. 0.359060575243397\n",
       "524. 0.203330909258629\n",
       "525. 0.150920423077129\n",
       "526. 0.212316661412966\n",
       "527. 0.255541759146525\n",
       "528. 0.709268592795317\n",
       "529. 0.558525683572257\n",
       "530. 0.140410700472605\n",
       "531. 0.140410700472605\n",
       "532. 0.287940398909027\n",
       "533. 0.259267708251366\n",
       "534. 0.416943484633065\n",
       "535. 0.210817495117819\n",
       "536. 0.657809502534609\n",
       "537. 0.233478129473165\n",
       "538. 0.36834944746659\n",
       "539. 0.140410700472605\n",
       "540. 0.202749944924359\n",
       "541. 0.327854321846187\n",
       "542. 0.212316661412966\n",
       "543. 0.258083158152784\n",
       "544. 0.140410700472605\n",
       "545. 0.250390859994071\n",
       "546. 0.259267708251366\n",
       "547. 0.796818466016312\n",
       "548. 0.255541759146525\n",
       "549. 0.210817495117819\n",
       "550. 0.199762298390942\n",
       "551. 0.303540168381316\n",
       "552. 0.957624827436696\n",
       "553. 0.263653433600722\n",
       "554. 0.296053680884441\n",
       "555. 0.92407947924288\n",
       "556. 0.303540168381316\n",
       "557. 0.179464398041015\n",
       "558. 0.613737509900783\n",
       "559. 0.404535559299887\n",
       "560. 0.209432144668635\n",
       "561. 0.359060575243397\n",
       "562. 0.255541759146525\n",
       "563. 0.443304248792827\n",
       "564. 0.676706659750958\n",
       "565. 0.260149782037432\n",
       "566. 0.81634072814827\n",
       "567. 0.270957006790474\n",
       "568. 0.303540168381316\n",
       "569. 0.259267708251366\n",
       "570. 0.255541759146525\n",
       "571. 0.703687994899811\n",
       "572. 0.140410700472605\n",
       "573. 0.685492872211998\n",
       "574. 0.150920423077129\n",
       "575. 0.714357073288815\n",
       "576. 0.202749944924359\n",
       "577. 0.36834944746659\n",
       "578. 0.327854321846187\n",
       "579. 0.184386581346285\n",
       "580. 0.255541759146525\n",
       "581. 0.233478129473165\n",
       "582. 0.179464398041015\n",
       "583. 0.10475296761192\n",
       "584. 0.852809727024064\n",
       "585. 0.212316661412966\n",
       "586. 0.36834944746659\n",
       "587. 0.287940398909027\n",
       "588. 0.287940398909027\n",
       "589. 0.10475296761192\n",
       "590. 0.140410700472605\n",
       "591. 0.260149782037432\n",
       "592. 0.303540168381316\n",
       "593. 0.10475296761192\n",
       "594. 0.150920423077129\n",
       "595. 0.363026896923872\n",
       "596. 0.209432144668635\n",
       "597. 0.303540168381316\n",
       "598. 0.258083158152784\n",
       "599. 0.210817495117819\n",
       "600. 0.136505262308892\n",
       "601. 0.325031396968285\n",
       "602. 0.263653433600722\n",
       "603. 0.236601256400567\n",
       "604. 0.671738774264812\n",
       "605. 0.140410700472605\n",
       "606. 0.255541759146525\n",
       "607. 0.154579449930328\n",
       "608. 0.363026896923872\n",
       "609. 0.10475296761192\n",
       "610. 0.939090369148877\n",
       "611. 0.210817495117819\n",
       "612. 0.564131146315923\n",
       "613. 0.938347884684307\n",
       "614. 0.360429537846714\n",
       "615. 0.255541759146525\n",
       "616. 0.147292724551831\n",
       "617. 0.737458296827584\n",
       "618. 0.823729245194469\n",
       "619. 0.140410700472605\n",
       "620. 0.259267708251366\n",
       "621. 0.287940398909027\n",
       "622. 0.140410700472605\n",
       "623. 0.150920423077129\n",
       "624. 0.140410700472605\n",
       "625. 0.154579449930328\n",
       "626. 0.724467558892919\n",
       "627. 0.212316661412966\n",
       "628. 0.359060575243397\n",
       "629. 0.149311776056979\n",
       "630. 0.258083158152784\n",
       "631. 0.259267708251366\n",
       "632. 0.140410700472605\n",
       "633. 0.236601256400567\n",
       "634. 0.280577158017499\n",
       "635. 0.939111714515002\n",
       "636. 0.296053680884441\n",
       "637. 0.136505262308892\n",
       "638. 0.212316661412966\n",
       "639. 0.270957006790474\n",
       "640. 0.606557206851563\n",
       "641. 0.259267708251366\n",
       "642. 0.140410700472605\n",
       "643. 0.210817495117819\n",
       "644. 0.240353293038969\n",
       "645. 0.140410700472605\n",
       "646. 0.303540168381316\n",
       "647. 0.179464398041015\n",
       "648. 0.154579449930328\n",
       "649. 0.363026896923872\n",
       "650. 0.210817495117819\n",
       "651. 0.416943484633065\n",
       "652. 0.184386581346285\n",
       "653. 0.236601256400567\n",
       "654. 0.359060575243397\n",
       "655. 0.140410700472605\n",
       "656. 0.263653433600722\n",
       "657. 0.255541759146525\n",
       "658. 0.140410700472605\n",
       "659. 0.179464398041015\n",
       "660. 0.255541759146525\n",
       "661. 0.236601256400567\n",
       "662. 0.147292724551831\n",
       "663. 0.360429537846714\n",
       "664. 0.303540168381316\n",
       "665. 0.10475296761192\n",
       "666. 0.104254243190589\n",
       "667. 0.186453258970893\n",
       "668. 0.186453258970893\n",
       "669. 0.212316661412966\n",
       "670. 0.435043056409538\n",
       "671. 0.263653433600722\n",
       "672. 0.251401814083053\n",
       "673. 0.280577158017499\n",
       "674. 0.140410700472605\n",
       "675. 0.192716448089242\n",
       "676. 0.233478129473165\n",
       "677. 0.136505262308892\n",
       "678. 0.259267708251366\n",
       "679. 0.150920423077129\n",
       "680. 0.240353293038969\n",
       "681. 0.186453258970893\n",
       "682. 0.303540168381316\n",
       "683. 0.303540168381316\n",
       "684. 0.70256399842942\n",
       "685. 0.657935033196083\n",
       "686. 0.140410700472605\n",
       "687. 0.179464398041015\n",
       "688. 0.656350183438676\n",
       "689. 0.140410700472605\n",
       "690. 0.637515591662838\n",
       "691. 0.186453258970893\n",
       "692. 0.233478129473165\n",
       "693. 0.147292724551831\n",
       "694. 0.287940398909027\n",
       "695. 0.184386581346285\n",
       "696. 0.255541759146525\n",
       "697. 0.303540168381316\n",
       "698. 0.360429537846714\n",
       "699. 0.939111714515002\n",
       "700. 0.10475296761192\n",
       "701. 0.157269436337511\n",
       "702. 0.615727255887486\n",
       "703. 0.263653433600722\n",
       "704. 0.443304248792827\n",
       "705. 0.140410700472605\n",
       "706. 0.179464398041015\n",
       "707. 0.270957006790474\n",
       "708. 0.705021816724597\n",
       "709. 0.104254243190589\n",
       "710. 0.280577158017499\n",
       "711. 0.280577158017499\n",
       "712. 0.250390859994071\n",
       "713. 0.195864614975529\n",
       "714. 0.263653433600722\n",
       "715. 0.303540168381316\n",
       "716. 0.263653433600722\n",
       "717. 0.184386581346285\n",
       "718. 0.404535559299887\n",
       "719. 0.258083158152784\n",
       "720. 0.637515591662838\n",
       "721. 0.255541759146525\n",
       "722. 0.136505262308892\n",
       "723. 0.36834944746659\n",
       "724. 0.186453258970893\n",
       "725. 0.140410700472605\n",
       "726. 0.255541759146525\n",
       "727. 0.941271032830213\n",
       "728. 0.270957006790474\n",
       "729. 0.140410700472605\n",
       "730. 0.554570583863829\n",
       "731. 0.363196653152763\n",
       "732. 0.212316661412966\n",
       "733. 0.387083142830042\n",
       "734. 0.263653433600722\n",
       "735. 0.23511511895634\n",
       "736. 0.287940398909027\n",
       "737. 0.136505262308892\n",
       "738. 0.140410700472605\n",
       "739. 0.244559378366155\n",
       "740. 0.758725171773406\n",
       "741. 0.924923059740632\n",
       "742. 0.270957006790474\n",
       "743. 0.390400698485063\n",
       "744. 0.941681878560522\n",
       "745. 0.136505262308892\n",
       "746. 0.303540168381316\n",
       "747. 0.233478129473165\n",
       "748. 0.539410720642678\n",
       "749. 0.325031396968285\n",
       "750. 0.212316661412966\n",
       "751. 0.664102727371852\n",
       "752. 0.209432144668635\n",
       "753. 0.287940398909027\n",
       "754. 0.267489102209345\n",
       "755. 0.136505262308892\n",
       "756. 0.236601256400567\n",
       "757. 0.154579449930328\n",
       "758. 0.212316661412966\n",
       "759. 0.327854321846187\n",
       "760. 0.714357073288815\n",
       "761. 0.287940398909027\n",
       "762. 0.157269436337511\n",
       "763. 0.195864614975529\n",
       "764. 0.699592690020604\n",
       "765. 0.443304248792827\n",
       "766. 0.538321528331251\n",
       "767. 0.709268592795317\n",
       "768. 0.779723158594629\n",
       "769. 0.147292724551831\n",
       "770. 0.212316661412966\n",
       "771. 0.255541759146525\n",
       "772. 0.655509694400969\n",
       "773. 0.303540168381316\n",
       "774. 0.192716448089242\n",
       "775. 0.195864614975529\n",
       "776. 0.387083142830042\n",
       "777. 0.390400698485063\n",
       "778. 0.203330909258629\n",
       "779. 0.23511511895634\n",
       "780. 0.721279692169841\n",
       "781. 0.263653433600722\n",
       "782. 0.140410700472605\n",
       "783. 0.443304248792827\n",
       "784. 0.267489102209345\n",
       "785. 0.571548361530728\n",
       "786. 0.698854372053202\n",
       "787. 0.263653433600722\n",
       "788. 0.267489102209345\n",
       "789. 0.203330909258629\n",
       "790. 0.267489102209345\n",
       "791. 0.250390859994071\n",
       "792. 0.136505262308892\n",
       "793. 0.250390859994071\n",
       "794. 0.140410700472605\n",
       "795. 0.363196653152763\n",
       "796. 0.85103456004097\n",
       "797. 0.926235770365555\n",
       "798. 0.360429537846714\n",
       "799. 0.270957006790474\n",
       "800. 0.23511511895634\n",
       "801. 0.815129602869136\n",
       "802. 0.615727255887486\n",
       "803. 0.136505262308892\n",
       "804. 0.210817495117819\n",
       "805. 0.894040947373294\n",
       "806. 0.303540168381316\n",
       "807. 0.259267708251366\n",
       "808. 0.212316661412966\n",
       "809. 0.363196653152763\n",
       "810. 0.327854321846187\n",
       "811. 0.179464398041015\n",
       "812. 0.280577158017499\n",
       "813. 0.212316661412966\n",
       "814. 0.260149782037432\n",
       "815. 0.390400698485063\n",
       "816. 0.255541759146525\n",
       "817. 0.179464398041015\n",
       "818. 0.255541759146525\n",
       "819. 0.363026896923872\n",
       "820. 0.780499613516611\n",
       "821. 0.303540168381316\n",
       "822. 0.387083142830042\n",
       "823. 0.195864614975529\n",
       "824. 0.179464398041015\n",
       "825. 0.199762298390942\n",
       "826. 0.36834944746659\n",
       "827. 0.945681963224875\n",
       "828. 0.249773115529272\n",
       "829. 0.230015133308653\n",
       "830. 0.287940398909027\n",
       "831. 0.387083142830042\n",
       "832. 0.233478129473165\n",
       "833. 0.781177512592929\n",
       "834. 0.287940398909027\n",
       "835. 0.700214753008697\n",
       "836. 0.244559378366155\n",
       "837. 0.140410700472605\n",
       "838. 0.104254243190589\n",
       "839. 0.714357073288815\n",
       "840. 0.287940398909027\n",
       "841. 0.325031396968285\n",
       "842. 0.263653433600722\n",
       "843. 0.255541759146525\n",
       "844. 0.327854321846187\n",
       "845. 0.244559378366155\n",
       "846. 0.303540168381316\n",
       "847. 0.718074038532234\n",
       "848. 0.455081350824798\n",
       "849. 0.325031396968285\n",
       "850. 0.184386581346285\n",
       "851. 0.790770115018419\n",
       "852. 0.610484581643423\n",
       "853. 0.655509694400969\n",
       "854. 0.140410700472605\n",
       "855. 0.404535559299887\n",
       "856. 0.327854321846187\n",
       "857. 0.184386581346285\n",
       "858. 0.303540168381316\n",
       "859. 0.950821926150528\n",
       "860. 0.195864614975529\n",
       "861. 0.233478129473165\n",
       "862. 0.263653433600722\n",
       "863. 0.811330994456108\n",
       "864. 0.236601256400567\n",
       "865. 0.140410700472605\n",
       "866. 0.360429537846714\n",
       "867. 0.140410700472605\n",
       "868. 0.651091072536366\n",
       "869. 0.793866095554564\n",
       "870. 0.244559378366155\n",
       "871. 0.404535559299887\n",
       "872. 0.140410700472605\n",
       "873. 0.250390859994071\n",
       "874. 0.212316661412966\n",
       "875. 0.260149782037432\n",
       "876. 0.140410700472605\n",
       "877. 0.210817495117819\n",
       "878. 0.184386581346285\n",
       "879. 0.136505262308892\n",
       "880. 0.240353293038969\n",
       "881. 0.606557206851563\n",
       "882. 0.136505262308892\n",
       "883. 0.287940398909027\n",
       "884. 0.303540168381316\n",
       "885. 0.327854321846187\n",
       "886. 0.136505262308892\n",
       "887. 0.303540168381316\n",
       "888. 0.287940398909027\n",
       "889. 0.443304248792827\n",
       "890. 0.303540168381316\n",
       "891. 0.136505262308892\n",
       "892. 0.443304248792827\n",
       "893. 0.303540168381316\n",
       "894. 0.140410700472605\n",
       "895. 0.184386581346285\n",
       "896. 0.210817495117819\n",
       "897. 0.267489102209345\n",
       "898. 0.260149782037432\n",
       "899. 0.140410700472605\n",
       "900. 0.104254243190589\n",
       "901. 0.236601256400567\n",
       "902. 0.656077437684926\n",
       "903. 0.210817495117819\n",
       "904. 0.249773115529272\n",
       "905. 0.195864614975529\n",
       "906. 0.236601256400567\n",
       "907. 0.637515591662838\n",
       "908. 0.615727255887486\n",
       "909. 0.287940398909027\n",
       "910. 0.932643821866116\n",
       "911. 0.413155642355208\n",
       "912. 0.36834944746659\n",
       "913. 0.192716448089242\n",
       "914. 0.79455841375669\n",
       "915. 0.140410700472605\n",
       "916. 0.255541759146525\n",
       "917. 0.154579449930328\n",
       "918. 0.104254243190589\n",
       "919. 0.823448749511182\n",
       "920. 0.140410700472605\n",
       "921. 0.416943484633065\n",
       "922. 0.781177512592929\n",
       "923. 0.209432144668635\n",
       "924. 0.260149782037432\n",
       "925. 0.387083142830042\n",
       "926. 0.23511511895634\n",
       "927. 0.150920423077129\n",
       "928. 0.287940398909027\n",
       "929. 0.240353293038969\n",
       "930. 0.260149782037432\n",
       "931. 0.259267708251366\n",
       "932. 0.23511511895634\n",
       "933. 0.387083142830042\n",
       "934. 0.23511511895634\n",
       "935. 0.404535559299887\n",
       "936. 0.267489102209345\n",
       "937. 0.360429537846714\n",
       "938. 0.236841734752239\n",
       "939. 0.263653433600722\n",
       "940. 0.104254243190589\n",
       "941. 0.179464398041015\n",
       "942. 0.136505262308892\n",
       "943. 0.823729245194469\n",
       "944. 0.280577158017499\n",
       "945. 0.74312346153102\n",
       "946. 0.104254243190589\n",
       "947. 0.777602361611969\n",
       "948. 0.233478129473165\n",
       "949. 0.287940398909027\n",
       "950. 0.150920423077129\n",
       "951. 0.781177512592929\n",
       "952. 0.360429537846714\n",
       "953. 0.136505262308892\n",
       "954. 0.23511511895634\n",
       "955. 0.303540168381316\n",
       "956. 0.287940398909027\n",
       "957. 0.184386581346285\n",
       "958. 0.443304248792827\n",
       "959. 0.303540168381316\n",
       "960. 0.932643821866116\n",
       "961. 0.186453258970893\n",
       "962. 0.897508681809954\n",
       "963. 0.869671792043324\n",
       "964. 0.704652946865888\n",
       "965. 0.154579449930328\n",
       "966. 0.260149782037432\n",
       "967. 0.179464398041015\n",
       "968. 0.186453258970893\n",
       "969. 0.260149782037432\n",
       "970. 0.104254243190589\n",
       "971. 0.817727888142566\n",
       "972. 0.287940398909027\n",
       "973. 0.390400698485063\n",
       "974. 0.781177512592929\n",
       "975. 0.212316661412966\n",
       "976. 0.244559378366155\n",
       "977. 0.801885365453711\n",
       "978. 0.150920423077129\n",
       "979. 0.76794109004424\n",
       "980. 0.192716448089242\n",
       "981. 0.267489102209345\n",
       "982. 0.360429537846714\n",
       "983. 0.210817495117819\n",
       "984. 0.236601256400567\n",
       "985. 0.263653433600722\n",
       "986. 0.412054766860731\n",
       "987. 0.244559378366155\n",
       "988. 0.251401814083053\n",
       "989. 0.233478129473165\n",
       "990. 0.280577158017499\n",
       "991. 0.255541759146525\n",
       "992. 0.280577158017499\n",
       "993. 0.36834944746659\n",
       "994. 0.325031396968285\n",
       "995. 0.258083158152784\n",
       "996. 0.255541759146525\n",
       "997. 0.140410700472605\n",
       "998. 0.140410700472605\n",
       "999. 0.255541759146525\n",
       "1000. 0.263653433600722\n",
       "1001. 0.184386581346285\n",
       "1002. 0.36834944746659\n",
       "1003. 0.195864614975529\n",
       "1004. 0.270957006790474\n",
       "1005. 0.404535559299887\n",
       "1006. 0.777602361611969\n",
       "1007. 0.263653433600722\n",
       "1008. 0.443304248792827\n",
       "1009. 0.36834944746659\n",
       "1010. 0.210817495117819\n",
       "1011. 0.939090369148877\n",
       "1012. 0.416943484633065\n",
       "1013. 0.750339927809653\n",
       "1014. 0.210817495117819\n",
       "1015. 0.136505262308892\n",
       "1016. 0.783277908522697\n",
       "1017. 0.558525683572257\n",
       "1018. 0.230015133308653\n",
       "1019. 0.140410700472605\n",
       "1020. 0.212316661412966\n",
       "1021. 0.212316661412966\n",
       "1022. 0.140410700472605\n",
       "1023. 0.36834944746659\n",
       "1024. 0.606557206851563\n",
       "1025. 0.140410700472605\n",
       "1026. 0.184386581346285\n",
       "1027. 0.260149782037432\n",
       "1028. 0.267489102209345\n",
       "1029. 0.823448749511182\n",
       "1030. 0.150920423077129\n",
       "1031. 0.154579449930328\n",
       "1032. 0.260149782037432\n",
       "1033. 0.795011033525534\n",
       "1034. 0.149311776056979\n",
       "1035. 0.387083142830042\n",
       "1036. 0.267489102209345\n",
       "1037. 0.140410700472605\n",
       "1038. 0.303540168381316\n",
       "1039. 0.236601256400567\n",
       "1040. 0.250390859994071\n",
       "1041. 0.157269436337511\n",
       "1042. 0.250390859994071\n",
       "1043. 0.212316661412966\n",
       "1044. 0.249773115529272\n",
       "1045. 0.36834944746659\n",
       "1046. 0.23511511895634\n",
       "1047. 0.303540168381316\n",
       "1048. 0.230015133308653\n",
       "1049. 0.296053680884441\n",
       "1050. 0.287940398909027\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   [1] 0.2879404 0.1864533 0.3590606 0.1404107 0.3683494 0.3035402 0.6297293\n",
       "   [8] 0.3870831 0.2445594 0.3250314 0.2592677 0.2555418 0.1927164 0.2555418\n",
       "  [15] 0.3630269 0.2555418 0.2960537 0.2636534 0.4433042 0.4045356 0.2514018\n",
       "  [22] 0.2636534 0.1864533 0.3683494 0.6854929 0.3604295 0.4131556 0.2674891\n",
       "  [29] 0.2300151 0.1493118 0.7025640 0.2368417 0.2334781 0.6579735 0.1545794\n",
       "  [36] 0.4120548 0.2351151 0.1404107 0.3590606 0.3035402 0.1042542 0.2108175\n",
       "  [43] 0.2123167 0.3278543 0.2709570 0.1864533 0.1572694 0.2636534 0.1042542\n",
       "  [50] 0.2555418 0.1864533 0.2366013 0.3870831 0.2592677 0.1509204 0.2108175\n",
       "  [57] 0.7364934 0.3278543 0.9240963 0.1404107 0.1572694 0.6757555 0.1404107\n",
       "  [64] 0.1864533 0.2636534 0.3035402 0.3035402 0.3590606 0.1509204 0.3278543\n",
       "  [71] 0.3035402 0.6579735 0.3250314 0.2403533 0.1545794 0.1404107 0.1365053\n",
       "  [78] 0.2503909 0.1404107 0.2580832 0.2033309 0.3035402 0.1509204 0.9132901\n",
       "  [85] 0.6995927 0.2601498 0.2445594 0.3035402 0.1493118 0.4120548 0.1843866\n",
       "  [92] 0.3630269 0.8113310 0.2960537 0.4045356 0.1404107 0.2497731 0.3035402\n",
       "  [99] 0.3278543 0.2592677 0.1404107 0.2601498 0.2879404 0.2592677 0.1404107\n",
       " [106] 0.3035402 0.7092686 0.1042542 0.4433042 0.1404107 0.3035402 0.3630269\n",
       " [113] 0.7797232 0.1864533 0.1864533 0.9604981 0.7532461 0.2503909 0.3278543\n",
       " [120] 0.7143571 0.7159502 0.2108175 0.7150089 0.3683494 0.2108175 0.1042542\n",
       " [127] 0.1365053 0.2351151 0.2601498 0.6065572 0.1365053 0.3870831 0.2503909\n",
       " [134] 0.2592677 0.1404107 0.1404107 0.3683494 0.4169435 0.3035402 0.1365053\n",
       " [141] 0.2709570 0.3604295 0.8459761 0.2366013 0.2123167 0.2709570 0.2960537\n",
       " [148] 0.2592677 0.2445594 0.3870831 0.1365053 0.2805772 0.7825695 0.9408536\n",
       " [155] 0.3604295 0.2366013 0.2445594 0.3683494 0.3671186 0.3035402 0.4433042\n",
       " [162] 0.8143149 0.3683494 0.1404107 0.2366013 0.3035402 0.2555418 0.2123167\n",
       " [169] 0.2601498 0.3250314 0.3035402 0.1545794 0.6932674 0.1958646 0.2580832\n",
       " [176] 0.2709570 0.2592677 0.1794644 0.9314600 0.7811775 0.1843866 0.4433042\n",
       " [183] 0.2636534 0.3630269 0.7046529 0.2334781 0.2805772 0.1365053 0.3590606\n",
       " [190] 0.3250314 0.3035402 0.3250314 0.1843866 0.2709570 0.6141107 0.1927164\n",
       " [197] 0.2366013 0.2503909 0.4433042 0.7150089 0.2555418 0.3250314 0.3278543\n",
       " [204] 0.1927164 0.2709570 0.2123167 0.2334781 0.1404107 0.1404107 0.1493118\n",
       " [211] 0.2674891 0.3035402 0.1042542 0.2334781 0.3604295 0.1404107 0.2445594\n",
       " [218] 0.1509204 0.4433042 0.3035402 0.2445594 0.4212389 0.2709570 0.2123167\n",
       " [225] 0.3250314 0.3683494 0.3250314 0.2709570 0.1545794 0.2580832 0.5520911\n",
       " [232] 0.6065572 0.4045356 0.3870831 0.2027499 0.3683494 0.2674891 0.9168347\n",
       " [239] 0.8030252 0.3590606 0.1843866 0.9209235 0.2445594 0.2108175 0.4120548\n",
       " [246] 0.2805772 0.7776024 0.3035402 0.3278543 0.2123167 0.1404107 0.2960537\n",
       " [253] 0.2351151 0.1927164 0.7299787 0.4045356 0.1843866 0.1404107 0.3604295\n",
       " [260] 0.1572694 0.2555418 0.2592677 0.2636534 0.2445594 0.6065572 0.1545794\n",
       " [267] 0.1365053 0.2555418 0.4045356 0.2709570 0.1365053 0.5585257 0.2300151\n",
       " [274] 0.2879404 0.1843866 0.6579735 0.2580832 0.7811775 0.3035402 0.7128746\n",
       " [281] 0.2445594 0.2636534 0.9502524 0.2709570 0.3250314 0.1404107 0.1927164\n",
       " [288] 0.2123167 0.9541985 0.1042542 0.6579350 0.2709570 0.4433042 0.3278543\n",
       " [295] 0.9446899 0.3604295 0.1404107 0.3604295 0.8599640 0.1042542 0.6648446\n",
       " [302] 0.3604295 0.1404107 0.2300151 0.6560774 0.2123167 0.6579350 0.2636534\n",
       " [309] 0.1472927 0.3250314 0.3630269 0.8788698 0.7503399 0.9310587 0.9288025\n",
       " [316] 0.2592677 0.2709570 0.1864533 0.2805772 0.1509204 0.2879404 0.2879404\n",
       " [323] 0.1365053 0.1509204 0.1545794 0.3035402 0.2503909 0.3683494 0.1042542\n",
       " [330] 0.1404107 0.5663436 0.1843866 0.2879404 0.2674891 0.1404107 0.2514018\n",
       " [337] 0.1958646 0.1404107 0.1794644 0.1047530 0.3683494 0.2636534 0.3870831\n",
       " [344] 0.3630269 0.1545794 0.7301826 0.1404107 0.9331417 0.6555097 0.2555418\n",
       " [351] 0.1572694 0.3604295 0.1843866 0.2123167 0.1864533 0.3683494 0.2445594\n",
       " [358] 0.2403533 0.4433042 0.1404107 0.3604295 0.3035402 0.2879404 0.1404107\n",
       " [365] 0.2805772 0.9147738 0.3278543 0.4433042 0.1493118 0.2123167 0.7907701\n",
       " [372] 0.2601498 0.2123167 0.2108175 0.9081779 0.7811775 0.3630269 0.9125038\n",
       " [379] 0.2555418 0.3035402 0.7025640 0.4045356 0.2123167 0.1864533 0.1864533\n",
       " [386] 0.3035402 0.2555418 0.1047530 0.2805772 0.8038136 0.7300381 0.2334781\n",
       " [393] 0.2601498 0.7870223 0.8420792 0.7907701 0.9177689 0.1365053 0.6506408\n",
       " [400] 0.2555418 0.1365053 0.2108175 0.1572694 0.1404107 0.2366013 0.2879404\n",
       " [407] 0.3870831 0.3590606 0.2601498 0.2709570 0.5675423 0.2108175 0.2033309\n",
       " [414] 0.2108175 0.3278543 0.2445594 0.2960537 0.2879404 0.2555418 0.1404107\n",
       " [421] 0.4045356 0.3035402 0.2709570 0.2503909 0.2592677 0.3035402 0.3870831\n",
       " [428] 0.1927164 0.2636534 0.2805772 0.1958646 0.3683494 0.2601498 0.2123167\n",
       " [435] 0.2445594 0.2123167 0.2334781 0.2709570 0.3035402 0.3630269 0.7257285\n",
       " [442] 0.1927164 0.7560284 0.1365053 0.2123167 0.8510346 0.8219855 0.2366013\n",
       " [449] 0.6560774 0.2879404 0.9558012 0.1509204 0.1404107 0.2351151 0.1509204\n",
       " [456] 0.3630269 0.1404107 0.2636534 0.2445594 0.2592677 0.4045356 0.2879404\n",
       " [463] 0.2094321 0.3250314 0.1042542 0.2555418 0.3604295 0.9389335 0.3035402\n",
       " [470] 0.1472927 0.1572694 0.2636534 0.1864533 0.2555418 0.1843866 0.2580832\n",
       " [477] 0.3250314 0.2879404 0.3278543 0.1927164 0.1404107 0.1545794 0.1404107\n",
       " [484] 0.1365053 0.1042542 0.1843866 0.1572694 0.3250314 0.3630269 0.3035402\n",
       " [491] 0.5545706 0.1047530 0.1572694 0.3630269 0.1404107 0.2636534 0.1404107\n",
       " [498] 0.1864533 0.2445594 0.2123167 0.2123167 0.2709570 0.2123167 0.1404107\n",
       " [505] 0.2636534 0.6555097 0.2601498 0.2366013 0.1794644 0.7143571 0.1047530\n",
       " [512] 0.1572694 0.9416819 0.3278543 0.2879404 0.2805772 0.2879404 0.9280412\n",
       " [519] 0.2351151 0.2368417 0.2368417 0.2123167 0.3590606 0.2033309 0.1509204\n",
       " [526] 0.2123167 0.2555418 0.7092686 0.5585257 0.1404107 0.1404107 0.2879404\n",
       " [533] 0.2592677 0.4169435 0.2108175 0.6578095 0.2334781 0.3683494 0.1404107\n",
       " [540] 0.2027499 0.3278543 0.2123167 0.2580832 0.1404107 0.2503909 0.2592677\n",
       " [547] 0.7968185 0.2555418 0.2108175 0.1997623 0.3035402 0.9576248 0.2636534\n",
       " [554] 0.2960537 0.9240795 0.3035402 0.1794644 0.6137375 0.4045356 0.2094321\n",
       " [561] 0.3590606 0.2555418 0.4433042 0.6767067 0.2601498 0.8163407 0.2709570\n",
       " [568] 0.3035402 0.2592677 0.2555418 0.7036880 0.1404107 0.6854929 0.1509204\n",
       " [575] 0.7143571 0.2027499 0.3683494 0.3278543 0.1843866 0.2555418 0.2334781\n",
       " [582] 0.1794644 0.1047530 0.8528097 0.2123167 0.3683494 0.2879404 0.2879404\n",
       " [589] 0.1047530 0.1404107 0.2601498 0.3035402 0.1047530 0.1509204 0.3630269\n",
       " [596] 0.2094321 0.3035402 0.2580832 0.2108175 0.1365053 0.3250314 0.2636534\n",
       " [603] 0.2366013 0.6717388 0.1404107 0.2555418 0.1545794 0.3630269 0.1047530\n",
       " [610] 0.9390904 0.2108175 0.5641311 0.9383479 0.3604295 0.2555418 0.1472927\n",
       " [617] 0.7374583 0.8237292 0.1404107 0.2592677 0.2879404 0.1404107 0.1509204\n",
       " [624] 0.1404107 0.1545794 0.7244676 0.2123167 0.3590606 0.1493118 0.2580832\n",
       " [631] 0.2592677 0.1404107 0.2366013 0.2805772 0.9391117 0.2960537 0.1365053\n",
       " [638] 0.2123167 0.2709570 0.6065572 0.2592677 0.1404107 0.2108175 0.2403533\n",
       " [645] 0.1404107 0.3035402 0.1794644 0.1545794 0.3630269 0.2108175 0.4169435\n",
       " [652] 0.1843866 0.2366013 0.3590606 0.1404107 0.2636534 0.2555418 0.1404107\n",
       " [659] 0.1794644 0.2555418 0.2366013 0.1472927 0.3604295 0.3035402 0.1047530\n",
       " [666] 0.1042542 0.1864533 0.1864533 0.2123167 0.4350431 0.2636534 0.2514018\n",
       " [673] 0.2805772 0.1404107 0.1927164 0.2334781 0.1365053 0.2592677 0.1509204\n",
       " [680] 0.2403533 0.1864533 0.3035402 0.3035402 0.7025640 0.6579350 0.1404107\n",
       " [687] 0.1794644 0.6563502 0.1404107 0.6375156 0.1864533 0.2334781 0.1472927\n",
       " [694] 0.2879404 0.1843866 0.2555418 0.3035402 0.3604295 0.9391117 0.1047530\n",
       " [701] 0.1572694 0.6157273 0.2636534 0.4433042 0.1404107 0.1794644 0.2709570\n",
       " [708] 0.7050218 0.1042542 0.2805772 0.2805772 0.2503909 0.1958646 0.2636534\n",
       " [715] 0.3035402 0.2636534 0.1843866 0.4045356 0.2580832 0.6375156 0.2555418\n",
       " [722] 0.1365053 0.3683494 0.1864533 0.1404107 0.2555418 0.9412710 0.2709570\n",
       " [729] 0.1404107 0.5545706 0.3631967 0.2123167 0.3870831 0.2636534 0.2351151\n",
       " [736] 0.2879404 0.1365053 0.1404107 0.2445594 0.7587252 0.9249231 0.2709570\n",
       " [743] 0.3904007 0.9416819 0.1365053 0.3035402 0.2334781 0.5394107 0.3250314\n",
       " [750] 0.2123167 0.6641027 0.2094321 0.2879404 0.2674891 0.1365053 0.2366013\n",
       " [757] 0.1545794 0.2123167 0.3278543 0.7143571 0.2879404 0.1572694 0.1958646\n",
       " [764] 0.6995927 0.4433042 0.5383215 0.7092686 0.7797232 0.1472927 0.2123167\n",
       " [771] 0.2555418 0.6555097 0.3035402 0.1927164 0.1958646 0.3870831 0.3904007\n",
       " [778] 0.2033309 0.2351151 0.7212797 0.2636534 0.1404107 0.4433042 0.2674891\n",
       " [785] 0.5715484 0.6988544 0.2636534 0.2674891 0.2033309 0.2674891 0.2503909\n",
       " [792] 0.1365053 0.2503909 0.1404107 0.3631967 0.8510346 0.9262358 0.3604295\n",
       " [799] 0.2709570 0.2351151 0.8151296 0.6157273 0.1365053 0.2108175 0.8940409\n",
       " [806] 0.3035402 0.2592677 0.2123167 0.3631967 0.3278543 0.1794644 0.2805772\n",
       " [813] 0.2123167 0.2601498 0.3904007 0.2555418 0.1794644 0.2555418 0.3630269\n",
       " [820] 0.7804996 0.3035402 0.3870831 0.1958646 0.1794644 0.1997623 0.3683494\n",
       " [827] 0.9456820 0.2497731 0.2300151 0.2879404 0.3870831 0.2334781 0.7811775\n",
       " [834] 0.2879404 0.7002148 0.2445594 0.1404107 0.1042542 0.7143571 0.2879404\n",
       " [841] 0.3250314 0.2636534 0.2555418 0.3278543 0.2445594 0.3035402 0.7180740\n",
       " [848] 0.4550814 0.3250314 0.1843866 0.7907701 0.6104846 0.6555097 0.1404107\n",
       " [855] 0.4045356 0.3278543 0.1843866 0.3035402 0.9508219 0.1958646 0.2334781\n",
       " [862] 0.2636534 0.8113310 0.2366013 0.1404107 0.3604295 0.1404107 0.6510911\n",
       " [869] 0.7938661 0.2445594 0.4045356 0.1404107 0.2503909 0.2123167 0.2601498\n",
       " [876] 0.1404107 0.2108175 0.1843866 0.1365053 0.2403533 0.6065572 0.1365053\n",
       " [883] 0.2879404 0.3035402 0.3278543 0.1365053 0.3035402 0.2879404 0.4433042\n",
       " [890] 0.3035402 0.1365053 0.4433042 0.3035402 0.1404107 0.1843866 0.2108175\n",
       " [897] 0.2674891 0.2601498 0.1404107 0.1042542 0.2366013 0.6560774 0.2108175\n",
       " [904] 0.2497731 0.1958646 0.2366013 0.6375156 0.6157273 0.2879404 0.9326438\n",
       " [911] 0.4131556 0.3683494 0.1927164 0.7945584 0.1404107 0.2555418 0.1545794\n",
       " [918] 0.1042542 0.8234487 0.1404107 0.4169435 0.7811775 0.2094321 0.2601498\n",
       " [925] 0.3870831 0.2351151 0.1509204 0.2879404 0.2403533 0.2601498 0.2592677\n",
       " [932] 0.2351151 0.3870831 0.2351151 0.4045356 0.2674891 0.3604295 0.2368417\n",
       " [939] 0.2636534 0.1042542 0.1794644 0.1365053 0.8237292 0.2805772 0.7431235\n",
       " [946] 0.1042542 0.7776024 0.2334781 0.2879404 0.1509204 0.7811775 0.3604295\n",
       " [953] 0.1365053 0.2351151 0.3035402 0.2879404 0.1843866 0.4433042 0.3035402\n",
       " [960] 0.9326438 0.1864533 0.8975087 0.8696718 0.7046529 0.1545794 0.2601498\n",
       " [967] 0.1794644 0.1864533 0.2601498 0.1042542 0.8177279 0.2879404 0.3904007\n",
       " [974] 0.7811775 0.2123167 0.2445594 0.8018854 0.1509204 0.7679411 0.1927164\n",
       " [981] 0.2674891 0.3604295 0.2108175 0.2366013 0.2636534 0.4120548 0.2445594\n",
       " [988] 0.2514018 0.2334781 0.2805772 0.2555418 0.2805772 0.3683494 0.3250314\n",
       " [995] 0.2580832 0.2555418 0.1404107 0.1404107 0.2555418 0.2636534 0.1843866\n",
       "[1002] 0.3683494 0.1958646 0.2709570 0.4045356 0.7776024 0.2636534 0.4433042\n",
       "[1009] 0.3683494 0.2108175 0.9390904 0.4169435 0.7503399 0.2108175 0.1365053\n",
       "[1016] 0.7832779 0.5585257 0.2300151 0.1404107 0.2123167 0.2123167 0.1404107\n",
       "[1023] 0.3683494 0.6065572 0.1404107 0.1843866 0.2601498 0.2674891 0.8234487\n",
       "[1030] 0.1509204 0.1545794 0.2601498 0.7950110 0.1493118 0.3870831 0.2674891\n",
       "[1037] 0.1404107 0.3035402 0.2366013 0.2503909 0.1572694 0.2503909 0.2123167\n",
       "[1044] 0.2497731 0.3683494 0.2351151 0.3035402 0.2300151 0.2960537 0.2879404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model on validation set\n",
    "gb.pred.up = predict(gb.up ,valid_processed[, -1], n.trees = 1000, type='response')\n",
    "\n",
    "# if probabibility is > 0.5 consider as subscribe\n",
    "gb.pred2.up <- ifelse(gb.pred.up > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction   0   1\n",
      "         0 827 105\n",
      "         1  48  70\n",
      "                                          \n",
      "               Accuracy : 0.8543          \n",
      "                 95% CI : (0.8315, 0.8751)\n",
      "    No Information Rate : 0.8333          \n",
      "    P-Value [Acc > NIR] : 0.03579         \n",
      "                                          \n",
      "                  Kappa : 0.3968          \n",
      "                                          \n",
      " Mcnemar's Test P-Value : 5.973e-06       \n",
      "                                          \n",
      "            Sensitivity : 0.9451          \n",
      "            Specificity : 0.4000          \n",
      "         Pos Pred Value : 0.8873          \n",
      "         Neg Pred Value : 0.5932          \n",
      "             Prevalence : 0.8333          \n",
      "         Detection Rate : 0.7876          \n",
      "   Detection Prevalence : 0.8876          \n",
      "      Balanced Accuracy : 0.6726          \n",
      "                                          \n",
      "       'Positive' Class : 0               \n",
      "                                          \n"
     ]
    }
   ],
   "source": [
    "# look at confusion matrix - accuracy decreases to 85.4% with resampling (from 89%)\n",
    "cm = confusionMatrix(as.factor(valid_processed$subscribe), as.factor(gb.pred2.up))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.7120596</td><td>0.2879404</td></tr>\n",
       "\t<tr><td>0.8135467</td><td>0.1864533</td></tr>\n",
       "\t<tr><td>0.6409394</td><td>0.3590606</td></tr>\n",
       "\t<tr><td>0.8595893</td><td>0.1404107</td></tr>\n",
       "\t<tr><td>0.6316506</td><td>0.3683494</td></tr>\n",
       "\t<tr><td>0.6964598</td><td>0.3035402</td></tr>\n",
       "\t<tr><td>0.3702707</td><td>0.6297293</td></tr>\n",
       "\t<tr><td>0.6129169</td><td>0.3870831</td></tr>\n",
       "\t<tr><td>0.7554406</td><td>0.2445594</td></tr>\n",
       "\t<tr><td>0.6749686</td><td>0.3250314</td></tr>\n",
       "\t<tr><td>0.7407323</td><td>0.2592677</td></tr>\n",
       "\t<tr><td>0.7444582</td><td>0.2555418</td></tr>\n",
       "\t<tr><td>0.8072836</td><td>0.1927164</td></tr>\n",
       "\t<tr><td>0.7444582</td><td>0.2555418</td></tr>\n",
       "\t<tr><td>0.6369731</td><td>0.3630269</td></tr>\n",
       "\t<tr><td>0.7444582</td><td>0.2555418</td></tr>\n",
       "\t<tr><td>0.7039463</td><td>0.2960537</td></tr>\n",
       "\t<tr><td>0.7363466</td><td>0.2636534</td></tr>\n",
       "\t<tr><td>0.5566958</td><td>0.4433042</td></tr>\n",
       "\t<tr><td>0.5954644</td><td>0.4045356</td></tr>\n",
       "\t<tr><td>0.7485982</td><td>0.2514018</td></tr>\n",
       "\t<tr><td>0.7363466</td><td>0.2636534</td></tr>\n",
       "\t<tr><td>0.8135467</td><td>0.1864533</td></tr>\n",
       "\t<tr><td>0.6316506</td><td>0.3683494</td></tr>\n",
       "\t<tr><td>0.3145071</td><td>0.6854929</td></tr>\n",
       "\t<tr><td>0.6395705</td><td>0.3604295</td></tr>\n",
       "\t<tr><td>0.5868444</td><td>0.4131556</td></tr>\n",
       "\t<tr><td>0.7325109</td><td>0.2674891</td></tr>\n",
       "\t<tr><td>0.7699849</td><td>0.2300151</td></tr>\n",
       "\t<tr><td>0.8506882</td><td>0.1493118</td></tr>\n",
       "\t<tr><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>0.7876833</td><td>0.2123167</td></tr>\n",
       "\t<tr><td>0.8595893</td><td>0.1404107</td></tr>\n",
       "\t<tr><td>0.6316506</td><td>0.3683494</td></tr>\n",
       "\t<tr><td>0.3934428</td><td>0.6065572</td></tr>\n",
       "\t<tr><td>0.8595893</td><td>0.1404107</td></tr>\n",
       "\t<tr><td>0.8156134</td><td>0.1843866</td></tr>\n",
       "\t<tr><td>0.7398502</td><td>0.2601498</td></tr>\n",
       "\t<tr><td>0.7325109</td><td>0.2674891</td></tr>\n",
       "\t<tr><td>0.1765513</td><td>0.8234487</td></tr>\n",
       "\t<tr><td>0.8490796</td><td>0.1509204</td></tr>\n",
       "\t<tr><td>0.8454206</td><td>0.1545794</td></tr>\n",
       "\t<tr><td>0.7398502</td><td>0.2601498</td></tr>\n",
       "\t<tr><td>0.2049890</td><td>0.7950110</td></tr>\n",
       "\t<tr><td>0.8506882</td><td>0.1493118</td></tr>\n",
       "\t<tr><td>0.6129169</td><td>0.3870831</td></tr>\n",
       "\t<tr><td>0.7325109</td><td>0.2674891</td></tr>\n",
       "\t<tr><td>0.8595893</td><td>0.1404107</td></tr>\n",
       "\t<tr><td>0.6964598</td><td>0.3035402</td></tr>\n",
       "\t<tr><td>0.7633987</td><td>0.2366013</td></tr>\n",
       "\t<tr><td>0.7496091</td><td>0.2503909</td></tr>\n",
       "\t<tr><td>0.8427306</td><td>0.1572694</td></tr>\n",
       "\t<tr><td>0.7496091</td><td>0.2503909</td></tr>\n",
       "\t<tr><td>0.7876833</td><td>0.2123167</td></tr>\n",
       "\t<tr><td>0.7502269</td><td>0.2497731</td></tr>\n",
       "\t<tr><td>0.6316506</td><td>0.3683494</td></tr>\n",
       "\t<tr><td>0.7648849</td><td>0.2351151</td></tr>\n",
       "\t<tr><td>0.6964598</td><td>0.3035402</td></tr>\n",
       "\t<tr><td>0.7699849</td><td>0.2300151</td></tr>\n",
       "\t<tr><td>0.7039463</td><td>0.2960537</td></tr>\n",
       "\t<tr><td>0.7120596</td><td>0.2879404</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " 0 & 1\\\\\n",
       "\\hline\n",
       "\t 0.7120596 & 0.2879404\\\\\n",
       "\t 0.8135467 & 0.1864533\\\\\n",
       "\t 0.6409394 & 0.3590606\\\\\n",
       "\t 0.8595893 & 0.1404107\\\\\n",
       "\t 0.6316506 & 0.3683494\\\\\n",
       "\t 0.6964598 & 0.3035402\\\\\n",
       "\t 0.3702707 & 0.6297293\\\\\n",
       "\t 0.6129169 & 0.3870831\\\\\n",
       "\t 0.7554406 & 0.2445594\\\\\n",
       "\t 0.6749686 & 0.3250314\\\\\n",
       "\t 0.7407323 & 0.2592677\\\\\n",
       "\t 0.7444582 & 0.2555418\\\\\n",
       "\t 0.8072836 & 0.1927164\\\\\n",
       "\t 0.7444582 & 0.2555418\\\\\n",
       "\t 0.6369731 & 0.3630269\\\\\n",
       "\t 0.7444582 & 0.2555418\\\\\n",
       "\t 0.7039463 & 0.2960537\\\\\n",
       "\t 0.7363466 & 0.2636534\\\\\n",
       "\t 0.5566958 & 0.4433042\\\\\n",
       "\t 0.5954644 & 0.4045356\\\\\n",
       "\t 0.7485982 & 0.2514018\\\\\n",
       "\t 0.7363466 & 0.2636534\\\\\n",
       "\t 0.8135467 & 0.1864533\\\\\n",
       "\t 0.6316506 & 0.3683494\\\\\n",
       "\t 0.3145071 & 0.6854929\\\\\n",
       "\t 0.6395705 & 0.3604295\\\\\n",
       "\t 0.5868444 & 0.4131556\\\\\n",
       "\t 0.7325109 & 0.2674891\\\\\n",
       "\t 0.7699849 & 0.2300151\\\\\n",
       "\t 0.8506882 & 0.1493118\\\\\n",
       "\t ... & ...\\\\\n",
       "\t 0.7876833 & 0.2123167\\\\\n",
       "\t 0.8595893 & 0.1404107\\\\\n",
       "\t 0.6316506 & 0.3683494\\\\\n",
       "\t 0.3934428 & 0.6065572\\\\\n",
       "\t 0.8595893 & 0.1404107\\\\\n",
       "\t 0.8156134 & 0.1843866\\\\\n",
       "\t 0.7398502 & 0.2601498\\\\\n",
       "\t 0.7325109 & 0.2674891\\\\\n",
       "\t 0.1765513 & 0.8234487\\\\\n",
       "\t 0.8490796 & 0.1509204\\\\\n",
       "\t 0.8454206 & 0.1545794\\\\\n",
       "\t 0.7398502 & 0.2601498\\\\\n",
       "\t 0.2049890 & 0.7950110\\\\\n",
       "\t 0.8506882 & 0.1493118\\\\\n",
       "\t 0.6129169 & 0.3870831\\\\\n",
       "\t 0.7325109 & 0.2674891\\\\\n",
       "\t 0.8595893 & 0.1404107\\\\\n",
       "\t 0.6964598 & 0.3035402\\\\\n",
       "\t 0.7633987 & 0.2366013\\\\\n",
       "\t 0.7496091 & 0.2503909\\\\\n",
       "\t 0.8427306 & 0.1572694\\\\\n",
       "\t 0.7496091 & 0.2503909\\\\\n",
       "\t 0.7876833 & 0.2123167\\\\\n",
       "\t 0.7502269 & 0.2497731\\\\\n",
       "\t 0.6316506 & 0.3683494\\\\\n",
       "\t 0.7648849 & 0.2351151\\\\\n",
       "\t 0.6964598 & 0.3035402\\\\\n",
       "\t 0.7699849 & 0.2300151\\\\\n",
       "\t 0.7039463 & 0.2960537\\\\\n",
       "\t 0.7120596 & 0.2879404\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 1 |\n",
       "|---|---|\n",
       "| 0.7120596 | 0.2879404 |\n",
       "| 0.8135467 | 0.1864533 |\n",
       "| 0.6409394 | 0.3590606 |\n",
       "| 0.8595893 | 0.1404107 |\n",
       "| 0.6316506 | 0.3683494 |\n",
       "| 0.6964598 | 0.3035402 |\n",
       "| 0.3702707 | 0.6297293 |\n",
       "| 0.6129169 | 0.3870831 |\n",
       "| 0.7554406 | 0.2445594 |\n",
       "| 0.6749686 | 0.3250314 |\n",
       "| 0.7407323 | 0.2592677 |\n",
       "| 0.7444582 | 0.2555418 |\n",
       "| 0.8072836 | 0.1927164 |\n",
       "| 0.7444582 | 0.2555418 |\n",
       "| 0.6369731 | 0.3630269 |\n",
       "| 0.7444582 | 0.2555418 |\n",
       "| 0.7039463 | 0.2960537 |\n",
       "| 0.7363466 | 0.2636534 |\n",
       "| 0.5566958 | 0.4433042 |\n",
       "| 0.5954644 | 0.4045356 |\n",
       "| 0.7485982 | 0.2514018 |\n",
       "| 0.7363466 | 0.2636534 |\n",
       "| 0.8135467 | 0.1864533 |\n",
       "| 0.6316506 | 0.3683494 |\n",
       "| 0.3145071 | 0.6854929 |\n",
       "| 0.6395705 | 0.3604295 |\n",
       "| 0.5868444 | 0.4131556 |\n",
       "| 0.7325109 | 0.2674891 |\n",
       "| 0.7699849 | 0.2300151 |\n",
       "| 0.8506882 | 0.1493118 |\n",
       "| ... | ... |\n",
       "| 0.7876833 | 0.2123167 |\n",
       "| 0.8595893 | 0.1404107 |\n",
       "| 0.6316506 | 0.3683494 |\n",
       "| 0.3934428 | 0.6065572 |\n",
       "| 0.8595893 | 0.1404107 |\n",
       "| 0.8156134 | 0.1843866 |\n",
       "| 0.7398502 | 0.2601498 |\n",
       "| 0.7325109 | 0.2674891 |\n",
       "| 0.1765513 | 0.8234487 |\n",
       "| 0.8490796 | 0.1509204 |\n",
       "| 0.8454206 | 0.1545794 |\n",
       "| 0.7398502 | 0.2601498 |\n",
       "| 0.2049890 | 0.7950110 |\n",
       "| 0.8506882 | 0.1493118 |\n",
       "| 0.6129169 | 0.3870831 |\n",
       "| 0.7325109 | 0.2674891 |\n",
       "| 0.8595893 | 0.1404107 |\n",
       "| 0.6964598 | 0.3035402 |\n",
       "| 0.7633987 | 0.2366013 |\n",
       "| 0.7496091 | 0.2503909 |\n",
       "| 0.8427306 | 0.1572694 |\n",
       "| 0.7496091 | 0.2503909 |\n",
       "| 0.7876833 | 0.2123167 |\n",
       "| 0.7502269 | 0.2497731 |\n",
       "| 0.6316506 | 0.3683494 |\n",
       "| 0.7648849 | 0.2351151 |\n",
       "| 0.6964598 | 0.3035402 |\n",
       "| 0.7699849 | 0.2300151 |\n",
       "| 0.7039463 | 0.2960537 |\n",
       "| 0.7120596 | 0.2879404 |\n",
       "\n"
      ],
      "text/plain": [
       "     0         1        \n",
       "1    0.7120596 0.2879404\n",
       "2    0.8135467 0.1864533\n",
       "3    0.6409394 0.3590606\n",
       "4    0.8595893 0.1404107\n",
       "5    0.6316506 0.3683494\n",
       "6    0.6964598 0.3035402\n",
       "7    0.3702707 0.6297293\n",
       "8    0.6129169 0.3870831\n",
       "9    0.7554406 0.2445594\n",
       "10   0.6749686 0.3250314\n",
       "11   0.7407323 0.2592677\n",
       "12   0.7444582 0.2555418\n",
       "13   0.8072836 0.1927164\n",
       "14   0.7444582 0.2555418\n",
       "15   0.6369731 0.3630269\n",
       "16   0.7444582 0.2555418\n",
       "17   0.7039463 0.2960537\n",
       "18   0.7363466 0.2636534\n",
       "19   0.5566958 0.4433042\n",
       "20   0.5954644 0.4045356\n",
       "21   0.7485982 0.2514018\n",
       "22   0.7363466 0.2636534\n",
       "23   0.8135467 0.1864533\n",
       "24   0.6316506 0.3683494\n",
       "25   0.3145071 0.6854929\n",
       "26   0.6395705 0.3604295\n",
       "27   0.5868444 0.4131556\n",
       "28   0.7325109 0.2674891\n",
       "29   0.7699849 0.2300151\n",
       "30   0.8506882 0.1493118\n",
       "...  ...       ...      \n",
       "1021 0.7876833 0.2123167\n",
       "1022 0.8595893 0.1404107\n",
       "1023 0.6316506 0.3683494\n",
       "1024 0.3934428 0.6065572\n",
       "1025 0.8595893 0.1404107\n",
       "1026 0.8156134 0.1843866\n",
       "1027 0.7398502 0.2601498\n",
       "1028 0.7325109 0.2674891\n",
       "1029 0.1765513 0.8234487\n",
       "1030 0.8490796 0.1509204\n",
       "1031 0.8454206 0.1545794\n",
       "1032 0.7398502 0.2601498\n",
       "1033 0.2049890 0.7950110\n",
       "1034 0.8506882 0.1493118\n",
       "1035 0.6129169 0.3870831\n",
       "1036 0.7325109 0.2674891\n",
       "1037 0.8595893 0.1404107\n",
       "1038 0.6964598 0.3035402\n",
       "1039 0.7633987 0.2366013\n",
       "1040 0.7496091 0.2503909\n",
       "1041 0.8427306 0.1572694\n",
       "1042 0.7496091 0.2503909\n",
       "1043 0.7876833 0.2123167\n",
       "1044 0.7502269 0.2497731\n",
       "1045 0.6316506 0.3683494\n",
       "1046 0.7648849 0.2351151\n",
       "1047 0.6964598 0.3035402\n",
       "1048 0.7699849 0.2300151\n",
       "1049 0.7039463 0.2960537\n",
       "1050 0.7120596 0.2879404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert output to a form that has 2 columns - probability for 0 and 1\n",
    "gb_df_up <- data.frame(gb.pred.up)\n",
    "gb_df_up$one <- gb_df_up$gb.pred.up\n",
    "gb_df_up$zero <- 1 - gb_df_up$gb.pred.up\n",
    "gb_df_up <- gb_df_up[-1]\n",
    "gb_df_up[, '0'] <- gb_df_up[, 'zero'] \n",
    "gb_df_up[, '1'] <- gb_df_up[, 1]\n",
    "gb_df_up <- gb_df_up[-1]\n",
    "gb_df_up <- gb_df_up[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8113998\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8113998\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nIQBJE0IAkiaEACRNCAFImhACkLT/JaSoUuMrwWQAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  import ROCR package for ROC curve plotting - AUC is 81.1% with resampling, improvement from earlier model\n",
    "library(ROCR)\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_gb_up_roc_curve <- gb_df_up\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(valid_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_gb_up_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.gb.valid.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.gb.valid.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.854285714285714"
      ],
      "text/latex": [
       "0.854285714285714"
      ],
      "text/markdown": [
       "0.854285714285714"
      ],
      "text/plain": [
       "[1] 0.8542857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.593220338983051"
      ],
      "text/latex": [
       "0.593220338983051"
      ],
      "text/markdown": [
       "0.593220338983051"
      ],
      "text/plain": [
       "[1] 0.5932203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - 85.4% without resampling, decrease from earlier model\n",
    "gb_acc_valid_up <- accuracy(valid_processed$subscribe, gb.pred2.up)\n",
    "gb_acc_valid_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1. Support Vector Machine - WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"e1071\")\n",
    "\n",
    "# train SVM on training set\n",
    "svm = svm(formula = subscribe ~ ., \n",
    "                 data = train_processed[,-1], \n",
    "                 type = 'C-classification', \n",
    "                 kernel = 'linear',  #checked results from linear, polynomial and radial kernels and linear preformed best\n",
    "                 probability=TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on validation set \n",
    "svm.pred = predict(svm, newdata = valid_processed[,-1], probability=TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   svm.pred\n",
       "      0   1\n",
       "  0 919  13\n",
       "  1  94  24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the confusion matrix\n",
    "cm = table(valid_processed$subscribe, svm.pred) \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.9039515 </td><td>0.09604854</td></tr>\n",
       "\t<tr><td>0.9039516 </td><td>0.09604842</td></tr>\n",
       "\t<tr><td>0.9039925 </td><td>0.09600746</td></tr>\n",
       "\t<tr><td>0.9039890 </td><td>0.09601097</td></tr>\n",
       "\t<tr><td>0.9039569 </td><td>0.09604309</td></tr>\n",
       "\t<tr><td>0.9039519 </td><td>0.09604811</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " 0 & 1\\\\\n",
       "\\hline\n",
       "\t 0.9039515  & 0.09604854\\\\\n",
       "\t 0.9039516  & 0.09604842\\\\\n",
       "\t 0.9039925  & 0.09600746\\\\\n",
       "\t 0.9039890  & 0.09601097\\\\\n",
       "\t 0.9039569  & 0.09604309\\\\\n",
       "\t 0.9039519  & 0.09604811\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 1 |\n",
       "|---|---|\n",
       "| 0.9039515  | 0.09604854 |\n",
       "| 0.9039516  | 0.09604842 |\n",
       "| 0.9039925  | 0.09600746 |\n",
       "| 0.9039890  | 0.09601097 |\n",
       "| 0.9039569  | 0.09604309 |\n",
       "| 0.9039519  | 0.09604811 |\n",
       "\n"
      ],
      "text/plain": [
       "  0         1         \n",
       "1 0.9039515 0.09604854\n",
       "2 0.9039516 0.09604842\n",
       "3 0.9039925 0.09600746\n",
       "4 0.9039890 0.09601097\n",
       "5 0.9039569 0.09604309\n",
       "6 0.9039519 0.09604811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if output of the model is in the form required \n",
    "head(attr(svm.pred, \"probabilities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.6173711\n",
      "\n",
      "[[1]]\n",
      "[1] 0.6173711\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nQmCC",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  import ROCR package for ROC curve plotting - AUC is 61.7% without resampling\n",
    "library(ROCR)\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_svm_roc_curve <- predict(svm, newdata = valid_processed[,-1], probability=TRUE) \n",
    "prediction_svm_roc_curve <- attr(prediction_svm_roc_curve, \"probabilities\")\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(valid_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_svm_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.svm.valid <- performance(pred, measure = \"auc\")\n",
    " print(auc.svm.valid@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.898095238095238"
      ],
      "text/latex": [
       "0.898095238095238"
      ],
      "text/markdown": [
       "0.898095238095238"
      ],
      "text/plain": [
       "[1] 0.8980952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(predicted[actual == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - 89.8% accuracy without resampling\n",
    "svm_acc_valid <- accuracy(valid_processed$subscribe, svm.pred)\n",
    "svm_acc_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2. Support Vector Machine - WITH RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/skamal/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"package 'DMwR' is in use and will not be installed\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2284 1713 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resample the data in the train set using SMOTE - makes the classes more balanced \n",
    "# undersamples majority class (0) and oversamples minority class (1)\n",
    "set.seed(1)\n",
    "train_processed$subscribe <- as.factor(train_processed$subscribe)\n",
    "up_train <- SMOTE(subscribe ~ ., data  = train_processed[, -1])                         \n",
    "table(up_train$subscribe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train SVM model on resampled data \n",
    "svm.up = svm(formula = subscribe ~ ., \n",
    "                 data = up_train[,-1], \n",
    "                 type = 'C-classification', \n",
    "                 kernel = 'linear',\n",
    "                 probability=TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the validation set \n",
    "svm.pred.up = predict(svm.up, newdata = valid_processed[,-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   svm.pred.up\n",
       "      0   1\n",
       "  0 805 127\n",
       "  1  48  70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the confusion matrix \n",
    "cm = table(valid_processed$subscribe, svm.pred.up) \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7800975\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7800975\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwgAAALQCAMAAACzGNRRAAAANlBMVEUAAAAAujhNTU1oaGh8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\nRK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  import ROCR package for ROC curve plotting - AUC goes up from 64% without resampling to 78% with resampling\n",
    "library(ROCR)\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_svm_up_roc_curve <- predict(svm.up, newdata = valid_processed[,-1], probability=TRUE) \n",
    "prediction_svm_up_roc_curve <- attr(prediction_svm_up_roc_curve, \"probabilities\")\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(valid_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(valid_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_svm_up_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " if (i==1)\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i]) \n",
    " }\n",
    " else\n",
    " {\n",
    "     plot(perf,main=\"ROC Curve\",col=colours[i],add=TRUE) \n",
    " }\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.svm.valid.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.svm.valid.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.833333333333333"
      ],
      "text/latex": [
       "0.833333333333333"
      ],
      "text/markdown": [
       "0.833333333333333"
      ],
      "text/plain": [
       "[1] 0.8333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(predicted[actual == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(actual[predicted == 1]):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy metric on validation set - 83% accuracy with resampling, decrease from earlier model\n",
    "svm_acc_valid_up <- accuracy(valid_processed$subscribe, svm.pred.up)\n",
    "svm_acc_valid_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0. Experiment 2 - Testing Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE ALL MODELS (WITH AND WITHOUT RESAMPLING) ON TEST SET \n",
    "# TOTAL OF TEN MODELS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Logistic Regression - TEST MODELS WITH AND WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION WITH AND WITHOUT SAMPLING\n",
    "\n",
    "# test model without resampling\n",
    "log.pred.test = (predict(log, newdata = test_processed[, -1]))\n",
    "# if probabibility is > 0.5 consider as subscribe\n",
    "log.pred2.test <- ifelse(log.pred.test > 0.5,1,0)\n",
    "\n",
    "# test model with resampling\n",
    "log.pred.test.up = plogis(predict(log.up, newdata = test_processed[, -1]))\n",
    "# if probabibility is > 0.5 consider as subscribe\n",
    "log.pred2.test.up <- ifelse(log.pred.test.up > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to get probabilities \n",
    "\n",
    "# without resampling\n",
    "log_df_test <- data.frame(log.pred.test)\n",
    "log_df_test$one <- log_df_test$log.pred.test\n",
    "log_df_test$zero <- 1 - log_df_test$log.pred.test\n",
    "log_df_test <- log_df_test[-1]\n",
    "log_df_test[, '0'] <- log_df_test[, 'zero'] \n",
    "log_df_test[, '1'] <- log_df_test[, 1]\n",
    "log_df_test <- log_df_test[-1]\n",
    "log_df_test <- log_df_test[-1]\n",
    "\n",
    "# with resampling\n",
    "\n",
    "log_df_test_up <- data.frame(log.pred.test.up)\n",
    "log_df_test_up$one <- log_df_test_up$log.pred.test.up\n",
    "log_df_test_up$zero <- 1 - log_df_test_up$log.pred.test.up\n",
    "log_df_test_up <- log_df_test_up[-1]\n",
    "log_df_test_up[, '0'] <- log_df_test_up[, 'zero'] \n",
    "log_df_test_up[, '1'] <- log_df_test_up[, 1]\n",
    "log_df_test_up <- log_df_test_up[-1]\n",
    "log_df_test_up <- log_df_test_up[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Logistic Model - Test Set - Without Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.831155\n",
      "\n",
      "[[1]]\n",
      "[1] 0.831155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test logistic regression without resampling\n",
    "# AUC is 83% without resampling\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "\n",
    "prediction_log_test_roc_curve <- log_df_test\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_log_test_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.log.test <- performance(pred, measure = \"auc\")\n",
    " print(auc.log.test@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.887619047619048"
      ],
      "text/latex": [
       "0.887619047619048"
      ],
      "text/markdown": [
       "0.887619047619048"
      ],
      "text/plain": [
       "[1] 0.887619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.172932330827068"
      ],
      "text/latex": [
       "0.172932330827068"
      ],
      "text/markdown": [
       "0.172932330827068"
      ],
      "text/plain": [
       "[1] 0.1729323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.741935483870968"
      ],
      "text/latex": [
       "0.741935483870968"
      ],
      "text/markdown": [
       "0.741935483870968"
      ],
      "text/plain": [
       "[1] 0.7419355"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on test set - 88.7% accuracy for logit model without resampling\n",
    "log_acc_test <- accuracy(test_processed$subscribe, log.pred2.test)\n",
    "log_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Logistic Model - Test Set - With Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8257107\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8257107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test logistic regression with resampling\n",
    "# AUC is 82.5% with resampling, slight decrease from 83% witout resamping\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "prediction_logup_test_roc_curve <- log_df_test_up\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_logup_test_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.log.test.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.log.test.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.841904761904762"
      ],
      "text/latex": [
       "0.841904761904762"
      ],
      "text/markdown": [
       "0.841904761904762"
      ],
      "text/plain": [
       "[1] 0.8419048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.676691729323308"
      ],
      "text/latex": [
       "0.676691729323308"
      ],
      "text/markdown": [
       "0.676691729323308"
      ],
      "text/plain": [
       "[1] 0.6766917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.422535211267606"
      ],
      "text/latex": [
       "0.422535211267606"
      ],
      "text/markdown": [
       "0.422535211267606"
      ],
      "text/plain": [
       "[1] 0.4225352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on test set - 84.2% accuracy for logit model with resampling, decrease from model without resampling\n",
    "log_acc_test_up <- accuracy(test_processed$subscribe, log.pred2.test.up)\n",
    "log_acc_test_up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 Logistic Model - Predict on Holdout set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>0.254727829425613</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>0.224242988872205</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>0.758230045708706</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0.274648751274905</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>0.161455333575095</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>0.276370025611108</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 0.254727829425613\n",
       "\\item[2] 0.224242988872205\n",
       "\\item[3] 0.758230045708706\n",
       "\\item[4] 0.274648751274905\n",
       "\\item[5] 0.161455333575095\n",
       "\\item[6] 0.276370025611108\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   0.2547278294256132\n",
       ":   0.2242429888722053\n",
       ":   0.7582300457087064\n",
       ":   0.2746487512749055\n",
       ":   0.1614553335750956\n",
       ":   0.276370025611108\n",
       "\n"
      ],
      "text/plain": [
       "        1         2         3         4         5         6 \n",
       "0.2547278 0.2242430 0.7582300 0.2746488 0.1614553 0.2763700 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PREDICT ON THE HOLDOUT SET\n",
    "\n",
    "# PREDICT LOGIT WITHOUT RESAMPLING\n",
    "log_pred_holdout <- plogis(predict(log, newdata=test_holdout_processed[, -1]))\n",
    "\n",
    "# PREDICT LOGIT WITH RESAMPLING\n",
    "log_pred_holdout_up <- plogis(predict(log.up, newdata=test_holdout_processed[, -1]))\n",
    "head(log_pred_holdout_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, ifelse(append, \"a\", \"w\")):\n",
      "\"cannot open file 'C:/Users/skamal/Downloads/log_submission_noresample.csv': Permission denied\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, ifelse(append, \"a\", \"w\")): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, ifelse(append, \"a\", \"w\")): cannot open the connection\nTraceback:\n",
      "1. write.csv(output, \"C:/Users/skamal/Downloads/log_submission_noresample.csv\", \n .     row.names = FALSE)",
      "2. eval.parent(Call)",
      "3. eval(expr, p)",
      "4. eval(expr, p)",
      "5. write.table(output, \"C:/Users/skamal/Downloads/log_submission_noresample.csv\", \n .     row.names = FALSE, col.names = TRUE, sep = \",\", dec = \".\", \n .     qmethod = \"double\")",
      "6. file(file, ifelse(append, \"a\", \"w\"))"
     ]
    }
   ],
   "source": [
    "# EXPORT FILES\n",
    "output <- data.frame(client_id=test_holdout$client_id, subscribe=log_pred_holdout)\n",
    "write.csv(output, 'C:/Users/skamal/Downloads/log_submission_noresample.csv', row.names=FALSE) # AUC 80.4 on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FILES\n",
    "output2 <- data.frame(client_id=test_holdout$client_id, subscribe=log_pred_holdout_up)\n",
    "write.csv(output2, 'C:/Users/skamal/Downloads/log_submission_resample.csv', row.names=FALSE) # AUC 80.1 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Decision Tree - TEST MODELS WITH AND WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree \n",
    "\n",
    "# predict tree with no resample\n",
    "\n",
    "tree_pred_test <- predict(classtree, newdata=test_processed[, -1], type='class')\n",
    "tree_pred_proba_test <- predict(classtree, newdata=test_processed[, -1], type='vector')\n",
    "\n",
    "# predict tree with resample\n",
    "\n",
    "tree_pred_test_up <- predict(classtree.up, newdata=test_processed[, -1], type='class')\n",
    "tree_pred_proba_test_up <- predict(classtree.up, newdata=test_processed[, -1], type='vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7878133\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7878133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree AUC on test - without resampling\n",
    "# AUC is 78.7% without oversampling\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "\n",
    "prediction_tree_roc_curve_test <- predict(classtree,test_processed[, -1],type=\"vector\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_tree_roc_curve_test[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    "\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.tree.test <- performance(pred, measure = \"auc\")\n",
    " print(auc.tree.test@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8178803\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8178803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree AUC on test set - with resampling\n",
    "# AUC is 81.7% with resampling\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "\n",
    "prediction_treeup_roc_curve_test <- predict(classtree.up,test_processed[, -1],type=\"vector\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_treeup_roc_curve_test[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.tree.test <- performance(pred, measure = \"auc\")\n",
    " print(auc.tree.test@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.888571428571429"
      ],
      "text/latex": [
       "0.888571428571429"
      ],
      "text/markdown": [
       "0.888571428571429"
      ],
      "text/plain": [
       "[1] 0.8885714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.845714285714286"
      ],
      "text/latex": [
       "0.845714285714286"
      ],
      "text/markdown": [
       "0.845714285714286"
      ],
      "text/plain": [
       "[1] 0.8457143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on test set - \n",
    "#without oversampling - 88.8% accuracy\n",
    "tree_acc_test <- accuracy(test_processed$subscribe, tree_pred_test)\n",
    "tree_acc_test\n",
    "\n",
    "#with oversampling - 84.5% accuracy\n",
    "tree_acc_test_up <- accuracy(test_processed$subscribe, tree_pred_test_up)\n",
    "tree_acc_test_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Random Forest - TEST MODELS WITH AND WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test random forest model without resampling\n",
    "\n",
    "rdf.pred.test = predict(rdf, newdata = test_processed[, -1], type='response')\n",
    "\n",
    "# test random forest model with resampling\n",
    "\n",
    "rdf.pred.test.up = predict(rdf_up, newdata = test_processed[, -1], type='response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7695862\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7695862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest auc on test - without resampling\n",
    "# AUC is 76.9% without resampling\n",
    "\n",
    "\n",
    "prediction_rdf_roc_curve_test <- predict(rdf,test_processed[, -1],type=\"prob\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_rdf_roc_curve_test[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    "\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.rdf.test <- performance(pred, measure = \"auc\")\n",
    " print(auc.rdf.test@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8032486\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8032486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest auc on test - with resampling\n",
    "# AUC is 80.3% with resampling\n",
    "\n",
    "# Calculate the probability of new observations belonging to each class\n",
    "\n",
    "prediction_rdfup_roc_curve_test <- predict(rdf_up,test_processed[, -1],type=\"prob\")\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_rdfup_roc_curve_test[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.rdf.test.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.rdf.test.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.89047619047619"
      ],
      "text/latex": [
       "0.89047619047619"
      ],
      "text/markdown": [
       "0.89047619047619"
      ],
      "text/plain": [
       "[1] 0.8904762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.841904761904762"
      ],
      "text/latex": [
       "0.841904761904762"
      ],
      "text/markdown": [
       "0.841904761904762"
      ],
      "text/plain": [
       "[1] 0.8419048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on test set - \n",
    "#without oversampling - 89% accuracy\n",
    "rf_acc_test <- accuracy(test_processed$subscribe, rdf.pred.test)\n",
    "rf_acc_test\n",
    "\n",
    "#with oversampling - 84.1% accuracy\n",
    "rf_acc_test_up <- accuracy(test_processed$subscribe, rdf.pred.test.up)\n",
    "rf_acc_test_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Gradient Boosting - TEST MODELS WITH AND WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.gbm(gb.up, test_processed[, -1], n.trees = 1500, type = \"response\"):\n",
      "\"Number of trees not specified or exceeded number fit so far. Using 1000.\""
     ]
    }
   ],
   "source": [
    "# TEST GRADIENT BOOSTING MODELS \n",
    "\n",
    "# without oversampling\n",
    "\n",
    "gb.pred.test = predict(gb , test_processed[, -1], n.trees = 1500, type='response')\n",
    "gb.pred2.test <- ifelse(gb.pred.test > 0.5,1,0)\n",
    "\n",
    "# with oversampling\n",
    "\n",
    "gb.pred.test.up = predict(gb.up , test_processed[, -1], n.trees = 1500, type='response')\n",
    "gb.pred2.test.up <- ifelse(gb.pred.test.up > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output to correct form\n",
    "\n",
    "gb_df_test <- data.frame(gb.pred.test)\n",
    "gb_df_test$one <- gb_df_test$gb.pred.test\n",
    "gb_df_test$zero <- 1 - gb_df_test$gb.pred.test\n",
    "gb_df_test <- gb_df_test[-1]\n",
    "gb_df_test[, '0'] <- gb_df_test[, 'zero'] \n",
    "gb_df_test[, '1'] <- gb_df_test[, 1]\n",
    "gb_df_test <- gb_df_test[-1]\n",
    "gb_df_test <- gb_df_test[-1]\n",
    "\n",
    "\n",
    "gb_df_test_up <- data.frame(gb.pred.test.up)\n",
    "gb_df_test_up$one <- gb_df_test_up$gb.pred.test.up\n",
    "gb_df_test_up$zero <- 1 - gb_df_test_up$gb.pred.test.up\n",
    "gb_df_test_up <- gb_df_test_up[-1]\n",
    "gb_df_test_up[, '0'] <- gb_df_test_up[, 'zero'] \n",
    "gb_df_test_up[, '1'] <- gb_df_test_up[, 1]\n",
    "gb_df_test_up <- gb_df_test_up[-1]\n",
    "gb_df_test_up <- gb_df_test_up[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8198727\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8198727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  GB AUC on test - AUC is 81.9% without resampling\n",
    "\n",
    "prediction_gb_test_roc_curve <- gb_df_test\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_gb_test_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.gb.test <- performance(pred, measure = \"auc\")\n",
    " print(auc.gb.test@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.8222793\n",
      "\n",
      "[[1]]\n",
      "[1] 0.8222793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  GB AUC on test - AUC is 82.2% with resampling, slight improvement from first model\n",
    "prediction_gbup_test_roc_curve <- gb_df_test_up\n",
    "\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_gbup_test_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.gb.test.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.gb.test.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.893333333333333"
      ],
      "text/latex": [
       "0.893333333333333"
      ],
      "text/markdown": [
       "0.893333333333333"
      ],
      "text/plain": [
       "[1] 0.8933333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.864761904761905"
      ],
      "text/latex": [
       "0.864761904761905"
      ],
      "text/markdown": [
       "0.864761904761905"
      ],
      "text/plain": [
       "[1] 0.8647619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on test set - \n",
    "#without resampling -89.3% accuracy\n",
    "gb_acc_test <- accuracy(test_processed$subscribe, gb.pred2.test)\n",
    "gb_acc_test\n",
    "\n",
    "#with resampling - 86.4% accuracy\n",
    "gb_acc_test_up <- accuracy(test_processed$subscribe, gb.pred2.test.up)\n",
    "gb_acc_test_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.0547091347517135</li>\n",
       "\t<li>0.051112936150499</li>\n",
       "\t<li>0.28309615916636</li>\n",
       "\t<li>0.055499895294003</li>\n",
       "\t<li>0.0417209958136068</li>\n",
       "\t<li>0.0546385477725835</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.0547091347517135\n",
       "\\item 0.051112936150499\n",
       "\\item 0.28309615916636\n",
       "\\item 0.055499895294003\n",
       "\\item 0.0417209958136068\n",
       "\\item 0.0546385477725835\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.0547091347517135\n",
       "2. 0.051112936150499\n",
       "3. 0.28309615916636\n",
       "4. 0.055499895294003\n",
       "5. 0.0417209958136068\n",
       "6. 0.0546385477725835\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.05470913 0.05111294 0.28309616 0.05549990 0.04172100 0.05463855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.179464398041015</li>\n",
       "\t<li>0.212316661412966</li>\n",
       "\t<li>0.530305829565382</li>\n",
       "\t<li>0.249773115529272</li>\n",
       "\t<li>0.260149782037432</li>\n",
       "\t<li>0.270957006790474</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.179464398041015\n",
       "\\item 0.212316661412966\n",
       "\\item 0.530305829565382\n",
       "\\item 0.249773115529272\n",
       "\\item 0.260149782037432\n",
       "\\item 0.270957006790474\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.179464398041015\n",
       "2. 0.212316661412966\n",
       "3. 0.530305829565382\n",
       "4. 0.249773115529272\n",
       "5. 0.260149782037432\n",
       "6. 0.270957006790474\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.1794644 0.2123167 0.5303058 0.2497731 0.2601498 0.2709570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PREDICT ON THE HOLDOUT SET\n",
    "\n",
    "# PREDICT GB WITHOUT RESAMPLING\n",
    "\n",
    "gb_pred_holdout <- predict(gb, newdata=test_holdout_processed[, -1], n.trees=1000, type='response')\n",
    "\n",
    "# PREDICT GB WITH RESAMPLING\n",
    "gb_pred_holdout_up <- predict(gb.up, newdata=test_holdout_processed[, -1], n.trees=1000, type='response')\n",
    "head(gb_pred_holdout)\n",
    "head(gb_pred_holdout_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FILES\n",
    "output <- data.frame(client_id=test_holdout$client_id, subscribe=gb_pred_holdout)\n",
    "write.csv(output, 'C:/Users/skamal/Downloads/gb_submission_noresample.csv', row.names=FALSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FILES\n",
    "output <- data.frame(client_id=test_holdout$client_id, subscribe=gb_pred_holdout_up)\n",
    "write.csv(output, 'C:/Users/skamal/Downloads/gb_submission_resample.csv', row.names=FALSE) # AUC 81.3 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Support Vector Machine - TEST MODELS  WITH AND WITHOUT RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict SVM on test set - without resampling\n",
    "svm.pred.test = predict(svm, newdata = test_processed[,-1]) \n",
    "\n",
    "# predict SVM on test set - with resampling\n",
    "svm.pred.test.up = predict(svm.up, newdata = test_processed[,-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.6519174\n",
      "\n",
      "[[1]]\n",
      "[1] 0.6519174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  SVM AUC on test - without resamping 65% AUC \n",
    "\n",
    "\n",
    "prediction_svm_test_roc_curve <- predict(svm, newdata = test_processed[,-1], probability=TRUE) \n",
    "prediction_svm_test_roc_curve <- attr(prediction_svm_test_roc_curve, \"probabilities\")\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_svm_test_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.svm.test <- performance(pred, measure = \"auc\")\n",
    " print(auc.svm.test@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[1] 0.7893384\n",
      "\n",
      "[[1]]\n",
      "[1] 0.7893384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  SVM AUC on test - with resamping 78.9% AUC \n",
    "\n",
    "\n",
    "prediction_svmup_test_roc_curve <- predict(svm.up, newdata = test_processed[,-1], probability=TRUE) \n",
    "prediction_svmup_test_roc_curve <- attr(prediction_svmup_test_roc_curve, \"probabilities\")\n",
    "colours <- c(\"#F8766D\",\"#00BA38\")\n",
    "\n",
    "# Specify the different classes \n",
    "classes <- levels(as.factor(test_processed$subscribe))\n",
    "\n",
    "\n",
    "for (i in 1:2)\n",
    "{\n",
    " # Define which observations belong to class[i]\n",
    " true_values <- ifelse(test_processed$subscribe==classes[i],1,0)\n",
    " # Assess the performance of classifier for class[i]\n",
    " pred <- prediction(prediction_svmup_test_roc_curve[,i],true_values)\n",
    " perf <- performance(pred, \"tpr\", \"fpr\")\n",
    " # Calculate the AUC and print it to screen\n",
    " auc.svm.test.up <- performance(pred, measure = \"auc\")\n",
    " print(auc.svm.test.up@y.values)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.884761904761905"
      ],
      "text/latex": [
       "0.884761904761905"
      ],
      "text/markdown": [
       "0.884761904761905"
      ],
      "text/plain": [
       "[1] 0.8847619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.845714285714286"
      ],
      "text/latex": [
       "0.845714285714286"
      ],
      "text/markdown": [
       "0.845714285714286"
      ],
      "text/plain": [
       "[1] 0.8457143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate accuracy on test set - \n",
    "#without resampling - 88.4% accurcay\n",
    "svm_acc_test <- accuracy(test_processed$subscribe, svm.pred.test)\n",
    "svm_acc_test\n",
    "\n",
    "#with resampling - 84.5% accuracy\n",
    "svm_acc_test_up <- accuracy(test_processed$subscribe, svm.pred.test.up)\n",
    "svm_acc_test_up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
